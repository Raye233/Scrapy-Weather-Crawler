2025-04-30 22:28:54 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:28:54 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:28:54 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:28:54 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:28:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:28:54 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:28:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:28:54 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:28:54 [scrapy.extensions.telnet] INFO: Telnet Password: 1de71afa16c56266
2025-04-30 22:28:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:28:54 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:28:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:28:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:28:55 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:28:55 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:28:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:28:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:28:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:28:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:28:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:29:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:29:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:29:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:29:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:29:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:29:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:29:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:29:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:29:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:29:12 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:29:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124935,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.431012,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 29, 12, 925223, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 28, 55, 494211, tzinfo=datetime.timezone.utc)}
2025-04-30 22:29:12 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:30:20 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:30:20 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:30:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:30:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:30:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:30:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: b9cfd449c322cc30
2025-04-30 22:30:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:30:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:30:21 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:30:21 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:30:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:30:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:30:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:30:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:30:37 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:30:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124916,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.639458,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 30, 37, 923323, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 30, 21, 283865, tzinfo=datetime.timezone.utc)}
2025-04-30 22:30:37 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:37:28 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:37:28 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:37:28 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:37:28 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:37:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:37:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:37:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:37:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:37:28 [scrapy.extensions.telnet] INFO: Telnet Password: b56929078e977ee6
2025-04-30 22:37:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:37:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:37:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:37:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:37:30 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:37:30 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:37:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:37:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:37:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:37:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:37:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:37:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:37:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:37:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:37:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:37:47 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:37:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124948,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.39802,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 37, 47, 577731, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 37, 30, 179711, tzinfo=datetime.timezone.utc)}
2025-04-30 22:37:47 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:38:16 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:38:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:38:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:38:16 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:38:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:38:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:38:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:38:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:38:16 [scrapy.extensions.telnet] INFO: Telnet Password: 0db8f9eac7909c62
2025-04-30 22:38:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:38:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:38:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:38:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:38:17 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:38:17 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:38:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:38:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:38:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '13',
 '最高温度': '22',
 '湿度': '59',
 '空气质量': '45',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:38:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '67',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西南风'}
2025-04-30 22:38:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '12',
 '空气质量': '51',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西风'}
2025-04-30 22:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250503.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '24',
 '湿度': '19',
 '空气质量': '45',
 '紫外线': '强',
 '风力': '4',
 '风向': '北风'}
2025-04-30 22:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/houtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '18',
 '最高温度': '23',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/mingtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:38:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '29',
 '湿度': '34',
 '空气质量': '良',
 '紫外线': '无',
 '风力': '5',
 '风向': '北风'}
2025-04-30 22:38:35 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:38:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125187,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.565106,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 38, 35, 17275, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599319,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 38, 17, 452169, tzinfo=datetime.timezone.utc)}
2025-04-30 22:38:35 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:40:01 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:40:01 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:40:01 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:40:01 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:40:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:40:01 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:40:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:40:01 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:40:01 [scrapy.extensions.telnet] INFO: Telnet Password: 1f76aeded2189120
2025-04-30 22:40:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:40:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:40:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:40:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:40:02 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:40:02 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:40:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:40:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:40:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:40:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '13',
 '最高温度': '22',
 '湿度': '59',
 '空气质量': '45',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:40:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '67',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西南风'}
2025-04-30 22:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '12',
 '空气质量': '51',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西风'}
2025-04-30 22:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250503.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '24',
 '湿度': '19',
 '空气质量': '45',
 '紫外线': '强',
 '风力': '4',
 '风向': '北风'}
2025-04-30 22:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/houtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '18',
 '最高温度': '23',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/mingtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-04-30 22:40:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '29',
 '湿度': '34',
 '空气质量': '良',
 '紫外线': '无',
 '风力': '5',
 '风向': '北风'}
2025-04-30 22:40:20 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:40:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125372,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.972627,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 40, 20, 875228, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599319,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 40, 2, 902601, tzinfo=datetime.timezone.utc)}
2025-04-30 22:40:20 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:41:37 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:41:37 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:41:37 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:41:37 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:41:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:41:37 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:41:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:41:37 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:41:37 [scrapy.extensions.telnet] INFO: Telnet Password: ea712282efc3082f
2025-04-30 22:41:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:41:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:41:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:41:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:41:39 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:41:39 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:41:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:41:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:41:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:41:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:41:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:41:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:41:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:41:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:41:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:41:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:41:56 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:41:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124923,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.208384,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 41, 56, 289077, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 41, 39, 80693, tzinfo=datetime.timezone.utc)}
2025-04-30 22:41:56 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:42:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:42:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:42:21 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:42:21 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:42:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:42:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:42:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:42:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:42:21 [scrapy.extensions.telnet] INFO: Telnet Password: b79f00e769b7064d
2025-04-30 22:42:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:42:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:42:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:42:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:42:23 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:42:23 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:42:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:42:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:42:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:42:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:42:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:42:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:42:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:42:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:42:42 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:42:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124923,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.983674,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 42, 42, 71697, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 42, 23, 88023, tzinfo=datetime.timezone.utc)}
2025-04-30 22:42:42 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:45:59 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:45:59 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:45:59 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:45:59 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:45:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:45:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:45:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:45:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:45:59 [scrapy.extensions.telnet] INFO: Telnet Password: e249338315a7ae13
2025-04-30 22:45:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:45:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:46:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:46:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:46:00 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:46:00 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:46:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:46:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:46:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:46:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:46:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:46:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:46:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:46:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:46:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:46:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:46:18 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:46:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124886,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.289588,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 46, 18, 863233, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598537,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 46, 0, 573645, tzinfo=datetime.timezone.utc)}
2025-04-30 22:46:18 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 22:50:04 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 22:50:04 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 22:50:04 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 22:50:04 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 22:50:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:50:04 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:50:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 22:50:04 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 22:50:04 [scrapy.extensions.telnet] INFO: Telnet Password: 0b42a615084f9f5c
2025-04-30 22:50:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 22:50:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 22:50:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 22:50:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 22:50:05 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 22:50:05 [scrapy.core.engine] INFO: Spider opened
2025-04-30 22:50:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 22:50:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 22:50:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 22:50:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 22:50:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:50:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 22:50:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 22:50:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 22:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 22:50:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 22:50:23 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 22:50:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124928,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.191453,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 14, 50, 23, 827674, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 14, 50, 5, 636221, tzinfo=datetime.timezone.utc)}
2025-04-30 22:50:23 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 23:01:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 23:01:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 23:01:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 23:01:09 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 23:01:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 23:01:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 23:01:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 23:01:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 23:01:09 [scrapy.extensions.telnet] INFO: Telnet Password: 3e013f0c3bbad410
2025-04-30 23:01:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 23:01:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 23:01:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 23:01:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 23:01:10 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 23:01:10 [scrapy.core.engine] INFO: Spider opened
2025-04-30 23:01:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 23:01:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 23:01:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 23:01:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 23:01:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:01:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 23:01:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 23:01:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 23:01:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:01:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:01:28 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 23:01:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124937,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.922573,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 15, 1, 28, 483009, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 15, 1, 10, 560436, tzinfo=datetime.timezone.utc)}
2025-04-30 23:01:28 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 23:40:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 23:40:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 23:40:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 23:40:02 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 23:40:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 23:40:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 23:40:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 23:40:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 23:40:02 [scrapy.extensions.telnet] INFO: Telnet Password: b6c4063e1b2efbc2
2025-04-30 23:40:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 23:40:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 23:40:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 23:40:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 23:40:04 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 23:40:04 [scrapy.core.engine] INFO: Spider opened
2025-04-30 23:40:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 23:40:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 23:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 23:40:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 23:40:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 23:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 23:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 23:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:40:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:40:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '19',
 '最高温度': '28',
 '湿度': '30',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:40:21 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 23:40:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124944,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.680212,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 15, 40, 21, 717827, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598668,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 15, 40, 4, 37615, tzinfo=datetime.timezone.utc)}
2025-04-30 23:40:21 [scrapy.core.engine] INFO: Spider closed (finished)
2025-04-30 23:54:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-04-30 23:54:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-04-30 23:54:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-04-30 23:54:00 [asyncio] DEBUG: Using selector: SelectSelector
2025-04-30 23:54:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 23:54:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 23:54:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-04-30 23:54:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-04-30 23:54:00 [scrapy.extensions.telnet] INFO: Telnet Password: f959c8cc81eda4a7
2025-04-30 23:54:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-04-30 23:54:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-04-30 23:54:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-04-30 23:54:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-04-30 23:54:01 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-04-30 23:54:01 [scrapy.core.engine] INFO: Spider opened
2025-04-30 23:54:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-04-30 23:54:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-04-30 23:54:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-04-30 23:54:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-04-30 23:54:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:54:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-04-30 23:54:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 23:54:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-04-30 23:54:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-04-30 23:54:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-04-30 23:54:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '17',
 '最高温度': '28',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '西北风'}
2025-04-30 23:54:20 [scrapy.core.engine] INFO: Closing spider (finished)
2025-04-30 23:54:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124847,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.970026,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 15, 54, 20, 627587, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598630,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 15, 54, 1, 657561, tzinfo=datetime.timezone.utc)}
2025-04-30 23:54:20 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:03:38 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:03:38 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:03:38 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:03:38 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:03:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:03:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:03:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:03:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:03:38 [scrapy.extensions.telnet] INFO: Telnet Password: 36f528cf3cb77cb9
2025-05-01 00:03:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:03:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:03:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:03:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:03:39 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:03:39 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:03:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:03:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:03:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 00:03:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-05-01 00:03:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:03:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-05-01 00:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:03:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 00:03:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:03:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:03:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '17',
 '最高温度': '28',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:03:54 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:03:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124887,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 15.509257,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 3, 54, 919586, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598630,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 16, 3, 39, 410329, tzinfo=datetime.timezone.utc)}
2025-05-01 00:03:54 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:05:40 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:05:40 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:05:40 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:05:40 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:05:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:05:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:05:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:05:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:05:40 [scrapy.extensions.telnet] INFO: Telnet Password: 7ad5ad94ca59e7d5
2025-05-01 00:05:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:05:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:05:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:05:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:05:41 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:05:41 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:05:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:05:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:05:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 00:05:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-05-01 00:05:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:05:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-05-01 00:05:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:05:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 00:05:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:05:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:05:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '17',
 '最高温度': '28',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:05:58 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:05:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124895,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.925496,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 5, 58, 783990, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598630,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 16, 5, 41, 858494, tzinfo=datetime.timezone.utc)}
2025-05-01 00:05:58 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:07:13 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:07:13 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:07:13 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:07:13 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:07:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:07:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:07:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:07:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:07:13 [scrapy.extensions.telnet] INFO: Telnet Password: 97996bb58bf182ac
2025-05-01 00:07:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:07:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:07:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:07:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:07:14 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:07:14 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:07:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:07:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 00:07:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-05-01 00:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:07:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-05-01 00:07:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 00:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:07:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:07:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '17',
 '最高温度': '28',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:07:31 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:07:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124887,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.071671,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 7, 31, 688146, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598630,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 16, 7, 14, 616475, tzinfo=datetime.timezone.utc)}
2025-05-01 00:07:31 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:08:22 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:08:22 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:08:23 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:08:23 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:08:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:08:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:08:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:08:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:08:23 [scrapy.extensions.telnet] INFO: Telnet Password: e5d5a4e12905a63f
2025-05-01 00:08:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:08:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:08:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:08:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:08:24 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:08:24 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:08:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:08:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:08:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 00:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-05-01 00:08:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:08:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-05-01 00:08:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:08:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 00:08:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:08:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:08:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '17',
 '最高温度': '28',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:08:40 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:08:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124887,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.101136,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 8, 40, 314652, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598630,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 16, 8, 24, 213516, tzinfo=datetime.timezone.utc)}
2025-05-01 00:08:40 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:10:49 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:10:49 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:10:49 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:10:49 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:10:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:10:49 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:10:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:10:49 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:10:49 [scrapy.extensions.telnet] INFO: Telnet Password: 350c43c5493ec7f4
2025-05-01 00:10:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:10:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:10:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:10:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:10:51 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:10:51 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:10:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:10:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 00:10:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:10:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '46',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东风'}
2025-05-01 00:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:10:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '14',
 '最高温度': '23',
 '湿度': '46',
 '空气质量': '49',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:10:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '29',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东南风'}
2025-05-01 00:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250503.html?qd=tq7>
{'时间': '2025年05月03日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '19',
 '空气质量': '33',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:11:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 00:11:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:11:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '北风'}
2025-05-01 00:11:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 00:11:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年04月30日',
 '最低温度': '17',
 '最高温度': '28',
 '湿度': '43',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 00:11:06 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:11:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 124897,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 15.321086,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 11, 6, 365282, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 598630,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 4, 30, 16, 10, 51, 44196, tzinfo=datetime.timezone.utc)}
2025-05-01 00:11:06 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:22:55 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:22:55 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:22:55 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:22:55 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:22:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:22:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:22:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:22:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:22:55 [scrapy.extensions.telnet] INFO: Telnet Password: b6cfe2a156a29e07
2025-05-01 00:22:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:22:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:22:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:22:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:22:56 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:22:56 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:22:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:22:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:22:56 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\day7_weather_spider.py", line 38, in start_requests
    print("== 爬虫开始请求 ==")
OSError: [Errno 22] Invalid argument
2025-05-01 00:22:56 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:22:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.0,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 22, 56, 387830, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 4, 30, 16, 22, 56, 387830, tzinfo=datetime.timezone.utc)}
2025-05-01 00:22:56 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 00:24:13 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 00:24:13 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 00:24:13 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 00:24:13 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 00:24:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:24:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:24:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 00:24:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 00:24:13 [scrapy.extensions.telnet] INFO: Telnet Password: 45565b14a6487405
2025-05-01 00:24:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 00:24:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 00:24:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 00:24:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 00:24:14 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 00:24:14 [scrapy.core.engine] INFO: Spider opened
2025-05-01 00:24:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 00:24:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 00:24:14 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\day7_weather_spider.py", line 38, in start_requests
    print("== 爬虫开始请求 ==")
OSError: [Errno 22] Invalid argument
2025-05-01 00:24:14 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 00:24:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.0,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 4, 30, 16, 24, 14, 509706, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 4, 30, 16, 24, 14, 509706, tzinfo=datetime.timezone.utc)}
2025-05-01 00:24:14 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 09:50:48 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 09:50:48 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 09:50:48 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 09:50:48 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 09:50:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:50:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:50:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:50:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:50:48 [scrapy.extensions.telnet] INFO: Telnet Password: 483d89c00bd57bc3
2025-05-01 09:50:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 09:50:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 09:50:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 09:50:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 09:50:49 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 09:50:49 [scrapy.core.engine] INFO: Spider opened
2025-05-01 09:50:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 09:50:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 09:50:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 09:50:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:50:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 09:50:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:50:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 09:50:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:50:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 09:51:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:51:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:51:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:51:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 09:51:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:51:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:51:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:51:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:51:08 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 09:51:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125030,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.769209,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 1, 51, 8, 680503, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 1, 50, 49, 911294, tzinfo=datetime.timezone.utc)}
2025-05-01 09:51:08 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 09:52:16 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 09:52:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 09:52:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 09:52:16 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 09:52:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:52:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:52:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:52:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:52:16 [scrapy.extensions.telnet] INFO: Telnet Password: b420c681ef1433aa
2025-05-01 09:52:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 09:52:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 09:52:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 09:52:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 09:52:18 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 09:52:18 [scrapy.core.engine] INFO: Spider opened
2025-05-01 09:52:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 09:52:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 09:52:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 09:52:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 09:52:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 09:52:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:52:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 09:52:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:52:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:52:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:52:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 09:52:35 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 09:52:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125167,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.116159,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 1, 52, 35, 161583, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 1, 52, 18, 45424, tzinfo=datetime.timezone.utc)}
2025-05-01 09:52:35 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 09:53:12 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 09:53:12 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 09:53:12 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 09:53:12 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 09:53:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:53:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:53:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:53:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:53:12 [scrapy.extensions.telnet] INFO: Telnet Password: 8e271150c9810778
2025-05-01 09:53:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 09:53:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 09:53:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 09:53:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 09:53:14 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 09:53:14 [scrapy.core.engine] INFO: Spider opened
2025-05-01 09:53:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 09:53:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 09:53:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 09:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 09:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 09:53:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:53:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 09:53:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:53:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 09:53:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 09:53:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 09:53:30 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 09:53:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125173,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.73454,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 1, 53, 30, 940156, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 1, 53, 14, 205616, tzinfo=datetime.timezone.utc)}
2025-05-01 09:53:30 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 09:56:27 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 09:56:27 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 09:56:27 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 09:56:27 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 09:56:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:56:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:56:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:56:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:56:27 [scrapy.extensions.telnet] INFO: Telnet Password: f055f5acaf2a0ec5
2025-05-01 09:56:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 09:56:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 09:56:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 09:56:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 09:56:28 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 09:56:28 [scrapy.core.engine] INFO: Spider opened
2025-05-01 09:56:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 09:56:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 09:56:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 09:58:28 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 09:58:28 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 09:58:28 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 09:58:28 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 09:58:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:58:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:58:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 09:58:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 09:58:28 [scrapy.extensions.telnet] INFO: Telnet Password: 9551e1971c515772
2025-05-01 09:58:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 09:58:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 09:58:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 09:58:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 09:58:29 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 09:58:29 [scrapy.core.engine] INFO: Spider opened
2025-05-01 09:58:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 09:58:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 09:58:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:02:12 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:02:12 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:02:12 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:02:12 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:02:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:02:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:02:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:02:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:02:12 [scrapy.extensions.telnet] INFO: Telnet Password: 11623ec17cfc5654
2025-05-01 10:02:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:02:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:02:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:02:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:02:13 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:02:13 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:02:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:02:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:02:13 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\day7_weather_spider.py", line 38, in start_requests
    print("== 爬虫开始请求 ==")
OSError: [Errno 22] Invalid argument
2025-05-01 10:02:13 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:02:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004517,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 2, 13, 302692, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 1, 2, 2, 13, 298175, tzinfo=datetime.timezone.utc)}
2025-05-01 10:02:13 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:02:51 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:02:51 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:02:51 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:02:51 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:02:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:02:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:02:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:02:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:02:51 [scrapy.extensions.telnet] INFO: Telnet Password: 19c4e415ac08d2fa
2025-05-01 10:02:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:02:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:02:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:02:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:02:53 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:02:53 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:02:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:02:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:02:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:02:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:02:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:02:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:03:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:03:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:03:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:03:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:03:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:03:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:03:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:03:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:03:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:03:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:03:09 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:03:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125192,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.565284,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 3, 9, 749469, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 2, 53, 184185, tzinfo=datetime.timezone.utc)}
2025-05-01 10:03:09 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:04:17 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:04:17 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:04:17 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:04:17 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:04:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:04:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:04:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:04:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:04:17 [scrapy.extensions.telnet] INFO: Telnet Password: dadb874300e7d756
2025-05-01 10:04:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:04:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:07:47 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:07:47 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:07:47 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:07:47 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:07:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:07:47 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:07:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:07:47 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:07:47 [scrapy.extensions.telnet] INFO: Telnet Password: ac45525e7df4cdb3
2025-05-01 10:07:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:07:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:07:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:07:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:07:48 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:07:48 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:07:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:07:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:07:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:07:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:07:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:07:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:07:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:07:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:07:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:07:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:07:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:07:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:07:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:08:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:08:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:08:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:08:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:08:04 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:08:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125189,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.086609,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 8, 4, 473131, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 7, 48, 386522, tzinfo=datetime.timezone.utc)}
2025-05-01 10:08:04 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:13:46 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:13:46 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:13:46 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:13:46 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:13:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:13:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:13:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:13:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:13:46 [scrapy.extensions.telnet] INFO: Telnet Password: aa2bc667e80c1248
2025-05-01 10:13:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:13:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:13:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:13:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:13:47 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:13:47 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:13:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:13:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:13:47 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\day7_weather_spider.py", line 38, in start_requests
    print("== 爬虫开始请求 ==")
OSError: [Errno 22] Invalid argument
2025-05-01 10:13:47 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:13:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 13, 47, 245879, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 1, 2, 13, 47, 241879, tzinfo=datetime.timezone.utc)}
2025-05-01 10:13:47 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:14:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:14:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:14:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:14:09 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:14:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:14:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:14:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:14:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:14:09 [scrapy.extensions.telnet] INFO: Telnet Password: 042019fc4dd81960
2025-05-01 10:14:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:14:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:14:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:14:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:14:11 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:14:11 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:14:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:14:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:14:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:14:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:14:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:14:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:15:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:15:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:15:20 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:15:20 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:15:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:15:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:15:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:15:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:15:20 [scrapy.extensions.telnet] INFO: Telnet Password: b65db1d69d318acb
2025-05-01 10:15:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:15:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:15:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:15:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:15:21 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:15:21 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:15:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:15:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:15:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:15:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:15:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:15:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:15:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:15:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:15:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:15:39 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:15:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125193,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.015171,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 15, 39, 731652, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 15, 21, 716481, tzinfo=datetime.timezone.utc)}
2025-05-01 10:15:39 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:20:19 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:20:19 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:20:19 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:20:19 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:20:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:20:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:20:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:20:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:20:19 [scrapy.extensions.telnet] INFO: Telnet Password: 7b4ce1ec1fb6c697
2025-05-01 10:20:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:20:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:20:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:20:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:20:21 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:20:21 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:20:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:20:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:20:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:20:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:20:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:20:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:20:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:20:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:20:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:20:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:20:37 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:20:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125190,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.643138,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 20, 37, 667411, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 20, 21, 24273, tzinfo=datetime.timezone.utc)}
2025-05-01 10:20:37 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:21:52 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:21:52 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:21:52 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:21:52 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:21:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:21:52 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:21:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:21:52 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:21:52 [scrapy.extensions.telnet] INFO: Telnet Password: cb0b35d67fd47ac6
2025-05-01 10:21:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:21:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:21:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:21:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:21:54 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:21:54 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:21:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:21:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:21:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:21:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:22:10 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:22:10 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:22:10 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:22:10 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:22:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:22:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:22:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:22:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:22:10 [scrapy.extensions.telnet] INFO: Telnet Password: 62d6a3a4bfe63a30
2025-05-01 10:22:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:22:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:22:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:22:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:22:11 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:22:11 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:22:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:22:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:22:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:22:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:22:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:22:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:22:28 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:22:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125179,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.546894,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 22, 28, 521988, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 22, 11, 975094, tzinfo=datetime.timezone.utc)}
2025-05-01 10:22:28 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:24:13 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:24:13 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:24:13 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:24:13 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:24:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:24:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:24:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:24:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:24:13 [scrapy.extensions.telnet] INFO: Telnet Password: 1672fa1576e4d245
2025-05-01 10:24:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:24:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:24:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:24:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:24:15 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:24:15 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:24:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:24:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:25:16 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:25:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:25:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:25:16 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:25:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:25:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:25:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:25:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:25:16 [scrapy.extensions.telnet] INFO: Telnet Password: 72a3ab19ffb83c91
2025-05-01 10:25:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:25:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:25:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:25:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:25:17 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:25:17 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:25:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:25:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:25:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:25:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:25:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:25:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:25:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:25:34 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:25:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125179,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.756902,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 25, 34, 666126, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 25, 17, 909224, tzinfo=datetime.timezone.utc)}
2025-05-01 10:25:34 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:26:43 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:26:43 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:26:43 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:26:43 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:26:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:26:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:26:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:26:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:26:43 [scrapy.extensions.telnet] INFO: Telnet Password: 81f103ccab9246d7
2025-05-01 10:26:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:26:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:26:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:26:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:26:44 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:26:44 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:26:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:26:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:26:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:26:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:26:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:26:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:26:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:26:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:26:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:26:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:26:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:26:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:26:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:26:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:26:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:27:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:27:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:27:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:27:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125180,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.607661,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 27, 1, 340869, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 26, 44, 733208, tzinfo=datetime.timezone.utc)}
2025-05-01 10:27:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 10:28:22 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 10:28:22 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 10:28:22 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 10:28:22 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 10:28:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:28:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:28:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 10:28:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 10:28:22 [scrapy.extensions.telnet] INFO: Telnet Password: 4ced11a476422a41
2025-05-01 10:28:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 10:28:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 10:28:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 10:28:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 10:28:23 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 10:28:23 [scrapy.core.engine] INFO: Spider opened
2025-05-01 10:28:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 10:28:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 10:28:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 10:28:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 10:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 10:28:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:28:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 10:28:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:28:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 10:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 10:28:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '15',
 '空气质量': '优',
 '紫外线': '弱',
 '风力': '3',
 '风向': '西北风'}
2025-05-01 10:28:41 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 10:28:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125179,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.353213,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 2, 28, 41, 961479, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599226,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 2, 28, 23, 608266, tzinfo=datetime.timezone.utc)}
2025-05-01 10:28:41 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 17:10:15 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 17:10:15 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 17:10:15 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 17:10:15 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 17:10:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 17:10:15 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 17:10:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 17:10:15 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 17:10:15 [scrapy.extensions.telnet] INFO: Telnet Password: e13737cdbcf91b72
2025-05-01 17:10:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 17:10:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 17:10:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 17:10:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 17:10:16 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 17:10:16 [scrapy.core.engine] INFO: Spider opened
2025-05-01 17:10:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 17:10:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 17:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 17:10:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 17:10:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 17:10:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:10:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 17:10:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:10:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:10:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:10:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '13',
 '最高温度': '26',
 '湿度': '22',
 '空气质量': '优',
 '紫外线': '中等',
 '风力': '2',
 '风向': '北风'}
2025-05-01 17:10:33 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 17:10:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125236,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.238994,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 9, 10, 33, 535705, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599207,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 9, 10, 16, 296711, tzinfo=datetime.timezone.utc)}
2025-05-01 17:10:33 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 17:11:06 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 17:11:06 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 17:11:06 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 17:11:06 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 17:11:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 17:11:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 17:11:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 17:11:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 17:11:06 [scrapy.extensions.telnet] INFO: Telnet Password: 3e0b5c52e2e5ca31
2025-05-01 17:11:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 17:11:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 17:11:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 17:11:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 17:11:07 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 17:11:07 [scrapy.core.engine] INFO: Spider opened
2025-05-01 17:11:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 17:11:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 17:11:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 17:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 17:11:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 17:11:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:11:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 17:11:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:11:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:11:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:11:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '13',
 '最高温度': '26',
 '湿度': '22',
 '空气质量': '优',
 '紫外线': '中等',
 '风力': '2',
 '风向': '北风'}
2025-05-01 17:11:24 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 17:11:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125221,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.514925,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 9, 11, 24, 25834, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599207,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 9, 11, 7, 510909, tzinfo=datetime.timezone.utc)}
2025-05-01 17:11:24 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 17:14:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 17:14:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 17:14:20 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 17:14:20 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 17:14:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 17:14:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 17:14:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 17:14:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 17:14:20 [scrapy.extensions.telnet] INFO: Telnet Password: 6a44e8b7e87af3cc
2025-05-01 17:14:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 17:14:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 17:14:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 17:14:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 17:14:22 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 17:14:22 [scrapy.core.engine] INFO: Spider opened
2025-05-01 17:14:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 17:14:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/7/> (referer: https://www.tianqi.com/)
2025-05-01 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '48',
 '空气质量': '56',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '南风'}
2025-05-01 17:14:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '15',
 '最高温度': '24',
 '湿度': '50',
 '空气质量': '38',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-01 17:14:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '24',
 '湿度': '53',
 '空气质量': '58',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:14:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/beijing/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '15',
 '空气质量': '54',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '南风'}
2025-05-01 17:14:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/houtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '52',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:14:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/mingtian/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/mingtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '15',
 '最高温度': '22',
 '湿度': '17',
 '空气质量': '优',
 '紫外线': '强',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 17:14:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/beijing/?qd=tq7> (referer: https://www.tianqi.com/beijing/7/)
2025-05-01 17:14:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/beijing/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '13',
 '最高温度': '26',
 '湿度': '22',
 '空气质量': '优',
 '紫外线': '中等',
 '风力': '2',
 '风向': '北风'}
2025-05-01 17:14:39 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 17:14:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125222,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.580323,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 9, 14, 39, 695950, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599207,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 9, 14, 22, 115627, tzinfo=datetime.timezone.utc)}
2025-05-01 17:14:39 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 22:22:22 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 22:22:22 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 22:22:22 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 22:22:22 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 22:22:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 22:22:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 22:22:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 22:22:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 22:22:22 [scrapy.extensions.telnet] INFO: Telnet Password: 4f1bcd0ab52e5a0e
2025-05-01 22:22:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 22:22:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 22:22:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 22:22:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 22:22:24 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 22:22:24 [scrapy.core.engine] INFO: Spider opened
2025-05-01 22:22:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 22:22:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 22:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/7/> (referer: https://www.tianqi.com/)
2025-05-01 22:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '12',
 '空气质量': '51',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西风'}
2025-05-01 22:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/houtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '18',
 '最高温度': '23',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东风'}
2025-05-01 22:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/mingtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-05-01 22:22:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '26',
 '湿度': '36',
 '空气质量': '良',
 '紫外线': '无',
 '风力': '3',
 '风向': '东南风'}
2025-05-01 22:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250507.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '15',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '57',
 '紫外线': '弱',
 '风力': '3',
 '风向': '东南风'}
2025-05-01 22:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '13',
 '最高温度': '22',
 '湿度': '59',
 '空气质量': '45',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 22:22:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:22:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '67',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西南风'}
2025-05-01 22:22:42 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 22:22:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125394,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 18.922669,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 14, 22, 42, 982113, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599413,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 14, 22, 24, 59444, tzinfo=datetime.timezone.utc)}
2025-05-01 22:22:42 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 22:23:24 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 22:23:24 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 22:23:24 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 22:23:24 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 22:23:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 22:23:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 22:23:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 22:23:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 22:23:24 [scrapy.extensions.telnet] INFO: Telnet Password: 21c682f7e3208fe5
2025-05-01 22:23:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 22:23:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 22:23:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 22:23:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 22:23:25 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 22:23:25 [scrapy.core.engine] INFO: Spider opened
2025-05-01 22:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 22:23:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 22:23:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/7/> (referer: https://www.tianqi.com/)
2025-05-01 22:23:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250507.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '15',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '57',
 '紫外线': '弱',
 '风力': '3',
 '风向': '东南风'}
2025-05-01 22:23:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '13',
 '最高温度': '22',
 '湿度': '59',
 '空气质量': '45',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 22:23:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '67',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西南风'}
2025-05-01 22:23:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '12',
 '空气质量': '51',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西风'}
2025-05-01 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/houtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '18',
 '最高温度': '23',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东风'}
2025-05-01 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/mingtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-05-01 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:23:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '26',
 '湿度': '36',
 '空气质量': '良',
 '紫外线': '无',
 '风力': '3',
 '风向': '东南风'}
2025-05-01 22:23:43 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 22:23:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125446,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 17.414297,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 14, 23, 43, 337788, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599413,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 14, 23, 25, 923491, tzinfo=datetime.timezone.utc)}
2025-05-01 22:23:43 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-01 22:24:13 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-01 22:24:13 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-01 22:24:13 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-01 22:24:13 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-01 22:24:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 22:24:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 22:24:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-01 22:24:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-01 22:24:13 [scrapy.extensions.telnet] INFO: Telnet Password: 107d908539ccdf0a
2025-05-01 22:24:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-01 22:24:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-01 22:24:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-01 22:24:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-01 22:24:15 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-01 22:24:15 [scrapy.core.engine] INFO: Spider opened
2025-05-01 22:24:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-01 22:24:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-01 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/7/> (referer: https://www.tianqi.com/)
2025-05-01 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250507.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250507.html?qd=tq7>
{'时间': '2025年05月07日',
 '最低温度': '15',
 '最高温度': '23',
 '湿度': '51',
 '空气质量': '57',
 '紫外线': '弱',
 '风力': '3',
 '风向': '东南风'}
2025-05-01 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250506.html?qd=tq7>
{'时间': '2025年05月06日',
 '最低温度': '13',
 '最高温度': '22',
 '湿度': '59',
 '空气质量': '45',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东北风'}
2025-05-01 22:24:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250505.html?qd=tq7>
{'时间': '2025年05月05日',
 '最低温度': '17',
 '最高温度': '25',
 '湿度': '31',
 '空气质量': '67',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西南风'}
2025-05-01 22:24:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianqi/tianjin/20250504.html?qd=tq7>
{'时间': '2025年05月04日',
 '最低温度': '16',
 '最高温度': '26',
 '湿度': '12',
 '空气质量': '51',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '西风'}
2025-05-01 22:24:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/houtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/houtian/?qd=tq7>
{'时间': '2025年05月02日',
 '最低温度': '18',
 '最高温度': '23',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '东风'}
2025-05-01 22:24:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/mingtian/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/mingtian/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '16',
 '最高温度': '25',
 '湿度': '39',
 '空气质量': '优',
 '紫外线': '无',
 '风力': '3',
 '风向': '北风'}
2025-05-01 22:24:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com/tianjin/?qd=tq7> (referer: https://www.tianqi.com/tianjin/7/)
2025-05-01 22:24:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com/tianjin/?qd=tq7>
{'时间': '2025年05月01日',
 '最低温度': '17',
 '最高温度': '26',
 '湿度': '36',
 '空气质量': '良',
 '紫外线': '无',
 '风力': '3',
 '风向': '东南风'}
2025-05-01 22:24:32 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-01 22:24:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3298,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 125456,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 16.934061,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 1, 14, 24, 32, 123179, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 599413,
 'httpcompression/response_count': 8,
 'item_scraped_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 20,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 8,
 'responses_per_minute': None,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 5, 1, 14, 24, 15, 189118, tzinfo=datetime.timezone.utc)}
2025-05-01 22:24:32 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 15:52:16 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 15:52:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 15:52:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 15:52:16 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 15:52:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 15:52:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 15:52:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 15:52:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 15:52:16 [scrapy.extensions.telnet] INFO: Telnet Password: 45aaf362d4b84879
2025-05-03 15:52:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 15:52:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 15:52:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 15:52:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 15:52:17 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 15:52:17 [scrapy.core.engine] INFO: Spider opened
2025-05-03 15:52:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:52:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 15:52:18 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443
2025-05-03 15:52:18 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 "GET /list/public_suffix_list.dat HTTP/11" 200 84525
2025-05-03 15:52:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200101%2f&_ordtok=b0Z3WVL0bLDbRrtVqZN6nWFq36> from <GET https://www.tianqi.com//tianqi/wuhan/20200101/>
2025-05-03 15:52:19 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'gateway.zscloud.net': <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200101%2f&_ordtok=b0Z3WVL0bLDbRrtVqZN6nWFq36>
2025-05-03 15:52:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200102%2f&_ordtok=5SZ3WV5WZQBn50sF3S03FQDj2Q> from <GET https://www.tianqi.com//tianqi/wuhan/20200102/>
2025-05-03 15:52:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200103%2f&_ordtok=shW3WV5r2260FRBmV0HD0NJSV6> from <GET https://www.tianqi.com//tianqi/wuhan/20200103/>
2025-05-03 15:52:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200104%2f&_ordtok=nB43WVLbQJrR6rTMWZVqKPnfnj> from <GET https://www.tianqi.com//tianqi/wuhan/20200104/>
2025-05-03 15:52:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200105%2f&_ordtok=Sm43WVFKs6MHr5NSN6kQ8qS48j> from <GET https://www.tianqi.com//tianqi/wuhan/20200105/>
2025-05-03 15:52:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200106%2f&_ordtok=R243WVZbq7L2F5cQjb62ZWRjqQ> from <GET https://www.tianqi.com//tianqi/wuhan/20200106/>
2025-05-03 15:52:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200107%2f&_ordtok=n6Z3WVRh6hs4Pr0L5L815QttJM> from <GET https://www.tianqi.com//tianqi/wuhan/20200107/>
2025-05-03 15:52:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200108%2f&_ordtok=njZ3WVR0s0khn5QTNLJP650ZDN> from <GET https://www.tianqi.com//tianqi/wuhan/20200108/>
2025-05-03 15:52:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200109%2f&_ordtok=nJW3WVF52M6sj3k047LrL2MnQM> from <GET https://www.tianqi.com//tianqi/wuhan/20200109/>
2025-05-03 15:52:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200110%2f&_ordtok=7Kk3WVhJsMqrMfWscnV2TjPMP7> from <GET https://www.tianqi.com//tianqi/wuhan/20200110/>
2025-05-03 15:52:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200111%2f&_ordtok=F0Z3WVRWSHVRnnPqdtsrZWfTV0> from <GET https://www.tianqi.com//tianqi/wuhan/20200111/>
2025-05-03 15:52:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200112%2f&_ordtok=ZKW3WV56hRhJRN3vtvjf41JTQ7> from <GET https://www.tianqi.com//tianqi/wuhan/20200112/>
2025-05-03 15:52:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200113%2f&_ordtok=QLW3WV3SrrP4RQ6Gj7sFbL64Jj> from <GET https://www.tianqi.com//tianqi/wuhan/20200113/>
2025-05-03 15:52:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200114%2f&_ordtok=FmW3WV3knrsPs6b5KJrnRM4bDj> from <GET https://www.tianqi.com//tianqi/wuhan/20200114/>
2025-05-03 15:52:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200115%2f&_ordtok=P0Z3WVL4SZKMQ6r6DqsRfDPqqN> from <GET https://www.tianqi.com//tianqi/wuhan/20200115/>
2025-05-03 15:52:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200116%2f&_ordtok=7h43WVZQsLF5H6DpbH66SnJPMN> from <GET https://www.tianqi.com//tianqi/wuhan/20200116/>
2025-05-03 15:53:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200117%2f&_ordtok=h5W3WVFMHNrk51S4W2R8DPWqrP> from <GET https://www.tianqi.com//tianqi/wuhan/20200117/>
2025-05-03 15:53:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200118%2f&_ordtok=rbW3WVZqNskkjH3vWtTzzngn3F> from <GET https://www.tianqi.com//tianqi/wuhan/20200118/>
2025-05-03 15:53:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200119%2f&_ordtok=KJW3WVh7HNjRr1VW3J7vW1PTqR> from <GET https://www.tianqi.com//tianqi/wuhan/20200119/>
2025-05-03 15:53:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:53:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200120%2f&_ordtok=FFW3WVhV4j2FMHrVkRQcT1RHJs> from <GET https://www.tianqi.com//tianqi/wuhan/20200120/>
2025-05-03 15:53:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200121%2f&_ordtok=Sn43WVF6Qqj4DrfD5RP53HHwDr> from <GET https://www.tianqi.com//tianqi/wuhan/20200121/>
2025-05-03 15:53:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200122%2f&_ordtok=F6Z3WV3jF0KPqFMNZH7PQj789P> from <GET https://www.tianqi.com//tianqi/wuhan/20200122/>
2025-05-03 15:53:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200123%2f&_ordtok=rM43WVLWJ2PFR65bKtn7W04NLN> from <GET https://www.tianqi.com//tianqi/wuhan/20200123/>
2025-05-03 15:53:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200124%2f&_ordtok=B043WV5VKPD0DP4f4QZRtDNsF6> from <GET https://www.tianqi.com//tianqi/wuhan/20200124/>
2025-05-03 15:53:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200125%2f&_ordtok=QL43WV55DQBmRTkZ0DQWZ4tjFr> from <GET https://www.tianqi.com//tianqi/wuhan/20200125/>
2025-05-03 15:53:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200126%2f&_ordtok=4n43WVZP7j50J6jQJ3n0M54ft6> from <GET https://www.tianqi.com//tianqi/wuhan/20200126/>
2025-05-03 15:53:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200127%2f&_ordtok=PqZ3WV3B3DMQP3F7MW8rZVJTvq> from <GET https://www.tianqi.com//tianqi/wuhan/20200127/>
2025-05-03 15:53:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200128%2f&_ordtok=Mb43WV3jWJMHRPWHTFqtK4LtfM> from <GET https://www.tianqi.com//tianqi/wuhan/20200128/>
2025-05-03 15:53:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200129%2f&_ordtok=hKk3WVRZZHKR5qnfs57Q7HQRWj> from <GET https://www.tianqi.com//tianqi/wuhan/20200129/>
2025-05-03 15:53:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200130%2f&_ordtok=WPk3WVL2ZBQb52443FtNS5J8RF> from <GET https://www.tianqi.com//tianqi/wuhan/20200130/>
2025-05-03 15:53:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200131%2f&_ordtok=mQk3WVR3bJqHPVPmVkDWmJnBnH> from <GET https://www.tianqi.com//tianqi/wuhan/20200131/>
2025-05-03 15:53:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200201%2f&_ordtok=bFZ3WVFF5j2MMlRsS2NVHDJVJ5> from <GET https://www.tianqi.com//tianqi/wuhan/20200201/>
2025-05-03 15:53:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200202%2f&_ordtok=24k3WV5mSRbSR2v0WF6knv4NDV> from <GET https://www.tianqi.com//tianqi/wuhan/20200202/>
2025-05-03 15:53:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200203%2f&_ordtok=k743WV50QkVVN01NnV2j737jQS> from <GET https://www.tianqi.com//tianqi/wuhan/20200203/>
2025-05-03 15:53:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200204%2f&_ordtok=brW3WVRMr7FhFKJ2VD5SmF7j4F> from <GET https://www.tianqi.com//tianqi/wuhan/20200204/>
2025-05-03 15:53:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200205%2f&_ordtok=2BW3WV3hN7RDN46sfQWnFn57WF> from <GET https://www.tianqi.com//tianqi/wuhan/20200205/>
2025-05-03 15:54:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200206%2f&_ordtok=SkZ3WV5sQMHVHJcctFTLckLRfc> from <GET https://www.tianqi.com//tianqi/wuhan/20200206/>
2025-05-03 15:54:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200207%2f&_ordtok=Jq43WV3DNVsQJqT77qLJqJH46Q> from <GET https://www.tianqi.com//tianqi/wuhan/20200207/>
2025-05-03 15:54:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:54:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200208%2f&_ordtok=mnk3WVL5jr0RnP31TV3JV0T11M> from <GET https://www.tianqi.com//tianqi/wuhan/20200208/>
2025-05-03 15:54:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200209%2f&_ordtok=D243WVFrnPFLRRQq5WMMjntHSs> from <GET https://www.tianqi.com//tianqi/wuhan/20200209/>
2025-05-03 15:54:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200210%2f&_ordtok=L243WVFRbMnhNNVVJrMPWkVL5F> from <GET https://www.tianqi.com//tianqi/wuhan/20200210/>
2025-05-03 15:54:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200211%2f&_ordtok=M343WV3SHkPK6pvQStjppDq0Pq> from <GET https://www.tianqi.com//tianqi/wuhan/20200211/>
2025-05-03 15:54:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200212%2f&_ordtok=Z4Z3WV3JkZ6hQQtNnrbLfWFL7r> from <GET https://www.tianqi.com//tianqi/wuhan/20200212/>
2025-05-03 15:54:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200213%2f&_ordtok=kV43WVqbbP30Nn7NSwW2vH2NHH> from <GET https://www.tianqi.com//tianqi/wuhan/20200213/>
2025-05-03 15:54:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200214%2f&_ordtok=S5Z3WV5j4MJhn21FqW417j8F3P> from <GET https://www.tianqi.com//tianqi/wuhan/20200214/>
2025-05-03 15:54:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200215%2f&_ordtok=LWk3WVqNJs56J3ZN3NQVnkSPVQ> from <GET https://www.tianqi.com//tianqi/wuhan/20200215/>
2025-05-03 15:54:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200216%2f&_ordtok=LS43WVZWHsPSD0RjfQHs4JWnsV> from <GET https://www.tianqi.com//tianqi/wuhan/20200216/>
2025-05-03 15:54:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200217%2f&_ordtok=NKZ3WV3kVsVBnJ3FwFvJP5DTj7> from <GET https://www.tianqi.com//tianqi/wuhan/20200217/>
2025-05-03 15:54:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200218%2f&_ordtok=S0Z3WVZQkLZDHP2kk526sH0kTH> from <GET https://www.tianqi.com//tianqi/wuhan/20200218/>
2025-05-03 15:54:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200219%2f&_ordtok=7m43WVqRqR3JrPJs56JVrT4kNM> from <GET https://www.tianqi.com//tianqi/wuhan/20200219/>
2025-05-03 15:54:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200220%2f&_ordtok=JL43WVqk2k0nDDq3M7J0dVWpVF> from <GET https://www.tianqi.com//tianqi/wuhan/20200220/>
2025-05-03 15:54:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200221%2f&_ordtok=LM43WVFL6KZ3P5KRRkWNJSPJGF> from <GET https://www.tianqi.com//tianqi/wuhan/20200221/>
2025-05-03 15:54:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200222%2f&_ordtok=LFW3WVZQMb6LDW6LZfLvqvjHJ5> from <GET https://www.tianqi.com//tianqi/wuhan/20200222/>
2025-05-03 15:54:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200223%2f&_ordtok=SQZ3WV3mBJS2Q1kW4ZTL1GSjn5> from <GET https://www.tianqi.com//tianqi/wuhan/20200223/>
2025-05-03 15:54:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200224%2f&_ordtok=kjk3WVhHFJL75rjSsW1Sjn1jZf> from <GET https://www.tianqi.com//tianqi/wuhan/20200224/>
2025-05-03 15:55:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200225%2f&_ordtok=JB43WVZDFB75rwwSF5tD2QJj5Q> from <GET https://www.tianqi.com//tianqi/wuhan/20200225/>
2025-05-03 15:55:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:55:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200226%2f&_ordtok=22k3WVLJ7D0BH2j5r0vH4VHQf6> from <GET https://www.tianqi.com//tianqi/wuhan/20200226/>
2025-05-03 15:55:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200227%2f&_ordtok=2Sk3WVFbrJZRRfBSkQwRDtkRMr> from <GET https://www.tianqi.com//tianqi/wuhan/20200227/>
2025-05-03 15:55:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200228%2f&_ordtok=KbW3WV5Ss35mPQ7VF47rt0vM1H> from <GET https://www.tianqi.com//tianqi/wuhan/20200228/>
2025-05-03 15:55:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200229/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:55:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:56:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:56:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-03 15:56:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:57:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:58:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 15:59:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 15:59:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 15:59:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 15:59:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 15:59:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:00:12 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-05-03 16:00:12 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-05-03 16:00:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:21:17 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:21:17 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:21:17 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:21:17 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:21:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:21:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:21:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:21:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:21:17 [scrapy.extensions.telnet] INFO: Telnet Password: d8beb9c670a80bc7
2025-05-03 16:21:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:21:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:21:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:21:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:21:19 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:21:19 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:21:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:21:19 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 72, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:21:19 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:21:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.006512,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 21, 19, 100298, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 21, 19, 93786, tzinfo=datetime.timezone.utc)}
2025-05-03 16:21:19 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:22:59 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-05-03 16:23:38 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:23:38 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:23:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:23:39 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:23:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:23:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:23:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:23:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:23:39 [scrapy.extensions.telnet] INFO: Telnet Password: 992f6fd59f07924a
2025-05-03 16:23:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:23:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:23:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:23:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:23:40 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:23:40 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:23:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:23:40 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 72, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:23:40 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:23:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.006511,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 23, 40, 332994, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 23, 40, 326483, tzinfo=datetime.timezone.utc)}
2025-05-03 16:23:40 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:26:25 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:26:25 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:26:25 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:26:25 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:26:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:26:25 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:26:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:26:25 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:26:25 [scrapy.extensions.telnet] INFO: Telnet Password: 985763d3d4cfe006
2025-05-03 16:26:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:26:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:26:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:26:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:26:26 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:26:26 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:26:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:26:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:26:27 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 72, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:26:27 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:26:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.006509,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 26, 27, 4708, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 26, 26, 998199, tzinfo=datetime.timezone.utc)}
2025-05-03 16:26:27 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:34:43 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:34:43 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:34:43 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:34:43 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:34:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:34:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:34:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:34:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:34:43 [scrapy.extensions.telnet] INFO: Telnet Password: 9e9169ae667bc1fb
2025-05-03 16:34:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:34:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:34:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:34:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:34:44 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.day7_WeatherPipeline',
 'weather_project.pipelines.year3_WeatherPipeline',
 'weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:34:44 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:34:44 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-05-03 16:34:44 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method CoreStats.spider_closed of <scrapy.extensions.corestats.CoreStats object at 0x000001D71182B8B0>>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\pipelines.py", line 45, in open_spider
    self.csv_file = open("year3_weather_data.csv", "a+", newline='')
PermissionError: [Errno 13] Permission denied: 'year3_weather_data.csv'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\utils\defer.py", line 400, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\extensions\corestats.py", line 41, in spider_closed
    assert self.start_time is not None
AssertionError
2025-05-03 16:34:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'responses_per_minute': None}
2025-05-03 16:34:44 [scrapy.core.engine] INFO: Spider closed (shutdown)
2025-05-03 16:34:44 [twisted] CRITICAL: Unhandled error in Deferred:
2025-05-03 16:34:44 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\pipelines.py", line 45, in open_spider
    self.csv_file = open("year3_weather_data.csv", "a+", newline='')
PermissionError: [Errno 13] Permission denied: 'year3_weather_data.csv'
2025-05-03 16:35:44 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:35:44 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:35:44 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:35:44 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:35:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:35:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:35:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:35:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:35:44 [scrapy.extensions.telnet] INFO: Telnet Password: 908a426cda81c6fa
2025-05-03 16:35:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:35:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:35:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:35:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:35:45 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:35:45 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:35:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:35:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:35:45 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 62, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:35:45 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004001,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 35, 45, 783814, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 35, 45, 779813, tzinfo=datetime.timezone.utc)}
2025-05-03 16:35:45 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:36:46 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:36:46 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:36:46 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:36:46 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:36:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:36:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:36:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:36:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:36:46 [scrapy.extensions.telnet] INFO: Telnet Password: ca9db6ca9af38e2a
2025-05-03 16:36:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:36:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:36:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:36:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:36:48 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:36:48 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:36:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:36:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:36:48 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 64, in start_requests
    print(f"Using proxy: {HTTP_PROXY}")
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (referer: https://www.tianqi.com/)
2025-05-03 16:36:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200101/>
{'时间': '2020年01月01日',
 '最低温度': '2',
 '最高温度': '7',
 '湿度': '94',
 '空气质量': '92',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-03 16:36:48 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:36:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 402,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 12038,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.331597,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 36, 48, 589455, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 49285,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 7,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 5, 3, 8, 36, 48, 257858, tzinfo=datetime.timezone.utc)}
2025-05-03 16:36:48 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:37:37 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:37:38 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:37:38 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:37:38 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:37:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:37:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:37:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:37:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:37:38 [scrapy.extensions.telnet] INFO: Telnet Password: 9234783fea53699b
2025-05-03 16:37:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:37:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:37:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:37:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:37:39 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:37:39 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:37:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:37:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:37:39 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 62, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:37:39 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:37:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004511,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 37, 39, 351472, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 37, 39, 346961, tzinfo=datetime.timezone.utc)}
2025-05-03 16:37:39 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:38:01 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:38:01 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:38:01 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:38:01 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:38:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:38:01 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:38:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:38:01 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:38:01 [scrapy.extensions.telnet] INFO: Telnet Password: 3f494b0d50306c2e
2025-05-03 16:38:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:38:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:38:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:38:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:38:03 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:38:03 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:38:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:38:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:38:03 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 61, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:38:03 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:38:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 38, 3, 77029, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 38, 3, 73029, tzinfo=datetime.timezone.utc)}
2025-05-03 16:38:03 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:38:12 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:38:12 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:38:12 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:38:12 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:38:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:38:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:38:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:38:12 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:38:12 [scrapy.extensions.telnet] INFO: Telnet Password: 26472226d3986e21
2025-05-03 16:38:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:38:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:38:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:38:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:38:14 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:38:14 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:38:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:38:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:38:14 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 61, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:38:14 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:38:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.003999,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 38, 14, 287185, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 38, 14, 283186, tzinfo=datetime.timezone.utc)}
2025-05-03 16:38:14 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:39:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:39:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:39:21 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:39:21 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:39:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:39:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:39:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:39:21 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:39:21 [scrapy.extensions.telnet] INFO: Telnet Password: f6aeb8dadea842a2
2025-05-03 16:39:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:39:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:39:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:39:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:39:23 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:39:23 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:39:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:39:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:39:23 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 61, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:39:23 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:39:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004141,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 39, 23, 271340, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 39, 23, 267199, tzinfo=datetime.timezone.utc)}
2025-05-03 16:39:23 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:40:33 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:40:33 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:40:33 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:40:33 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:40:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:40:33 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:40:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:40:33 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:40:33 [scrapy.extensions.telnet] INFO: Telnet Password: 7d12eb2541f89016
2025-05-03 16:40:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:40:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:40:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:40:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:40:35 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:40:35 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:40:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:40:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:40:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200101/>
{'时间': '2020年01月01日',
 '最低温度': '2',
 '最高温度': '7',
 '湿度': '94',
 '空气质量': '92',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-03 16:40:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200102/>
{'时间': '2020年01月02日',
 '最低温度': '5',
 '最高温度': '8',
 '湿度': '86',
 '空气质量': '141',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '北风'}
2025-05-03 16:40:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200103/>
{'时间': '2020年01月03日',
 '最低温度': '4',
 '最高温度': '7',
 '湿度': '97',
 '空气质量': '115',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '北风'}
2025-05-03 16:40:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200104/>
{'时间': '2020年01月04日',
 '最低温度': '6',
 '最高温度': '11',
 '湿度': '93',
 '空气质量': '173',
 '紫外线': '弱',
 '风力': '1',
 '风向': '东北风'}
2025-05-03 16:40:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200105/>
{'时间': '2020年01月05日',
 '最低温度': '7',
 '最高温度': '10',
 '湿度': '97',
 '空气质量': '64',
 '紫外线': '最弱',
 '风力': '2',
 '风向': '东风'}
2025-05-03 16:40:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200106/>
{'时间': '2020年01月06日',
 '最低温度': '4',
 '最高温度': '9',
 '湿度': '92',
 '空气质量': '22',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-03 16:40:50 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-05-03 16:40:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-05-03 16:40:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200107/>
{'时间': '2020年01月07日',
 '最低温度': '2',
 '最高温度': '7',
 '湿度': '88',
 '空气质量': '55',
 '紫外线': '最弱',
 '风力': '3',
 '风向': '北风'}
2025-05-03 16:40:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (referer: https://www.tianqi.com/)
2025-05-03 16:40:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tianqi.com//tianqi/wuhan/20200108/>
{'时间': '2020年01月08日',
 '最低温度': '0',
 '最高温度': '7',
 '湿度': '93',
 '空气质量': '61',
 '紫外线': '中等',
 '风力': '3',
 '风向': '东北风'}
2025-05-03 16:40:55 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-05-03 16:41:41 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:41:41 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:41:41 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:41:41 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:41:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:41:41 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:41:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:41:41 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:41:41 [scrapy.extensions.telnet] INFO: Telnet Password: c0a0cf8cd25101de
2025-05-03 16:41:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:41:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:41:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:41:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:41:43 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:41:43 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:41:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:41:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:41:43 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\engine.py", line 185, in _next_request
    request_or_item = next(self.slot.start_requests)
  File "F:\Rayedata2\weather_crawl\weather_predict\weather_project\weather_project\spiders\year5_weather_spider.py", line 61, in start_requests
    yield scrapy.Request(url=com_url, callback=self.five_years_parse_weather_info, meta={'proxy': HTTP_PROXY})
NameError: name 'HTTP_PROXY' is not defined
2025-05-03 16:41:43 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-03 16:41:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 3, 8, 41, 43, 78732, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'responses_per_minute': None,
 'start_time': datetime.datetime(2025, 5, 3, 8, 41, 43, 74728, tzinfo=datetime.timezone.utc)}
2025-05-03 16:41:43 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-03 16:43:23 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 16:43:23 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 16:43:23 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 16:43:23 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 16:43:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:43:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:43:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 16:43:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 16:43:23 [scrapy.extensions.telnet] INFO: Telnet Password: c0cb7fa2720274fc
2025-05-03 16:43:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 16:43:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 16:43:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 16:43:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 16:43:25 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 16:43:25 [scrapy.core.engine] INFO: Spider opened
2025-05-03 16:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:43:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 16:43:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:43:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:44:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200109/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200110/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200111/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200112/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200109/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200110/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200111/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200112/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200109/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200110/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200111/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200112/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200113/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200114/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200115/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200116/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200113/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200114/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200115/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200116/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200113/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200114/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200115/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200116/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200117/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:45:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200118/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200119/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200120/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200117/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200118/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200119/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200120/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200117/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200118/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:45:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200119/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200120/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200121/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200122/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200123/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200124/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200121/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200122/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200123/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200124/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200121/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:46:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200122/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200123/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200124/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200125/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200126/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200127/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200128/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200125/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200126/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200127/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200128/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200125/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200126/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200127/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:46:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200128/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200129/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200130/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200131/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200201/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200129/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200130/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200131/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200201/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200129/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200130/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:47:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200131/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200131/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200201/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200202/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200203/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200204/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200205/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200202/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200203/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200204/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200205/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200202/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200203/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200204/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:47:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200205/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200206/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200207/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200208/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200209/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200206/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200207/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:48:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200208/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200209/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200206/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200207/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200208/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200209/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200210/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200211/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200212/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200213/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200210/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200211/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200212/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200213/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200210/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200211/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:48:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200212/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200213/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200214/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200215/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200216/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200217/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200214/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200215/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200216/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200217/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200214/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:49:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200215/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200216/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200217/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200218/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200219/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200220/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200221/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200218/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200219/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200220/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200221/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200218/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200219/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200220/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:49:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200221/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200222/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200223/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200224/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200225/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200222/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200223/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200224/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200225/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200222/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200223/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:50:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200224/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200225/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200226/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200227/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200228/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200226/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200227/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:50:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200228/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200226/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200227/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200228/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-03 16:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:53:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 16:54:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 16:54:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 16:54:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 16:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:56:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 16:57:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 16:57:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 16:57:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 16:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 16:59:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 16:59:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200229/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 17:00:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 17:00:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 17:00:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 17:00:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 17:00:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 17:00:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 17:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:02:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 17:03:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 17:03:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 17:03:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 17:03:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:05:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 17:06:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 17:06:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 17:06:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 17:06:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:07:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:08:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:08:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 17:08:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200304/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 17:09:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 17:09:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200305/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 17:09:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 17:09:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200306/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 17:09:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 17:09:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200307/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 17:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:10:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:11:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200308/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 17:12:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200309/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 17:12:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200310/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 17:12:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200311/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 17:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:13:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:14:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:14:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200308/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 17:15:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200309/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 17:15:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200310/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 17:15:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200311/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 17:15:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:17:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:17:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200308/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 17:17:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200308/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 17:18:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200309/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 17:18:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200309/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 17:18:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200310/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 17:18:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200310/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 17:18:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200311/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 17:18:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200311/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 17:18:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:19:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:20:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200312/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 17:21:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200313/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 17:21:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200314/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 17:21:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200315/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 17:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200312/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 17:24:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200313/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 17:24:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200314/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 17:24:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200315/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 17:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:26:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200312/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 17:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200312/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 17:27:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200313/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 17:27:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200313/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 17:27:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200314/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 17:27:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200314/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 17:27:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200315/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 17:27:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200315/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 17:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:29:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:29:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200316/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 17:30:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200317/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 17:30:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200318/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 17:30:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200319/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 17:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:31:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200316/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 17:33:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200317/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 17:33:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200318/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 17:33:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200319/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 17:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:35:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:35:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200316/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 17:35:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200316/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 17:36:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200317/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 17:36:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200317/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 17:36:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200318/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 17:36:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200318/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 17:36:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200319/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 17:36:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200319/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 17:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:38:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:38:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200320/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-03 17:39:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200321/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-03 17:39:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200322/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-03 17:39:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200323/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-03 17:39:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:40:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:41:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200320/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-03 17:42:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200321/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-03 17:42:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200322/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-03 17:42:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200323/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-03 17:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:44:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200320/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-03 17:44:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200320/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-03 17:45:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200321/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-03 17:45:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200321/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-03 17:45:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200322/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-03 17:45:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200322/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-03 17:45:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200323/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-03 17:45:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200323/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-03 17:45:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:47:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200324/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-03 17:48:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200325/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-03 17:48:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200326/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-03 17:48:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200327/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-03 17:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:50:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200324/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-03 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200325/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-03 17:51:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200326/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-03 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200327/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-03 17:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:53:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200324/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-03 17:53:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200324/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-03 17:54:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200325/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-03 17:54:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200325/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-03 17:54:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200326/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-03 17:54:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200326/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-03 17:54:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200327/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-03 17:54:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200327/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-03 17:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:56:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200328/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-03 17:57:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200329/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-03 17:57:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200330/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-03 17:57:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200331/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-03 17:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 17:59:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200328/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-03 18:00:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200329/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-03 18:00:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200330/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-03 18:00:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200331/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-03 18:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:02:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200328/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-03 18:02:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200328/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-03 18:03:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200329/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-03 18:03:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200329/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-03 18:03:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200330/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-03 18:03:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200330/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-03 18:03:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200331/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-03 18:03:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200331/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-03 18:03:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:05:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200401/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-03 18:06:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200402/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-03 18:06:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200403/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-03 18:06:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200404/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-03 18:06:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:07:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:08:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200401/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-03 18:09:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200402/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-03 18:09:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200403/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-03 18:09:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200404/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-03 18:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:10:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:11:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200401/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-03 18:11:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200401/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-03 18:12:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200402/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-03 18:12:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200402/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-03 18:12:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200403/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-03 18:12:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200403/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-03 18:12:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200404/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-03 18:12:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200404/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-03 18:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:13:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:14:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:14:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200405/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-03 18:15:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200406/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-03 18:15:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200407/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-03 18:15:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200408/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-03 18:15:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:17:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:17:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200405/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-03 18:18:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200406/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-03 18:18:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200407/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-03 18:18:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200408/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-03 18:18:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:19:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:20:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200405/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-03 18:21:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200405/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-03 18:21:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200406/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-03 18:21:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200407/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-03 18:21:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200406/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-03 18:21:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200407/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-03 18:21:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200408/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-03 18:21:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200408/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-03 18:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:24:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200409/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-03 18:24:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200410/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-03 18:24:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200411/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-03 18:24:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200412/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-03 18:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:27:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200409/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-03 18:27:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200410/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-03 18:27:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200411/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-03 18:27:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200412/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-03 18:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:29:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:30:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200409/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-03 18:30:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200409/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-03 18:30:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200410/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-03 18:30:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200410/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-03 18:30:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200411/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-03 18:30:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200411/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-03 18:30:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200412/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-03 18:30:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200412/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-03 18:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:31:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:33:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200413/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-03 18:33:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200414/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-03 18:33:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200415/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-03 18:33:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200416/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-03 18:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:35:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:36:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200413/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-03 18:36:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200414/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-03 18:36:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200415/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-03 18:36:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200416/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-03 18:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:38:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:39:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200413/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-03 18:39:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200413/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-03 18:39:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200414/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-03 18:39:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200414/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-03 18:39:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200415/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-03 18:39:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200415/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-03 18:39:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200416/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-03 18:39:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200416/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-03 18:39:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:40:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:42:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200417/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-03 18:42:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200418/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-03 18:42:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200419/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-03 18:42:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200420/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-03 18:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:45:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200417/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-03 18:45:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200418/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-03 18:45:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200419/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-03 18:45:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200420/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-03 18:45:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:48:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200417/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-03 18:48:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200417/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-03 18:48:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200418/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-03 18:48:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200418/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-03 18:48:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200419/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-03 18:48:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200419/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-03 18:48:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200420/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-03 18:48:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200420/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-03 18:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:51:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200421/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-03 18:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200422/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-03 18:51:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200423/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-03 18:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200424/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-03 18:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:54:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200421/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-03 18:54:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200422/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-03 18:54:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200423/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-03 18:54:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200424/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-03 18:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:57:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200421/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-03 18:57:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200421/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-03 18:57:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200422/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-03 18:57:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200422/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-03 18:57:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200423/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-03 18:57:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200423/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-03 18:57:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200424/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-03 18:57:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200424/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-03 18:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 18:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:00:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200425/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-03 19:00:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200426/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-03 19:00:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200427/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-03 19:00:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200428/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-03 19:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:03:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200425/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-03 19:03:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200426/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-03 19:03:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200427/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-03 19:03:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200428/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-03 19:03:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:06:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200425/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200425/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200426/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200427/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200428/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200426/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200427/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-03 19:06:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200428/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-03 19:06:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:07:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:08:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200429/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200429/ took longer than 180.0 seconds..
2025-05-03 19:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:09:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200430/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200430/ took longer than 180.0 seconds..
2025-05-03 19:09:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200501/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200501/ took longer than 180.0 seconds..
2025-05-03 19:09:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200502/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200502/ took longer than 180.0 seconds..
2025-05-03 19:10:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:12:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200429/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200429/ took longer than 180.0 seconds..
2025-05-03 19:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:12:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200430/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200430/ took longer than 180.0 seconds..
2025-05-03 19:12:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200501/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200501/ took longer than 180.0 seconds..
2025-05-03 19:12:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200502/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200502/ took longer than 180.0 seconds..
2025-05-03 19:13:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:14:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:15:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200429/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200429/ took longer than 180.0 seconds..
2025-05-03 19:15:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200429/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200429/ took longer than 180.0 seconds..
2025-05-03 19:15:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:15:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200430/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200430/ took longer than 180.0 seconds..
2025-05-03 19:15:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200430/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200430/ took longer than 180.0 seconds..
2025-05-03 19:15:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200501/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200501/ took longer than 180.0 seconds..
2025-05-03 19:15:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200501/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200501/ took longer than 180.0 seconds..
2025-05-03 19:15:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200502/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200502/ took longer than 180.0 seconds..
2025-05-03 19:15:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200502/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200502/ took longer than 180.0 seconds..
2025-05-03 19:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:17:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:18:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200503/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200503/ took longer than 180.0 seconds..
2025-05-03 19:18:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:18:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200504/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200504/ took longer than 180.0 seconds..
2025-05-03 19:18:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200505/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200505/ took longer than 180.0 seconds..
2025-05-03 19:18:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200506/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200506/ took longer than 180.0 seconds..
2025-05-03 19:19:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:21:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200503/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200503/ took longer than 180.0 seconds..
2025-05-03 19:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:21:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200504/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200504/ took longer than 180.0 seconds..
2025-05-03 19:21:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200505/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200505/ took longer than 180.0 seconds..
2025-05-03 19:21:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200506/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200506/ took longer than 180.0 seconds..
2025-05-03 19:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:24:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200503/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200503/ took longer than 180.0 seconds..
2025-05-03 19:24:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200503/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200503/ took longer than 180.0 seconds..
2025-05-03 19:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:24:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200504/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200504/ took longer than 180.0 seconds..
2025-05-03 19:24:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200504/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200504/ took longer than 180.0 seconds..
2025-05-03 19:24:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200505/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200505/ took longer than 180.0 seconds..
2025-05-03 19:24:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200505/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200505/ took longer than 180.0 seconds..
2025-05-03 19:24:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200506/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200506/ took longer than 180.0 seconds..
2025-05-03 19:24:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200506/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200506/ took longer than 180.0 seconds..
2025-05-03 19:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:27:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200507/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200507/ took longer than 180.0 seconds..
2025-05-03 19:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:27:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200508/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200508/ took longer than 180.0 seconds..
2025-05-03 19:27:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200509/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200509/ took longer than 180.0 seconds..
2025-05-03 19:27:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200510/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200510/ took longer than 180.0 seconds..
2025-05-03 19:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:29:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:30:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200507/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200507/ took longer than 180.0 seconds..
2025-05-03 19:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:30:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200508/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200508/ took longer than 180.0 seconds..
2025-05-03 19:30:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200509/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200509/ took longer than 180.0 seconds..
2025-05-03 19:30:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200510/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200510/ took longer than 180.0 seconds..
2025-05-03 19:31:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:33:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200507/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200507/ took longer than 180.0 seconds..
2025-05-03 19:33:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200507/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200507/ took longer than 180.0 seconds..
2025-05-03 19:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:33:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200508/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200508/ took longer than 180.0 seconds..
2025-05-03 19:33:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200508/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200508/ took longer than 180.0 seconds..
2025-05-03 19:33:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200509/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200509/ took longer than 180.0 seconds..
2025-05-03 19:33:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200509/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200509/ took longer than 180.0 seconds..
2025-05-03 19:33:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200510/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200510/ took longer than 180.0 seconds..
2025-05-03 19:33:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200510/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200510/ took longer than 180.0 seconds..
2025-05-03 19:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:35:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:36:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200511/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200511/ took longer than 180.0 seconds..
2025-05-03 19:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:36:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200512/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200512/ took longer than 180.0 seconds..
2025-05-03 19:36:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200513/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200513/ took longer than 180.0 seconds..
2025-05-03 19:36:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200514/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200514/ took longer than 180.0 seconds..
2025-05-03 19:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:38:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:39:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200511/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200511/ took longer than 180.0 seconds..
2025-05-03 19:39:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:39:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200512/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200512/ took longer than 180.0 seconds..
2025-05-03 19:39:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200513/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200513/ took longer than 180.0 seconds..
2025-05-03 19:39:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200514/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200514/ took longer than 180.0 seconds..
2025-05-03 19:40:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:42:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200511/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200511/ took longer than 180.0 seconds..
2025-05-03 19:42:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200511/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200511/ took longer than 180.0 seconds..
2025-05-03 19:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:42:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200512/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200512/ took longer than 180.0 seconds..
2025-05-03 19:42:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200512/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200512/ took longer than 180.0 seconds..
2025-05-03 19:42:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200513/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200513/ took longer than 180.0 seconds..
2025-05-03 19:42:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200513/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200513/ took longer than 180.0 seconds..
2025-05-03 19:42:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200514/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200514/ took longer than 180.0 seconds..
2025-05-03 19:42:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200514/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200514/ took longer than 180.0 seconds..
2025-05-03 19:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:45:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200515/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200515/ took longer than 180.0 seconds..
2025-05-03 19:45:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:45:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200516/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200516/ took longer than 180.0 seconds..
2025-05-03 19:45:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200517/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200517/ took longer than 180.0 seconds..
2025-05-03 19:45:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200518/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200518/ took longer than 180.0 seconds..
2025-05-03 19:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:48:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200515/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200515/ took longer than 180.0 seconds..
2025-05-03 19:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:48:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200516/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200516/ took longer than 180.0 seconds..
2025-05-03 19:48:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200517/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200517/ took longer than 180.0 seconds..
2025-05-03 19:48:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200518/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200518/ took longer than 180.0 seconds..
2025-05-03 19:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:51:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200515/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200515/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200515/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200515/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200516/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200516/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200517/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200517/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200518/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200518/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200518/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200518/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200516/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200516/ took longer than 180.0 seconds..
2025-05-03 19:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200517/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200517/ took longer than 180.0 seconds..
2025-05-03 19:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:54:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200519/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200519/ took longer than 180.0 seconds..
2025-05-03 19:54:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200520/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200520/ took longer than 180.0 seconds..
2025-05-03 19:54:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200521/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200521/ took longer than 180.0 seconds..
2025-05-03 19:54:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200522/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200522/ took longer than 180.0 seconds..
2025-05-03 19:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:57:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200519/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200519/ took longer than 180.0 seconds..
2025-05-03 19:57:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200520/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200520/ took longer than 180.0 seconds..
2025-05-03 19:57:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200521/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200521/ took longer than 180.0 seconds..
2025-05-03 19:57:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200522/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200522/ took longer than 180.0 seconds..
2025-05-03 19:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 19:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:00:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200519/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200519/ took longer than 180.0 seconds..
2025-05-03 20:00:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200519/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200519/ took longer than 180.0 seconds..
2025-05-03 20:00:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200520/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200520/ took longer than 180.0 seconds..
2025-05-03 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200520/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200520/ took longer than 180.0 seconds..
2025-05-03 20:00:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200521/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200521/ took longer than 180.0 seconds..
2025-05-03 20:00:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200521/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200521/ took longer than 180.0 seconds..
2025-05-03 20:00:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200522/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200522/ took longer than 180.0 seconds..
2025-05-03 20:00:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200522/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200522/ took longer than 180.0 seconds..
2025-05-03 20:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:03:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:03:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200523/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200523/ took longer than 180.0 seconds..
2025-05-03 20:03:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200524/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200524/ took longer than 180.0 seconds..
2025-05-03 20:03:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200525/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200525/ took longer than 180.0 seconds..
2025-05-03 20:03:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200526/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200526/ took longer than 180.0 seconds..
2025-05-03 20:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:06:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:06:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200523/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200523/ took longer than 180.0 seconds..
2025-05-03 20:06:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200524/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200524/ took longer than 180.0 seconds..
2025-05-03 20:06:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200525/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200525/ took longer than 180.0 seconds..
2025-05-03 20:06:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200526/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200526/ took longer than 180.0 seconds..
2025-05-03 20:07:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:08:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:09:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200523/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200523/ took longer than 180.0 seconds..
2025-05-03 20:09:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200523/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200523/ took longer than 180.0 seconds..
2025-05-03 20:09:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200524/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200524/ took longer than 180.0 seconds..
2025-05-03 20:09:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200524/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200524/ took longer than 180.0 seconds..
2025-05-03 20:09:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200525/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200525/ took longer than 180.0 seconds..
2025-05-03 20:09:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200525/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200525/ took longer than 180.0 seconds..
2025-05-03 20:09:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200526/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200526/ took longer than 180.0 seconds..
2025-05-03 20:09:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200526/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200526/ took longer than 180.0 seconds..
2025-05-03 20:10:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:12:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200527/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200527/ took longer than 180.0 seconds..
2025-05-03 20:12:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200528/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200528/ took longer than 180.0 seconds..
2025-05-03 20:12:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200529/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200529/ took longer than 180.0 seconds..
2025-05-03 20:12:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200530/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200530/ took longer than 180.0 seconds..
2025-05-03 20:13:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:14:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:15:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:15:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200527/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200527/ took longer than 180.0 seconds..
2025-05-03 20:15:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200528/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200528/ took longer than 180.0 seconds..
2025-05-03 20:15:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200529/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200529/ took longer than 180.0 seconds..
2025-05-03 20:15:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200530/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200530/ took longer than 180.0 seconds..
2025-05-03 20:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:17:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:18:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:18:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200527/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200527/ took longer than 180.0 seconds..
2025-05-03 20:18:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200527/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200527/ took longer than 180.0 seconds..
2025-05-03 20:18:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200528/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200528/ took longer than 180.0 seconds..
2025-05-03 20:18:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200528/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200528/ took longer than 180.0 seconds..
2025-05-03 20:18:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200529/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200529/ took longer than 180.0 seconds..
2025-05-03 20:18:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200529/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200529/ took longer than 180.0 seconds..
2025-05-03 20:18:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200530/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200530/ took longer than 180.0 seconds..
2025-05-03 20:18:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200530/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200530/ took longer than 180.0 seconds..
2025-05-03 20:19:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:21:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200531/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200531/ took longer than 180.0 seconds..
2025-05-03 20:21:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200601/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200601/ took longer than 180.0 seconds..
2025-05-03 20:21:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200602/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200602/ took longer than 180.0 seconds..
2025-05-03 20:21:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200603/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200603/ took longer than 180.0 seconds..
2025-05-03 20:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:24:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200531/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200531/ took longer than 180.0 seconds..
2025-05-03 20:24:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200601/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200601/ took longer than 180.0 seconds..
2025-05-03 20:24:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200602/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200602/ took longer than 180.0 seconds..
2025-05-03 20:24:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200603/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200603/ took longer than 180.0 seconds..
2025-05-03 20:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:27:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200531/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200531/ took longer than 180.0 seconds..
2025-05-03 20:27:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200531/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200531/ took longer than 180.0 seconds..
2025-05-03 20:27:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200601/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200601/ took longer than 180.0 seconds..
2025-05-03 20:27:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200601/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200601/ took longer than 180.0 seconds..
2025-05-03 20:27:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200602/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200602/ took longer than 180.0 seconds..
2025-05-03 20:27:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200602/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200602/ took longer than 180.0 seconds..
2025-05-03 20:27:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200603/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200603/ took longer than 180.0 seconds..
2025-05-03 20:27:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200603/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200603/ took longer than 180.0 seconds..
2025-05-03 20:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:29:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:30:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200604/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200604/ took longer than 180.0 seconds..
2025-05-03 20:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200605/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200605/ took longer than 180.0 seconds..
2025-05-03 20:30:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200606/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200606/ took longer than 180.0 seconds..
2025-05-03 20:30:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200607/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200607/ took longer than 180.0 seconds..
2025-05-03 20:31:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:33:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200604/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200604/ took longer than 180.0 seconds..
2025-05-03 20:33:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200605/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200605/ took longer than 180.0 seconds..
2025-05-03 20:33:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200606/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200606/ took longer than 180.0 seconds..
2025-05-03 20:33:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200607/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200607/ took longer than 180.0 seconds..
2025-05-03 20:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:35:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:36:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200604/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200604/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200604/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200604/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200605/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200605/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200606/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200606/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200607/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200607/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200606/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200606/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200605/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200605/ took longer than 180.0 seconds..
2025-05-03 20:36:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200607/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200607/ took longer than 180.0 seconds..
2025-05-03 20:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:38:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:39:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:39:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200608/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200608/ took longer than 180.0 seconds..
2025-05-03 20:39:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200609/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200609/ took longer than 180.0 seconds..
2025-05-03 20:39:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200610/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200610/ took longer than 180.0 seconds..
2025-05-03 20:39:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200611/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200611/ took longer than 180.0 seconds..
2025-05-03 20:40:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:42:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200608/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200608/ took longer than 180.0 seconds..
2025-05-03 20:42:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200609/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200609/ took longer than 180.0 seconds..
2025-05-03 20:42:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200610/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200610/ took longer than 180.0 seconds..
2025-05-03 20:42:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200611/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200611/ took longer than 180.0 seconds..
2025-05-03 20:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:45:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:45:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200608/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200608/ took longer than 180.0 seconds..
2025-05-03 20:45:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200608/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200608/ took longer than 180.0 seconds..
2025-05-03 20:45:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200609/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200609/ took longer than 180.0 seconds..
2025-05-03 20:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200609/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200609/ took longer than 180.0 seconds..
2025-05-03 20:45:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200610/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200610/ took longer than 180.0 seconds..
2025-05-03 20:45:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200610/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200610/ took longer than 180.0 seconds..
2025-05-03 20:45:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200611/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200611/ took longer than 180.0 seconds..
2025-05-03 20:45:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200611/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200611/ took longer than 180.0 seconds..
2025-05-03 20:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:48:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200612/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200612/ took longer than 180.0 seconds..
2025-05-03 20:48:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200613/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200613/ took longer than 180.0 seconds..
2025-05-03 20:48:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200614/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200614/ took longer than 180.0 seconds..
2025-05-03 20:48:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200615/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200615/ took longer than 180.0 seconds..
2025-05-03 20:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:51:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200612/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200612/ took longer than 180.0 seconds..
2025-05-03 20:51:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200613/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200613/ took longer than 180.0 seconds..
2025-05-03 20:51:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200614/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200614/ took longer than 180.0 seconds..
2025-05-03 20:51:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200615/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200615/ took longer than 180.0 seconds..
2025-05-03 20:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:54:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200612/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200612/ took longer than 180.0 seconds..
2025-05-03 20:54:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200612/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200612/ took longer than 180.0 seconds..
2025-05-03 20:54:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200613/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200613/ took longer than 180.0 seconds..
2025-05-03 20:54:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200613/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200613/ took longer than 180.0 seconds..
2025-05-03 20:54:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200614/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200614/ took longer than 180.0 seconds..
2025-05-03 20:54:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200614/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200614/ took longer than 180.0 seconds..
2025-05-03 20:54:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200615/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200615/ took longer than 180.0 seconds..
2025-05-03 20:54:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200615/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200615/ took longer than 180.0 seconds..
2025-05-03 20:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:57:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200616/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200616/ took longer than 180.0 seconds..
2025-05-03 20:57:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200617/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200617/ took longer than 180.0 seconds..
2025-05-03 20:57:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200618/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200618/ took longer than 180.0 seconds..
2025-05-03 20:57:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200619/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200619/ took longer than 180.0 seconds..
2025-05-03 20:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 20:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:00:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200616/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200616/ took longer than 180.0 seconds..
2025-05-03 21:00:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200617/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200617/ took longer than 180.0 seconds..
2025-05-03 21:00:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200618/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200618/ took longer than 180.0 seconds..
2025-05-03 21:00:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200619/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200619/ took longer than 180.0 seconds..
2025-05-03 21:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:03:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:03:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200616/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200616/ took longer than 180.0 seconds..
2025-05-03 21:03:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200616/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200616/ took longer than 180.0 seconds..
2025-05-03 21:03:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200617/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200617/ took longer than 180.0 seconds..
2025-05-03 21:03:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200617/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200617/ took longer than 180.0 seconds..
2025-05-03 21:03:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200618/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200618/ took longer than 180.0 seconds..
2025-05-03 21:03:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200618/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200618/ took longer than 180.0 seconds..
2025-05-03 21:03:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200619/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200619/ took longer than 180.0 seconds..
2025-05-03 21:03:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200619/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200619/ took longer than 180.0 seconds..
2025-05-03 21:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:06:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:06:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200620/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200620/ took longer than 180.0 seconds..
2025-05-03 21:06:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200621/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200621/ took longer than 180.0 seconds..
2025-05-03 21:06:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200622/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200622/ took longer than 180.0 seconds..
2025-05-03 21:06:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200623/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200623/ took longer than 180.0 seconds..
2025-05-03 21:07:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:08:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:09:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200620/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200620/ took longer than 180.0 seconds..
2025-05-03 21:09:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200621/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200621/ took longer than 180.0 seconds..
2025-05-03 21:09:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200622/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200622/ took longer than 180.0 seconds..
2025-05-03 21:09:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200623/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200623/ took longer than 180.0 seconds..
2025-05-03 21:10:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:12:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200620/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200620/ took longer than 180.0 seconds..
2025-05-03 21:12:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200620/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200620/ took longer than 180.0 seconds..
2025-05-03 21:12:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200621/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200621/ took longer than 180.0 seconds..
2025-05-03 21:12:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200621/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200621/ took longer than 180.0 seconds..
2025-05-03 21:12:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200622/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200622/ took longer than 180.0 seconds..
2025-05-03 21:12:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200622/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200622/ took longer than 180.0 seconds..
2025-05-03 21:12:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200623/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200623/ took longer than 180.0 seconds..
2025-05-03 21:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200623/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200623/ took longer than 180.0 seconds..
2025-05-03 21:13:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:14:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:15:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:15:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200624/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200624/ took longer than 180.0 seconds..
2025-05-03 21:15:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200625/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200625/ took longer than 180.0 seconds..
2025-05-03 21:15:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200626/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200626/ took longer than 180.0 seconds..
2025-05-03 21:15:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200627/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200627/ took longer than 180.0 seconds..
2025-05-03 21:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:17:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:18:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:18:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200624/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200624/ took longer than 180.0 seconds..
2025-05-03 21:18:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200625/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200625/ took longer than 180.0 seconds..
2025-05-03 21:18:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200626/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200626/ took longer than 180.0 seconds..
2025-05-03 21:18:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200627/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200627/ took longer than 180.0 seconds..
2025-05-03 21:19:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:21:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200624/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200624/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200624/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200624/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200625/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200625/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200626/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200626/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200627/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200627/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200625/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200625/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200626/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200626/ took longer than 180.0 seconds..
2025-05-03 21:22:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200627/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200627/ took longer than 180.0 seconds..
2025-05-03 21:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:25:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200628/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-03 21:25:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200629/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-03 21:25:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200630/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-03 21:25:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200701/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-03 21:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:28:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200628/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-03 21:28:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200629/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-03 21:28:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200630/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-03 21:28:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200701/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-03 21:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:29:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:31:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200628/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-03 21:31:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200628/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-03 21:31:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200629/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-03 21:31:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200629/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-03 21:31:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200630/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-03 21:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200630/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-03 21:31:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200701/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-03 21:31:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200701/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-03 21:31:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200702/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-03 21:34:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200703/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-03 21:34:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200704/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-03 21:34:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200705/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-03 21:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:35:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:37:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200702/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-03 21:37:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200703/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-03 21:37:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200704/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-03 21:37:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200705/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-03 21:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:38:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:39:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:40:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200702/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-03 21:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200702/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-03 21:40:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200703/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-03 21:40:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200703/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-03 21:40:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200704/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-03 21:40:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200704/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-03 21:40:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200705/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-03 21:40:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200705/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-03 21:40:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:43:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200706/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-03 21:43:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200707/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-03 21:43:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200708/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-03 21:43:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200709/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-03 21:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:45:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:46:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200706/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-03 21:46:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200707/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-03 21:46:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200708/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-03 21:46:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200709/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-03 21:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:49:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200706/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-03 21:49:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200706/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-03 21:49:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200707/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-03 21:49:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200707/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-03 21:49:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200708/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-03 21:49:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200708/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-03 21:49:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200709/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-03 21:49:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200709/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-03 21:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:52:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200710/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-03 21:52:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200711/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-03 21:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200712/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-03 21:52:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200713/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-03 21:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:55:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200710/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-03 21:55:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200711/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-03 21:55:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200712/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-03 21:55:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200713/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-03 21:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:58:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200710/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-03 21:58:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200710/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-03 21:58:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200711/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-03 21:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200711/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-03 21:58:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200712/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-03 21:58:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200712/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-03 21:58:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200713/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-03 21:58:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200713/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-03 21:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 21:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:01:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200714/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-03 22:01:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200715/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-03 22:01:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200716/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-03 22:01:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200717/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-03 22:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:03:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:04:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200714/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-03 22:04:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200715/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-03 22:04:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200716/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-03 22:04:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200717/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-03 22:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:06:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:07:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200714/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200714/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200715/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200716/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200717/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200716/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200715/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-03 22:07:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200717/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-03 22:07:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:08:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:09:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:10:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200718/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-03 22:10:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200719/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-03 22:10:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200720/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-03 22:10:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200721/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-03 22:10:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:13:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200718/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-03 22:13:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200719/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-03 22:13:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200720/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-03 22:13:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200721/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-03 22:13:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:14:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:15:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:16:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200718/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-03 22:16:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200718/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-03 22:16:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200719/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-03 22:16:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200719/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-03 22:16:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200720/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-03 22:16:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200720/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-03 22:16:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200721/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-03 22:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200721/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-03 22:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:17:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:18:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:19:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200722/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-03 22:19:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200723/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-03 22:19:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200724/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-03 22:19:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200725/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-03 22:19:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:22:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200722/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-03 22:22:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200723/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-03 22:22:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200724/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-03 22:22:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200725/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-03 22:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:25:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200722/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-03 22:25:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200722/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-03 22:25:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200723/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-03 22:25:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200723/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-03 22:25:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200724/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-03 22:25:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200724/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-03 22:25:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200725/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-03 22:25:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200725/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-03 22:25:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:28:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200726/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-03 22:28:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200727/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-03 22:28:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200728/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-03 22:28:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200729/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-03 22:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:29:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:31:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200726/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-03 22:31:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200727/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-03 22:31:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200728/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-03 22:31:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200729/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-03 22:31:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:34:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200726/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-03 22:34:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200726/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-03 22:34:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200727/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-03 22:34:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200727/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-03 22:34:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200728/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-03 22:34:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200728/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-03 22:34:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200729/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-03 22:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200729/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-03 22:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:35:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:37:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200730/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-03 22:37:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200731/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-03 22:37:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200801/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-03 22:37:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200802/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-03 22:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:38:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:39:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:40:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200730/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-03 22:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200731/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-03 22:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200801/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-03 22:40:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200802/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-03 22:40:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:43:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200730/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-03 22:43:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200730/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-03 22:43:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200731/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-03 22:43:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200731/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-03 22:43:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200801/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-03 22:43:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200801/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-03 22:43:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200802/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-03 22:43:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200802/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-03 22:43:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:45:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:46:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200803/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-03 22:46:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200804/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-03 22:46:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200805/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-03 22:46:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200806/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-03 22:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:47:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:48:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:49:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200803/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-03 22:49:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200804/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-03 22:49:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200805/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-03 22:49:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200806/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-03 22:49:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:50:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:51:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:52:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200803/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200803/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200804/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200805/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200806/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200806/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200804/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-03 22:52:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200805/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-03 22:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:54:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:55:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200807/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-03 22:55:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200808/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-03 22:55:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200809/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-03 22:55:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:55:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200810/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-03 22:56:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:57:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:58:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200807/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-03 22:58:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200808/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-03 22:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 22:58:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200809/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-03 22:58:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200810/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-03 22:59:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:00:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:01:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200807/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-03 23:01:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200807/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-03 23:01:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200808/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-03 23:01:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200808/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-03 23:01:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:01:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200809/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-03 23:01:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200809/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-03 23:01:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200810/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-03 23:01:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200810/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-03 23:06:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-03 23:06:39 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-03 23:06:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-03 23:06:39 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-03 23:06:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 23:06:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 23:06:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-03 23:06:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-03 23:06:39 [scrapy.extensions.telnet] INFO: Telnet Password: b32b8508e9038119
2025-05-03 23:06:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-03 23:06:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-03 23:06:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-03 23:06:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-03 23:06:40 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-03 23:06:40 [scrapy.core.engine] INFO: Spider opened
2025-05-03 23:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:06:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-03 23:06:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:06:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:07:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200109/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200110/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200111/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200112/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200109/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200110/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200111/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:07:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200112/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200109/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200110/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200111/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200112/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200113/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200114/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200115/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200116/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200113/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200114/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200115/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200116/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200113/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200114/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200115/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200116/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:08:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200117/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200118/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200119/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200120/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200117/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:08:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200118/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200119/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200120/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200117/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200118/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200119/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200120/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200121/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200122/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200123/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200124/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200121/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200122/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200123/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200124/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200121/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200122/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200123/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:09:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200124/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200125/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200126/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200127/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200128/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200125/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200126/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:09:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200127/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200128/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200125/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200126/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200127/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200128/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200129/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200130/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200131/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200201/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200129/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200130/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200131/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200201/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200129/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200130/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200131/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200131/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:10:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200201/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200202/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200203/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200204/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200205/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200202/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200203/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:10:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200204/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200205/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200202/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200203/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200204/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200205/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200206/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200207/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200208/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200209/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200206/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200207/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200208/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200209/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200206/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:11:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200207/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200208/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200209/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200210/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200211/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200212/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:11:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200213/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200210/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200211/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200212/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200213/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200210/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200211/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200212/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200213/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200214/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200215/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200216/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200217/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200214/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200215/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200216/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200217/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200214/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200215/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:12:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200216/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200217/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200218/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200219/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200220/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200221/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200218/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:12:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200219/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200220/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200221/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200218/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200219/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200220/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200221/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200222/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200223/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200224/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200225/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200222/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200223/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200224/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200225/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200222/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200223/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:13:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200224/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:13:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200225/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200226/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200227/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200228/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200226/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200227/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200228/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200226/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200227/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200228/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-03 23:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:17:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 23:17:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 23:17:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 23:17:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 23:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:20:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 23:20:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 23:20:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 23:20:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 23:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:23:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200229/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 23:23:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200229/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200229/ took longer than 180.0 seconds..
2025-05-03 23:23:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200301/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 23:23:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200301/ took longer than 180.0 seconds..
2025-05-03 23:23:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200302/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 23:23:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200302/ took longer than 180.0 seconds..
2025-05-03 23:23:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200303/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 23:23:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200303/ took longer than 180.0 seconds..
2025-05-03 23:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:26:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 23:26:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 23:26:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 23:26:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 23:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:29:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 23:29:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 23:29:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 23:29:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 23:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:32:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200304/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 23:32:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200304/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200304/ took longer than 180.0 seconds..
2025-05-03 23:32:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200305/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 23:32:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200305/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200305/ took longer than 180.0 seconds..
2025-05-03 23:32:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200306/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 23:32:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200306/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200306/ took longer than 180.0 seconds..
2025-05-03 23:32:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200307/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 23:32:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200307/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200307/ took longer than 180.0 seconds..
2025-05-03 23:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:35:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200308/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 23:35:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200309/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 23:35:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200310/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 23:35:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200311/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 23:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200308/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 23:38:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200309/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 23:38:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200310/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 23:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200311/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 23:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:41:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200308/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 23:41:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200308/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200308/ took longer than 180.0 seconds..
2025-05-03 23:41:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200309/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 23:41:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200309/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200309/ took longer than 180.0 seconds..
2025-05-03 23:41:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200310/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 23:41:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200310/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200310/ took longer than 180.0 seconds..
2025-05-03 23:41:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200311/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 23:41:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200311/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200311/ took longer than 180.0 seconds..
2025-05-03 23:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:44:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200312/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 23:44:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200313/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 23:44:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200314/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 23:44:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200315/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 23:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:47:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200312/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 23:47:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200313/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 23:47:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200314/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 23:47:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200315/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 23:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:50:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200312/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 23:50:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200312/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200312/ took longer than 180.0 seconds..
2025-05-03 23:50:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200313/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 23:50:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200313/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200313/ took longer than 180.0 seconds..
2025-05-03 23:50:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200314/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 23:50:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200314/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200314/ took longer than 180.0 seconds..
2025-05-03 23:50:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200315/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 23:50:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200315/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200315/ took longer than 180.0 seconds..
2025-05-03 23:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:53:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200316/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 23:53:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200317/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 23:53:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200318/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 23:53:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200319/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 23:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:56:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200316/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 23:56:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200317/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 23:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200318/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 23:56:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200319/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 23:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-03 23:59:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200316/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 23:59:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200316/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200316/ took longer than 180.0 seconds..
2025-05-03 23:59:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200317/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 23:59:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200317/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200317/ took longer than 180.0 seconds..
2025-05-03 23:59:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200318/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 23:59:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200318/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200318/ took longer than 180.0 seconds..
2025-05-03 23:59:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200319/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 23:59:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200319/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200319/ took longer than 180.0 seconds..
2025-05-03 23:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:02:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200320/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-04 00:02:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200321/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-04 00:02:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200322/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-04 00:02:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200323/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-04 00:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:05:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200320/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-04 00:05:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200321/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-04 00:05:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200322/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-04 00:05:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200323/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-04 00:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:08:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200320/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-04 00:08:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200320/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200320/ took longer than 180.0 seconds..
2025-05-04 00:08:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200321/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-04 00:08:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200321/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200321/ took longer than 180.0 seconds..
2025-05-04 00:08:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200322/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-04 00:08:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200322/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200322/ took longer than 180.0 seconds..
2025-05-04 00:08:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200323/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-04 00:08:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200323/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200323/ took longer than 180.0 seconds..
2025-05-04 00:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:11:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200324/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-04 00:11:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200325/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-04 00:11:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200326/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-04 00:11:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200327/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-04 00:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:14:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200324/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-04 00:14:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200325/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-04 00:14:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200326/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-04 00:14:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200327/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-04 00:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:17:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200324/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-04 00:17:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200324/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200324/ took longer than 180.0 seconds..
2025-05-04 00:17:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200325/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-04 00:17:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200325/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200325/ took longer than 180.0 seconds..
2025-05-04 00:17:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200326/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-04 00:17:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200326/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200326/ took longer than 180.0 seconds..
2025-05-04 00:17:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200327/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-04 00:17:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200327/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200327/ took longer than 180.0 seconds..
2025-05-04 00:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:20:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200328/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-04 00:20:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200329/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-04 00:20:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200330/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-04 00:20:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200331/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-04 00:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:23:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200328/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-04 00:23:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200329/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-04 00:23:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200330/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-04 00:23:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200331/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-04 00:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:26:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200328/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-04 00:26:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200328/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200328/ took longer than 180.0 seconds..
2025-05-04 00:26:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200329/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-04 00:26:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200329/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200329/ took longer than 180.0 seconds..
2025-05-04 00:26:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200330/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-04 00:26:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200330/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200330/ took longer than 180.0 seconds..
2025-05-04 00:26:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200331/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-04 00:26:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200331/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200331/ took longer than 180.0 seconds..
2025-05-04 00:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:29:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200401/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-04 00:29:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200402/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-04 00:29:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200403/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-04 00:29:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200404/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-04 00:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:32:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200401/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-04 00:32:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200402/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-04 00:32:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200403/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-04 00:32:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200404/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-04 00:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:35:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200401/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-04 00:35:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200401/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200401/ took longer than 180.0 seconds..
2025-05-04 00:35:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200402/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-04 00:35:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200402/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200402/ took longer than 180.0 seconds..
2025-05-04 00:35:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200403/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-04 00:35:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200403/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200403/ took longer than 180.0 seconds..
2025-05-04 00:35:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200404/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-04 00:35:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200404/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200404/ took longer than 180.0 seconds..
2025-05-04 00:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:38:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200405/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-04 00:38:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200406/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-04 00:38:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200407/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-04 00:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200408/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-04 00:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:41:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200405/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-04 00:41:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200406/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-04 00:41:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200407/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-04 00:41:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200408/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-04 00:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:44:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200405/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-04 00:44:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200405/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200405/ took longer than 180.0 seconds..
2025-05-04 00:44:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200406/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-04 00:44:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200407/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-04 00:44:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200407/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200407/ took longer than 180.0 seconds..
2025-05-04 00:44:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200406/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200406/ took longer than 180.0 seconds..
2025-05-04 00:44:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200408/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-04 00:44:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200408/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200408/ took longer than 180.0 seconds..
2025-05-04 00:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:47:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200409/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-04 00:47:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200410/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-04 00:47:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200411/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-04 00:47:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200412/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-04 00:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:50:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200409/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-04 00:50:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200410/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-04 00:50:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200411/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-04 00:50:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200412/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-04 00:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:53:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200409/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-04 00:53:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200409/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200409/ took longer than 180.0 seconds..
2025-05-04 00:53:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200410/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-04 00:53:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200410/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200410/ took longer than 180.0 seconds..
2025-05-04 00:53:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200411/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-04 00:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200411/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200411/ took longer than 180.0 seconds..
2025-05-04 00:53:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200412/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-04 00:53:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200412/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200412/ took longer than 180.0 seconds..
2025-05-04 00:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:56:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200413/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-04 00:56:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200414/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-04 00:56:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200415/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-04 00:56:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200416/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-04 00:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 00:59:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200413/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-04 00:59:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200414/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-04 00:59:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200415/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-04 00:59:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200416/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-04 00:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:02:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200413/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-04 01:02:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200413/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200413/ took longer than 180.0 seconds..
2025-05-04 01:02:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200414/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-04 01:02:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200414/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200414/ took longer than 180.0 seconds..
2025-05-04 01:02:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200415/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-04 01:02:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200415/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200415/ took longer than 180.0 seconds..
2025-05-04 01:02:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200416/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-04 01:02:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200416/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200416/ took longer than 180.0 seconds..
2025-05-04 01:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:05:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200417/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-04 01:05:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200418/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-04 01:05:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200419/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-04 01:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200420/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-04 01:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:08:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200417/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-04 01:08:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200418/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-04 01:08:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200419/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-04 01:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200420/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-04 01:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:11:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200417/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-04 01:11:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200417/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200417/ took longer than 180.0 seconds..
2025-05-04 01:11:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200418/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-04 01:11:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200418/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200418/ took longer than 180.0 seconds..
2025-05-04 01:11:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200419/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-04 01:11:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200419/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200419/ took longer than 180.0 seconds..
2025-05-04 01:11:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200420/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-04 01:11:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200420/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200420/ took longer than 180.0 seconds..
2025-05-04 01:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:14:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200421/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-04 01:14:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200422/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-04 01:14:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200423/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-04 01:14:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200424/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-04 01:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:17:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200421/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-04 01:17:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200422/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-04 01:17:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200423/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-04 01:17:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200424/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-04 01:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:20:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200421/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-04 01:20:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200421/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200421/ took longer than 180.0 seconds..
2025-05-04 01:20:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200422/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-04 01:20:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200422/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200422/ took longer than 180.0 seconds..
2025-05-04 01:20:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200423/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-04 01:20:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200423/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200423/ took longer than 180.0 seconds..
2025-05-04 01:20:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200424/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-04 01:20:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200424/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200424/ took longer than 180.0 seconds..
2025-05-04 01:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:23:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200425/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-04 01:23:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200426/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-04 01:23:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200427/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-04 01:23:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200428/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-04 01:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:26:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200425/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-04 01:26:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200426/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-04 01:26:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200427/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-04 01:26:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200428/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-04 01:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:29:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200425/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200425/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200425/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200426/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200427/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200428/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:29:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200427/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200427/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200428/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200428/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200426/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200426/ took longer than 180.0 seconds..
2025-05-04 01:29:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200429%2f&_ordtok=7hk3WVZkSnj6DV4Frqnt5V2HNr> from <GET https://www.tianqi.com//tianqi/wuhan/20200429/>
2025-05-04 01:29:44 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'gateway.zscloud.net': <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200429%2f&_ordtok=7hk3WVZkSnj6DV4Frqnt5V2HNr>
2025-05-04 01:29:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200430%2f&_ordtok=DNZ3WVLnkQWW6f0JFMf5JRtZM7> from <GET https://www.tianqi.com//tianqi/wuhan/20200430/>
2025-05-04 01:29:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200501%2f&_ordtok=DrW3WVLDmShSMLTQcjQ6M47jSP> from <GET https://www.tianqi.com//tianqi/wuhan/20200501/>
2025-05-04 01:29:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200502%2f&_ordtok=66W3WVLNM4q3JS7058kHFTDHnM> from <GET https://www.tianqi.com//tianqi/wuhan/20200502/>
2025-05-04 01:29:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200503%2f&_ordtok=VZk3WVFSbqH2H0pfqkqDWr6jjQ> from <GET https://www.tianqi.com//tianqi/wuhan/20200503/>
2025-05-04 01:29:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200504%2f&_ordtok=SP43WVhFRb7KjnjsH0sjsq3VnQ> from <GET https://www.tianqi.com//tianqi/wuhan/20200504/>
2025-05-04 01:29:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200505%2f&_ordtok=VDW3WVFSBHSMHJ6q13R1D36DPH> from <GET https://www.tianqi.com//tianqi/wuhan/20200505/>
2025-05-04 01:30:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200506%2f&_ordtok=HkZ3WVLkS47F5Q0JrJsRVpSfpP> from <GET https://www.tianqi.com//tianqi/wuhan/20200506/>
2025-05-04 01:30:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200507%2f&_ordtok=jbW3WVF5WBh25ZRQFPT5jrtvjj> from <GET https://www.tianqi.com//tianqi/wuhan/20200507/>
2025-05-04 01:30:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200508%2f&_ordtok=JWW3WVLZ32LKF1NfQfVt0MlRFF> from <GET https://www.tianqi.com//tianqi/wuhan/20200508/>
2025-05-04 01:30:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200509%2f&_ordtok=RDZ3WVZR0HR6nw225w7sVsNv7M> from <GET https://www.tianqi.com//tianqi/wuhan/20200509/>
2025-05-04 01:30:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200510%2f&_ordtok=4Wk3WVLs5VrkP4mVMkPk5r7pmB> from <GET https://www.tianqi.com//tianqi/wuhan/20200510/>
2025-05-04 01:30:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200511%2f&_ordtok=n0Z3WV5mJF32qs0HPZsgDt665T> from <GET https://www.tianqi.com//tianqi/wuhan/20200511/>
2025-05-04 01:30:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200512%2f&_ordtok=VM43WV3SMSMVHNjPn2r765zfgs> from <GET https://www.tianqi.com//tianqi/wuhan/20200512/>
2025-05-04 01:30:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200513%2f&_ordtok=0RW3WVhr75ZNPPMfr44MqVkvkM> from <GET https://www.tianqi.com//tianqi/wuhan/20200513/>
2025-05-04 01:30:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200514%2f&_ordtok=Bmk3WVhDh53BJP4WRZPqF0FMsr> from <GET https://www.tianqi.com//tianqi/wuhan/20200514/>
2025-05-04 01:30:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200515%2f&_ordtok=LPk3WV3WVD4hMjN7WHsLJVkpL3> from <GET https://www.tianqi.com//tianqi/wuhan/20200515/>
2025-05-04 01:30:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200516%2f&_ordtok=VqW3WVh7S6P4jRDr3qDr1bbsWj> from <GET https://www.tianqi.com//tianqi/wuhan/20200516/>
2025-05-04 01:30:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200517%2f&_ordtok=RN43WVqnbHJrHqJpjRDSZK8VKj> from <GET https://www.tianqi.com//tianqi/wuhan/20200517/>
2025-05-04 01:30:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200518%2f&_ordtok=3hk3WV5SsD7sMvj2nJQ67NQrBr> from <GET https://www.tianqi.com//tianqi/wuhan/20200518/>
2025-05-04 01:30:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200519%2f&_ordtok=KSW3WVF0qNhbHJ75qrQ73RZtLq> from <GET https://www.tianqi.com//tianqi/wuhan/20200519/>
2025-05-04 01:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:30:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200520%2f&_ordtok=HRk3WVZF3LWjFz2Mk4FN7W73Fj> from <GET https://www.tianqi.com//tianqi/wuhan/20200520/>
2025-05-04 01:30:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200521%2f&_ordtok=BRk3WVhK3NrHNfJWjfPSP3Sjn5> from <GET https://www.tianqi.com//tianqi/wuhan/20200521/>
2025-05-04 01:30:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200522%2f&_ordtok=FRk3WV5h4NF3FNfRbSJKJsb6ST> from <GET https://www.tianqi.com//tianqi/wuhan/20200522/>
2025-05-04 01:30:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200523%2f&_ordtok=LJk3WVFJ2r5FnqHJ0M8NpLZjj3> from <GET https://www.tianqi.com//tianqi/wuhan/20200523/>
2025-05-04 01:30:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200524%2f&_ordtok=R7Z3WV3SNR2hQ120Z16SjWft7M> from <GET https://www.tianqi.com//tianqi/wuhan/20200524/>
2025-05-04 01:30:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200525%2f&_ordtok=SSW3WV333Zj6sF1Pq78kfSfLHM> from <GET https://www.tianqi.com//tianqi/wuhan/20200525/>
2025-05-04 01:30:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200526%2f&_ordtok=W443WV5Ks2BKQRR62Nqq7VR3SH> from <GET https://www.tianqi.com//tianqi/wuhan/20200526/>
2025-05-04 01:30:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200527%2f&_ordtok=WWZ3WVLWqDWP6fS0S3m6D315PT> from <GET https://www.tianqi.com//tianqi/wuhan/20200527/>
2025-05-04 01:31:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200528%2f&_ordtok=VK43WVZQQL6m5lsS266b5BJBRH> from <GET https://www.tianqi.com//tianqi/wuhan/20200528/>
2025-05-04 01:31:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200529%2f&_ordtok=sBW3WV5rqNN0qPB1044JS0Pr26> from <GET https://www.tianqi.com//tianqi/wuhan/20200529/>
2025-05-04 01:31:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200530%2f&_ordtok=MQW3WVRP7JMSFWTFJMst10FR1j> from <GET https://www.tianqi.com//tianqi/wuhan/20200530/>
2025-05-04 01:31:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200531%2f&_ordtok=m243WV5mZFF0JMNvHfPkHT5stP> from <GET https://www.tianqi.com//tianqi/wuhan/20200531/>
2025-05-04 01:31:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200601%2f&_ordtok=RFW3WV37VR7MNRsJ990sKVKKsj> from <GET https://www.tianqi.com//tianqi/wuhan/20200601/>
2025-05-04 01:31:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200602%2f&_ordtok=44W3WV5DPjSVMMTZdN2RWtsjs2> from <GET https://www.tianqi.com//tianqi/wuhan/20200602/>
2025-05-04 01:31:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200603%2f&_ordtok=rKW3WV5jDbjQRQVTH45RHwM4QM> from <GET https://www.tianqi.com//tianqi/wuhan/20200603/>
2025-05-04 01:31:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200604%2f&_ordtok=Hkk3WVR0Fk2DM6dRSWkHJBfj0Q> from <GET https://www.tianqi.com//tianqi/wuhan/20200604/>
2025-05-04 01:31:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200605%2f&_ordtok=6J43WVqBn5kMJjw7Nf6tftnnNQ> from <GET https://www.tianqi.com//tianqi/wuhan/20200605/>
2025-05-04 01:31:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200606%2f&_ordtok=Kqk3WVFNHkbDqP6QF7cW3vF2VJ> from <GET https://www.tianqi.com//tianqi/wuhan/20200606/>
2025-05-04 01:31:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200607%2f&_ordtok=HS43WV3Z6sbVsSt2NDPVJtHtnH> from <GET https://www.tianqi.com//tianqi/wuhan/20200607/>
2025-05-04 01:31:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200608%2f&_ordtok=RNZ3WVhs5NhnrGRGkKQf10H4kF> from <GET https://www.tianqi.com//tianqi/wuhan/20200608/>
2025-05-04 01:31:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200609%2f&_ordtok=MR43WVZM55W3rJrqf616S8FqZP> from <GET https://www.tianqi.com//tianqi/wuhan/20200609/>
2025-05-04 01:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:31:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200610%2f&_ordtok=46Z3WVF76WsDJF17Tv14H0vFkM> from <GET https://www.tianqi.com//tianqi/wuhan/20200610/>
2025-05-04 01:31:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200611%2f&_ordtok=QS43WVL6MFrqJ3SWM4MjZFF7NH> from <GET https://www.tianqi.com//tianqi/wuhan/20200611/>
2025-05-04 01:31:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200612%2f&_ordtok=J2Z3WV5M2hb3nTDf180J5NRJ1n> from <GET https://www.tianqi.com//tianqi/wuhan/20200612/>
2025-05-04 01:31:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200613%2f&_ordtok=bHZ3WV3jDbF76KfZbMrbHkG5TN> from <GET https://www.tianqi.com//tianqi/wuhan/20200613/>
2025-05-04 01:31:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200614%2f&_ordtok=7q43WV5HQD6Rn1SNkq8sDSP0NR> from <GET https://www.tianqi.com//tianqi/wuhan/20200614/>
2025-05-04 01:31:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200615%2f&_ordtok=LBk3WVhWZqS3njLJQ3QnDkD3j6> from <GET https://www.tianqi.com//tianqi/wuhan/20200615/>
2025-05-04 01:31:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200616%2f&_ordtok=7j43WVFZBF265kRZLFQqnVND8s> from <GET https://www.tianqi.com//tianqi/wuhan/20200616/>
2025-05-04 01:31:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200617%2f&_ordtok=kRW3WVhnFQZSDqJt4qkBt5kFVQ> from <GET https://www.tianqi.com//tianqi/wuhan/20200617/>
2025-05-04 01:32:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200618%2f&_ordtok=HR43WVRL6mS76qD37rNZVr044w> from <GET https://www.tianqi.com//tianqi/wuhan/20200618/>
2025-05-04 01:32:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200619%2f&_ordtok=n5W3WV3bKrJMJ0SMHqv3sNM24N> from <GET https://www.tianqi.com//tianqi/wuhan/20200619/>
2025-05-04 01:32:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200620%2f&_ordtok=nHW3WVR3S2VrR65NM1FSJQQkJr> from <GET https://www.tianqi.com//tianqi/wuhan/20200620/>
2025-05-04 01:32:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200621%2f&_ordtok=ZDW3WV5P2ZKjDLjpKPj8QrPKpM> from <GET https://www.tianqi.com//tianqi/wuhan/20200621/>
2025-05-04 01:32:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200622%2f&_ordtok=N243WVqRMbQPqHLSrK1Qrvb50r> from <GET https://www.tianqi.com//tianqi/wuhan/20200622/>
2025-05-04 01:32:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200623%2f&_ordtok=QrZ3WVFkM345R0V7GHtSjk70NP> from <GET https://www.tianqi.com//tianqi/wuhan/20200623/>
2025-05-04 01:32:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200624%2f&_ordtok=kJZ3WVLS5PP6stpqtv0FSnWr5n> from <GET https://www.tianqi.com//tianqi/wuhan/20200624/>
2025-05-04 01:32:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200625%2f&_ordtok=LD43WVRP2b24qH5JBqjM3qM53F> from <GET https://www.tianqi.com//tianqi/wuhan/20200625/>
2025-05-04 01:32:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200626%2f&_ordtok=4nW3WVRmJs22JnTQFWnSV6qFd3> from <GET https://www.tianqi.com//tianqi/wuhan/20200626/>
2025-05-04 01:32:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200627%2f&_ordtok=Jn43WV3hhNBNRj6ppFjdstZ8q5> from <GET https://www.tianqi.com//tianqi/wuhan/20200627/>
2025-05-04 01:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:35:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200628/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-04 01:35:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200629/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-04 01:35:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200630/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-04 01:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:35:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200701/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-04 01:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200628/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-04 01:38:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200629/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-04 01:38:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200630/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-04 01:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:38:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200701/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-04 01:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:41:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200628/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-04 01:41:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200628/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200628/ took longer than 180.0 seconds..
2025-05-04 01:41:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200629/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-04 01:41:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200629/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200629/ took longer than 180.0 seconds..
2025-05-04 01:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:41:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200630/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-04 01:41:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200630/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200630/ took longer than 180.0 seconds..
2025-05-04 01:41:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200701/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-04 01:41:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200701/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200701/ took longer than 180.0 seconds..
2025-05-04 01:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:44:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200702/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-04 01:44:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200703/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-04 01:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:44:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200704/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-04 01:44:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200705/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-04 01:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:47:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200702/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-04 01:47:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200703/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-04 01:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:47:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200704/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-04 01:47:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200705/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-04 01:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:50:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200702/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-04 01:50:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200702/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200702/ took longer than 180.0 seconds..
2025-05-04 01:50:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200703/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-04 01:50:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200703/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200703/ took longer than 180.0 seconds..
2025-05-04 01:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:50:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200704/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-04 01:50:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200704/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200704/ took longer than 180.0 seconds..
2025-05-04 01:50:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200705/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-04 01:50:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200705/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200705/ took longer than 180.0 seconds..
2025-05-04 01:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:53:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200706/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-04 01:53:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200707/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-04 01:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:53:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200708/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-04 01:53:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200709/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-04 01:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:56:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200706/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-04 01:56:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200707/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-04 01:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:56:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200708/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-04 01:56:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200709/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-04 01:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:59:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200706/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-04 01:59:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200706/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200706/ took longer than 180.0 seconds..
2025-05-04 01:59:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200707/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-04 01:59:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200707/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200707/ took longer than 180.0 seconds..
2025-05-04 01:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 01:59:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200708/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-04 01:59:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200708/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200708/ took longer than 180.0 seconds..
2025-05-04 01:59:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200709/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-04 01:59:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200709/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200709/ took longer than 180.0 seconds..
2025-05-04 02:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200710/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-04 02:02:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200711/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-04 02:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:02:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200712/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-04 02:02:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200713/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-04 02:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:05:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200710/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-04 02:05:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200711/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-04 02:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:05:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200712/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-04 02:05:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200713/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-04 02:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:08:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200710/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-04 02:08:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200710/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200710/ took longer than 180.0 seconds..
2025-05-04 02:08:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200711/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-04 02:08:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200711/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200711/ took longer than 180.0 seconds..
2025-05-04 02:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:08:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200712/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-04 02:08:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200712/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200712/ took longer than 180.0 seconds..
2025-05-04 02:08:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200713/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-04 02:08:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200713/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200713/ took longer than 180.0 seconds..
2025-05-04 02:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:11:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200714/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-04 02:11:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200715/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-04 02:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:11:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200716/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-04 02:11:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200717/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-04 02:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:14:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200714/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-04 02:14:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200715/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-04 02:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:14:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200716/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-04 02:14:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200717/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-04 02:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:17:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200714/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200714/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200714/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200715/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:17:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200716/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200717/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200715/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200715/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200716/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200716/ took longer than 180.0 seconds..
2025-05-04 02:17:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200717/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200717/ took longer than 180.0 seconds..
2025-05-04 02:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:20:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200718/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-04 02:20:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200719/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-04 02:20:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200720/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-04 02:20:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200721/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-04 02:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:23:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200718/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-04 02:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200719/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-04 02:23:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200720/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-04 02:23:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200721/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-04 02:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:26:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200718/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-04 02:26:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200718/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200718/ took longer than 180.0 seconds..
2025-05-04 02:26:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200719/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-04 02:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200719/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200719/ took longer than 180.0 seconds..
2025-05-04 02:26:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200720/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-04 02:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200720/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200720/ took longer than 180.0 seconds..
2025-05-04 02:26:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200721/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-04 02:26:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200721/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200721/ took longer than 180.0 seconds..
2025-05-04 02:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:29:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200722/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-04 02:29:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200723/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-04 02:29:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200724/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-04 02:29:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200725/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-04 02:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:32:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200722/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-04 02:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200723/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-04 02:32:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200724/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-04 02:32:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200725/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-04 02:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:35:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200722/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-04 02:35:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200722/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200722/ took longer than 180.0 seconds..
2025-05-04 02:35:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200723/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-04 02:35:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200723/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200723/ took longer than 180.0 seconds..
2025-05-04 02:35:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200724/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-04 02:35:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200724/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200724/ took longer than 180.0 seconds..
2025-05-04 02:35:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200725/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-04 02:35:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200725/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200725/ took longer than 180.0 seconds..
2025-05-04 02:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:38:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200726/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-04 02:38:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200727/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-04 02:38:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200728/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-04 02:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200729/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-04 02:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:41:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200726/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-04 02:41:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200727/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-04 02:41:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200728/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-04 02:41:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200729/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-04 02:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:44:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200726/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-04 02:44:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200726/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200726/ took longer than 180.0 seconds..
2025-05-04 02:44:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200727/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-04 02:44:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200727/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200727/ took longer than 180.0 seconds..
2025-05-04 02:44:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200728/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-04 02:44:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200728/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200728/ took longer than 180.0 seconds..
2025-05-04 02:44:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200729/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-04 02:44:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200729/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200729/ took longer than 180.0 seconds..
2025-05-04 02:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:47:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200730/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-04 02:47:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200731/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-04 02:47:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200801/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-04 02:47:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200802/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-04 02:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:50:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200730/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-04 02:50:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200731/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-04 02:50:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200801/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-04 02:50:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200802/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-04 02:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:53:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200730/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-04 02:53:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200730/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200730/ took longer than 180.0 seconds..
2025-05-04 02:53:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200731/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-04 02:53:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200731/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200731/ took longer than 180.0 seconds..
2025-05-04 02:53:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200801/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-04 02:53:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200801/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200801/ took longer than 180.0 seconds..
2025-05-04 02:53:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200802/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-04 02:53:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200802/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200802/ took longer than 180.0 seconds..
2025-05-04 02:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:56:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200803/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-04 02:56:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200804/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-04 02:56:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200805/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-04 02:56:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200806/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-04 02:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 02:59:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200803/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-04 02:59:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200804/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-04 02:59:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200805/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-04 02:59:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200806/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-04 03:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:02:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200803/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200803/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200803/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200804/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200805/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200806/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200804/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200804/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200805/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200805/ took longer than 180.0 seconds..
2025-05-04 03:02:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200806/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200806/ took longer than 180.0 seconds..
2025-05-04 03:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:05:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200807/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-04 03:05:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200808/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-04 03:06:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200809/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-04 03:06:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200810/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-04 03:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:08:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200807/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-04 03:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200808/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-04 03:09:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200809/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-04 03:09:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200810/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-04 03:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:11:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200807/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-04 03:11:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200807/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200807/ took longer than 180.0 seconds..
2025-05-04 03:11:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200808/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-04 03:11:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200808/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200808/ took longer than 180.0 seconds..
2025-05-04 03:12:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200809/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-04 03:12:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200809/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200809/ took longer than 180.0 seconds..
2025-05-04 03:12:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200810/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-04 03:12:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200810/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200810/ took longer than 180.0 seconds..
2025-05-04 03:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:14:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200811/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200811/ took longer than 180.0 seconds..
2025-05-04 03:14:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200812/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200812/ took longer than 180.0 seconds..
2025-05-04 03:15:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200813/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200813/ took longer than 180.0 seconds..
2025-05-04 03:15:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200814/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200814/ took longer than 180.0 seconds..
2025-05-04 03:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:17:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200811/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200811/ took longer than 180.0 seconds..
2025-05-04 03:17:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200812/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200812/ took longer than 180.0 seconds..
2025-05-04 03:18:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200813/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200813/ took longer than 180.0 seconds..
2025-05-04 03:18:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200814/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200814/ took longer than 180.0 seconds..
2025-05-04 03:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:20:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200811/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200811/ took longer than 180.0 seconds..
2025-05-04 03:20:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200811/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200811/ took longer than 180.0 seconds..
2025-05-04 03:20:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200812/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200812/ took longer than 180.0 seconds..
2025-05-04 03:20:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200812/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200812/ took longer than 180.0 seconds..
2025-05-04 03:21:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200813/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200813/ took longer than 180.0 seconds..
2025-05-04 03:21:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200813/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200813/ took longer than 180.0 seconds..
2025-05-04 03:21:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200814/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200814/ took longer than 180.0 seconds..
2025-05-04 03:21:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200814/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200814/ took longer than 180.0 seconds..
2025-05-04 03:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200815/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200815/ took longer than 180.0 seconds..
2025-05-04 03:23:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200816/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200816/ took longer than 180.0 seconds..
2025-05-04 03:24:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200817/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200817/ took longer than 180.0 seconds..
2025-05-04 03:24:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200818/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200818/ took longer than 180.0 seconds..
2025-05-04 03:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:26:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200815/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200815/ took longer than 180.0 seconds..
2025-05-04 03:26:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200816/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200816/ took longer than 180.0 seconds..
2025-05-04 03:27:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200817/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200817/ took longer than 180.0 seconds..
2025-05-04 03:27:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200818/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200818/ took longer than 180.0 seconds..
2025-05-04 03:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:29:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200815/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200815/ took longer than 180.0 seconds..
2025-05-04 03:29:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200815/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200815/ took longer than 180.0 seconds..
2025-05-04 03:29:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200816/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200816/ took longer than 180.0 seconds..
2025-05-04 03:29:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200816/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200816/ took longer than 180.0 seconds..
2025-05-04 03:30:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200817/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200817/ took longer than 180.0 seconds..
2025-05-04 03:30:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200817/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200817/ took longer than 180.0 seconds..
2025-05-04 03:30:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200818/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200818/ took longer than 180.0 seconds..
2025-05-04 03:30:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200818/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200818/ took longer than 180.0 seconds..
2025-05-04 03:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:32:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200819/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200819/ took longer than 180.0 seconds..
2025-05-04 03:32:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200820/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200820/ took longer than 180.0 seconds..
2025-05-04 03:33:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200821/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200821/ took longer than 180.0 seconds..
2025-05-04 03:33:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200822/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200822/ took longer than 180.0 seconds..
2025-05-04 03:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:35:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200819/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200819/ took longer than 180.0 seconds..
2025-05-04 03:35:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200819/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:35:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200819/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:35:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200823/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:35:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200820/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200820/ took longer than 180.0 seconds..
2025-05-04 03:36:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200823/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200821/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200821/ took longer than 180.0 seconds..
2025-05-04 03:36:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200820/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200820/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200822/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20200822/ took longer than 180.0 seconds..
2025-05-04 03:36:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200823/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200823/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200821/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200821/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200824/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200822/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200822/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200825/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200826/> (failed 1 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200824/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200827/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:36:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200825/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:36:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200826/> (failed 2 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200824/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200824/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200827/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:36:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200825/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200825/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200826/> (failed 3 times): Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200826/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 220.243.154.49:11267 [{'status': 403, 'reason': b'Forbidden'}]
2025-05-04 03:36:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200828/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200827/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200827/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200829/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200830/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200828/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200831/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200829/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200830/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200828/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200828/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200831/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200829/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200829/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200830/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200830/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200901/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200831/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200831/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200902/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200903/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200901/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200904/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:37:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200902/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200903/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200901/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200901/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200904/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200902/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200902/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200903/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200903/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200905/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200904/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:37:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200904/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200906/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200907/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200905/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200908/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200906/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200907/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200905/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200905/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200908/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200906/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200906/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200907/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200907/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200909/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200908/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200908/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200910/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200911/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200909/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200912/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200910/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:38:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200911/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200909/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200909/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200912/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200910/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200910/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200911/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200911/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200913/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:38:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200912/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200914/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200912/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200915/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200913/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200916/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200914/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200915/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200913/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200913/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200916/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200914/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200914/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200915/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200915/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200917/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200916/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200916/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200918/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200919/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:39:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200917/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200920/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200918/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200919/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200917/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200917/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200920/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200918/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200918/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200919/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:39:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200919/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200921/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200920/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200920/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200922/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200923/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200921/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200924/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200922/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200923/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200921/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200921/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200924/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200922/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200922/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200923/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200923/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200925/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200924/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200924/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200926/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200927/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:40:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200925/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200928/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200926/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200927/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200925/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200925/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200928/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200926/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200926/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200927/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200927/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200929/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200928/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200928/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200930/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201001/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200929/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201002/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200930/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201001/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200929/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200929/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201002/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200930/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200930/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201001/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201001/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201003/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201002/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201002/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:41:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201004/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201005/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201003/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201006/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201004/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201005/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201003/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:41:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201003/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201006/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201004/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201004/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201005/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201005/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201007/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201006/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201006/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201008/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201009/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201007/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201010/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201008/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201009/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201007/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201007/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201010/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201008/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201008/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201009/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201009/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:42:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201011/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201010/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201010/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201012/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201013/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201011/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201014/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201012/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:42:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201013/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201011/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201011/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201014/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201012/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201012/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201013/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201013/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201015/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201014/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201014/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201016/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201017/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201015/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201018/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201016/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201017/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201015/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201015/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201018/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201016/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201016/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201017/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201017/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:43:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201019/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201018/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201018/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201020/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201021/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201019/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201022/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201020/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:43:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201021/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201019/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201019/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201022/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201020/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201020/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201021/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201021/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201023/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201022/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201022/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201024/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201025/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201023/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201026/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:44:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201024/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201025/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201023/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201023/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201026/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201024/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201024/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201025/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201025/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201027/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201026/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:44:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201026/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201028/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201029/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201027/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201030/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201028/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201029/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201027/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201027/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201030/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201028/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201028/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201029/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201029/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201031/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201030/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201030/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201101/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201102/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201031/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201103/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:45:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201101/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201102/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201031/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201031/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201103/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201101/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201102/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201104/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201103/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:45:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201105/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201106/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201104/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201107/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201105/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201106/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201104/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201107/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201105/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201106/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201108/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201107/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201109/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201110/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201108/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201111/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201109/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201110/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201108/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:46:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201111/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201109/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201110/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201112/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:46:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201111/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201113/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201114/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201112/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201115/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201113/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201114/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201112/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201115/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201113/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201114/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201116/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201115/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201117/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201118/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201116/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201119/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:47:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201117/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201118/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201116/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201119/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201117/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201118/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201120/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201119/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:47:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201121/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201122/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201120/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201123/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201121/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201122/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201120/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201123/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201121/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201122/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201124/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201123/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201125/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201126/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201124/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201127/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:48:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201125/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201126/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201124/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201127/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201125/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201126/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201128/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201127/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:48:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201129/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201130/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201128/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201201/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201129/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201130/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201128/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201201/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201129/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201130/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201202/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201201/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:49:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201203/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201204/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201202/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201205/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201203/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201204/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201202/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:49:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201205/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201203/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201204/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201206/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201205/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201207/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201208/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201206/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201209/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201207/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201208/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201206/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201209/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201207/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201208/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201210/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201209/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:50:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201211/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201212/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201210/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201213/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201211/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201212/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201210/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:50:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201213/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201211/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201212/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201214/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201213/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201215/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201216/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201214/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201217/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201215/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201216/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201214/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201217/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201215/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201216/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201218/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201217/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201219/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:51:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201220/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201218/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201221/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201219/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201220/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201218/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201221/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201219/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201220/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201222/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201221/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201223/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201224/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201222/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201225/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201223/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201224/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201222/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201225/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201223/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:52:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201224/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 03:52:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201226/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201225/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201227/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201228/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201226/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201229/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:52:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201227/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201228/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201226/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201229/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201227/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201228/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201230/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201229/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201229/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201231/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210101/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201230/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210102/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20201231/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210101/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201230/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201230/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210102/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20201231/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20201231/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210101/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:53:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210103/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210102/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210104/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210105/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210103/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210106/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210104/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:53:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210105/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210103/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210106/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210104/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210105/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210107/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210106/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210108/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210109/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210107/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210110/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210108/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210109/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210107/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210110/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210108/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210109/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210111/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:54:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210110/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210112/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210113/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210111/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:54:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210114/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210112/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210113/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210111/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210114/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210112/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210113/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210115/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210114/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210116/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210117/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210115/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210118/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210116/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210117/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210115/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210118/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:55:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210116/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210117/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210119/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210118/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210120/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210121/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210119/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210122/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:55:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210120/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210121/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210119/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210122/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210120/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210121/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210123/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210122/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210124/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210125/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210123/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210126/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210124/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210125/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210123/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210126/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210124/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:56:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210125/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210127/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210126/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210128/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210129/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210127/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210130/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:56:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210128/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210129/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210127/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210130/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210128/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210129/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210131/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210130/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210201/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210202/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210131/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210203/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210201/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210202/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210131/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210131/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:57:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210203/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210201/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210202/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210204/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210203/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210205/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210206/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:57:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210204/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210207/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210205/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210206/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210204/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210207/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210205/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210206/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210208/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210207/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210209/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210210/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210208/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210211/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210209/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210210/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210208/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:58:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210211/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210209/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210210/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210212/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210211/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210213/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210214/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:58:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210212/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210215/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210213/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210214/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210212/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210215/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210213/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210214/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210216/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210215/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210217/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210218/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210216/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210219/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210217/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210218/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210216/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210219/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 03:59:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210217/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210218/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210220/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 03:59:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210219/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210221/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210222/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210220/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210223/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210221/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210222/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210220/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210223/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210221/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210222/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210224/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210223/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210225/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210226/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210224/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210227/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:00:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210225/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210226/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210224/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210227/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210225/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210226/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:00:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210228/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210227/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210301/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210302/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210228/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210303/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210301/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210302/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210228/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210303/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210301/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210302/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210304/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210303/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210305/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210306/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210304/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210307/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:01:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210305/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210306/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210304/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210304/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210307/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210305/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210305/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210306/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210306/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210308/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210307/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:01:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210307/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210309/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210310/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210308/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210311/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210309/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210310/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210308/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210308/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210311/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210309/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210309/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210310/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210310/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210312/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210311/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210311/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210313/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210314/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:02:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210312/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210315/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210313/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210314/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210312/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210312/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210315/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210313/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:02:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210313/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210314/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210314/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210316/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210315/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210315/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210317/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210318/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210316/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210319/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210317/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210318/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210316/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210316/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210319/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210317/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210317/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210318/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210318/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210320/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210319/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210319/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210321/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:03:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210322/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210320/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210323/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210321/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210322/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210320/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210320/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:03:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210323/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210321/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210321/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210322/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210322/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210324/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210323/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210323/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210325/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210326/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210324/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210327/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210325/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210326/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210324/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210324/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210327/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210325/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210325/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210326/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210326/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210328/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210327/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210327/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210329/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210330/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:04:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210328/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210331/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210329/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210330/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210328/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210328/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210331/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210329/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210329/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210330/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210330/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:04:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210401/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210331/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210331/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210402/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210403/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210401/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210404/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210402/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210403/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210401/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210401/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210404/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210402/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210402/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210403/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210403/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210405/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210404/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210404/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:05:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210406/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210407/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210405/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210408/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210406/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210407/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210405/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:05:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210405/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210408/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210406/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210406/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210407/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210407/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210409/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210408/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210408/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210410/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210411/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210409/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210412/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210410/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210411/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210409/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210409/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210412/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210410/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210410/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210411/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210411/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210413/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210412/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210412/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:06:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210414/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210415/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210413/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210416/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210414/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210415/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210413/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:06:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210413/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210416/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210414/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210414/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210415/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210415/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210417/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210416/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210416/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210418/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210419/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210417/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210420/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210418/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210419/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210417/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210417/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210420/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210418/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210418/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210419/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210419/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210421/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210420/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210420/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:07:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210422/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210423/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:07:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210421/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210424/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210422/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210423/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210421/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210421/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210424/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210422/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210422/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210423/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210423/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 04:08:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210425/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210424/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210424/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210426/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210427/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210425/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210428/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210426/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210427/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210425/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210425/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:08:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210428/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210426/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210426/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210427/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210427/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210429/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210428/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210428/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210430/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:08:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210501/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210429/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210502/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210430/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210501/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210429/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210429/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210502/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210430/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210430/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210501/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210501/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210503/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210502/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210502/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210504/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210505/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210503/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210506/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210504/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210505/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210503/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210503/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:09:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210506/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210504/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210504/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210505/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210505/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210507/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210506/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210506/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210508/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210509/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:09:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210507/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210510/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210508/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210509/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210507/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210507/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210510/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210508/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210508/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210509/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210509/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210511/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210510/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210510/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210512/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210513/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210511/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210514/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210512/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:10:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210513/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210511/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210511/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210514/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210512/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210512/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210513/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210513/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210515/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210514/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:10:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210514/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210516/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210517/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210515/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210518/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210516/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210517/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210515/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210515/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210518/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210516/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210516/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210517/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210517/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210519/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210518/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210518/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210520/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210521/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210519/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210522/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210520/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:11:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210521/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210519/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210519/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210522/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210520/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210520/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210521/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210521/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210523/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210522/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:11:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210522/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210524/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210525/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210523/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210526/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210524/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210525/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210523/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210523/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210526/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210524/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210524/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210525/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210525/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210527/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210526/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210526/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210528/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210529/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210527/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210530/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210528/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:12:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210529/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210527/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210527/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210530/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210528/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210528/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210529/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210529/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210531/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:12:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210530/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210530/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210601/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210602/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210531/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210603/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210601/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210602/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210531/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210531/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210603/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210601/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210601/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210602/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210602/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210604/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210603/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210603/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210605/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210606/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210604/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:13:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210607/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210605/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210606/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210604/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210604/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210607/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210605/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210605/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210606/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210606/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:13:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210608/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210607/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210607/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210609/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210610/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210608/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210611/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210609/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210610/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210608/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210608/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210611/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210609/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210609/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210610/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210610/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210612/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210611/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210611/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210613/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210614/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210612/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210615/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:14:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210613/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210614/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210612/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210612/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210615/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210613/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210613/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210614/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210614/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210616/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210615/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:14:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210615/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210617/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210618/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210616/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210619/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210617/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210618/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210616/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210616/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210619/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210617/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210617/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210618/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210618/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210620/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210619/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210619/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:15:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210621/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210622/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210620/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210623%2f&_ordtok=7K43WVRD6k4DRDrNTtqJSqsRN7> from <GET https://www.tianqi.com//tianqi/wuhan/20210623/>
2025-05-04 04:15:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210621/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210622/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210620/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210620/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:15:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210624%2f&_ordtok=Khk3WVZkqQSNNBft1v0qDHSqN6> from <GET https://www.tianqi.com//tianqi/wuhan/20210624/>
2025-05-04 04:16:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210621/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210621/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:16:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210622/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210622/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:16:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210625%2f&_ordtok=nq43WV56qJPS61MjQsS5WDDRfP> from <GET https://www.tianqi.com//tianqi/wuhan/20210625/>
2025-05-04 04:16:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210626%2f&_ordtok=rF43WVZ6MM76F85t47SfvSrFH2> from <GET https://www.tianqi.com//tianqi/wuhan/20210626/>
2025-05-04 04:16:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210627%2f&_ordtok=MhZ3WVhb3PBKDS1sZMddv7RdFQ> from <GET https://www.tianqi.com//tianqi/wuhan/20210627/>
2025-05-04 04:16:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210628%2f&_ordtok=QjW3WVZ7sFZNPQSLHFk6MtRsJN> from <GET https://www.tianqi.com//tianqi/wuhan/20210628/>
2025-05-04 04:16:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210629%2f&_ordtok=k4Z3WV3bK4VjNGQjnSHQ3krnlH> from <GET https://www.tianqi.com//tianqi/wuhan/20210629/>
2025-05-04 04:16:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210630%2f&_ordtok=j3Z3WVhM03sBHHMrMCJPf7j6DN> from <GET https://www.tianqi.com//tianqi/wuhan/20210630/>
2025-05-04 04:16:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210701%2f&_ordtok=P6k3WVqMMDFqqj5VDKgMqZGNTP> from <GET https://www.tianqi.com//tianqi/wuhan/20210701/>
2025-05-04 04:16:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210702%2f&_ordtok=V7W3WVhD32FH6SK4PZ0WHNWK6j> from <GET https://www.tianqi.com//tianqi/wuhan/20210702/>
2025-05-04 04:16:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210703%2f&_ordtok=MDZ3WVLB4r0VjMDrFLn0DS73G6> from <GET https://www.tianqi.com//tianqi/wuhan/20210703/>
2025-05-04 04:16:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210704%2f&_ordtok=7mW3WV3MhhZW6Sv3k0VHJsM4M5> from <GET https://www.tianqi.com//tianqi/wuhan/20210704/>
2025-05-04 04:16:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210705%2f&_ordtok=FnZ3WV3qPPsLrtvrWV7Z7wDQt5> from <GET https://www.tianqi.com//tianqi/wuhan/20210705/>
2025-05-04 04:16:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210706%2f&_ordtok=BBk3WV3hLW6WPs2DSzv6D760JR> from <GET https://www.tianqi.com//tianqi/wuhan/20210706/>
2025-05-04 04:16:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210707%2f&_ordtok=FWk3WVh7V6PhRS7fPR6Q7K6sJH> from <GET https://www.tianqi.com//tianqi/wuhan/20210707/>
2025-05-04 04:16:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210708%2f&_ordtok=FnZ3WV3qPPsLrn1rWV7rw6vMRP> from <GET https://www.tianqi.com//tianqi/wuhan/20210708/>
2025-05-04 04:16:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210709%2f&_ordtok=VsZ3WV3jKH5mPv6Zsrlt1fWM2q> from <GET https://www.tianqi.com//tianqi/wuhan/20210709/>
2025-05-04 04:16:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:16:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210710%2f&_ordtok=7KZ3WV3BmNSZPDZV4vN6V05kts> from <GET https://www.tianqi.com//tianqi/wuhan/20210710/>
2025-05-04 04:16:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210711%2f&_ordtok=j5Z3WVLMbBD4JjFjqR0V5LGDjR> from <GET https://www.tianqi.com//tianqi/wuhan/20210711/>
2025-05-04 04:16:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210712%2f&_ordtok=DZZ3WVZ7KFSNNDRHvsNt7MjPr6> from <GET https://www.tianqi.com//tianqi/wuhan/20210712/>
2025-05-04 04:16:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210713%2f&_ordtok=NrZ3WVqZ2QrDHQ3HN23qqHHJMP> from <GET https://www.tianqi.com//tianqi/wuhan/20210713/>
2025-05-04 04:17:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210714%2f&_ordtok=Qq43WVZRF7MsFJbrqQ9bDsp4VQ> from <GET https://www.tianqi.com//tianqi/wuhan/20210714/>
2025-05-04 04:17:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210715%2f&_ordtok=D443WVL0MV3nPTRfFk7qZrSJN5> from <GET https://www.tianqi.com//tianqi/wuhan/20210715/>
2025-05-04 04:17:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210716%2f&_ordtok=HW43WV5nrknqM3v6jFF6HNQZ6q> from <GET https://www.tianqi.com//tianqi/wuhan/20210716/>
2025-05-04 04:17:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210717%2f&_ordtok=6WW3WV5LqnsFrHF6qwf16W0S2M> from <GET https://www.tianqi.com//tianqi/wuhan/20210717/>
2025-05-04 04:17:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210718%2f&_ordtok=5mZ3WVLM2HjKDVRM12q7F1sMJJ> from <GET https://www.tianqi.com//tianqi/wuhan/20210718/>
2025-05-04 04:17:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210719%2f&_ordtok=njW3WVZ3VhLmNr0rBZqjKk4qGM> from <GET https://www.tianqi.com//tianqi/wuhan/20210719/>
2025-05-04 04:17:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210720%2f&_ordtok=72W3WV553HZnQWPVb7MMZSM56r> from <GET https://www.tianqi.com//tianqi/wuhan/20210720/>
2025-05-04 04:17:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210721%2f&_ordtok=FHZ3WV5RNFR4H1NRPH5rLHVtZN> from <GET https://www.tianqi.com//tianqi/wuhan/20210721/>
2025-05-04 04:17:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210722%2f&_ordtok=bj43WVhrjBHmP22tP5tSvvH4nH> from <GET https://www.tianqi.com//tianqi/wuhan/20210722/>
2025-05-04 04:17:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210723%2f&_ordtok=7Vk3WVhWrs5WJSM5q6nrF0mNjH> from <GET https://www.tianqi.com//tianqi/wuhan/20210723/>
2025-05-04 04:17:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210724%2f&_ordtok=MQZ3WVhLJqqZqDZkQjRqP0rj4F> from <GET https://www.tianqi.com//tianqi/wuhan/20210724/>
2025-05-04 04:17:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210725%2f&_ordtok=PR43WV5jsLsH6nJs4Fq660qRtP> from <GET https://www.tianqi.com//tianqi/wuhan/20210725/>
2025-05-04 04:17:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210726%2f&_ordtok=ZLk3WVRsJVs7HGQ0qDVFFw2WWP> from <GET https://www.tianqi.com//tianqi/wuhan/20210726/>
2025-05-04 04:17:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210727%2f&_ordtok=H0W3WVZ207PJMRqPD0L2n07njF> from <GET https://www.tianqi.com//tianqi/wuhan/20210727/>
2025-05-04 04:17:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210728%2f&_ordtok=Fq43WV52sWMJRqvNkkSSM45QT5> from <GET https://www.tianqi.com//tianqi/wuhan/20210728/>
2025-05-04 04:17:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210729%2f&_ordtok=srW3WVZnkFqZJMJbMMWqN7P5FH> from <GET https://www.tianqi.com//tianqi/wuhan/20210729/>
2025-05-04 04:17:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:17:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210730%2f&_ordtok=b2Z3WVFbh7j0PW0t5NNFS52nNM> from <GET https://www.tianqi.com//tianqi/wuhan/20210730/>
2025-05-04 04:17:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210731%2f&_ordtok=2BW3WV3hN7RDN5n7MQWQ235FP5> from <GET https://www.tianqi.com//tianqi/wuhan/20210731/>
2025-05-04 04:17:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210801%2f&_ordtok=hPZ3WVhQLhSbjbHDPNDS50FKrn> from <GET https://www.tianqi.com//tianqi/wuhan/20210801/>
2025-05-04 04:17:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210802%2f&_ordtok=jk43WV5P2NMSNW5nDHMjM7qq1H> from <GET https://www.tianqi.com//tianqi/wuhan/20210802/>
2025-05-04 04:17:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210803%2f&_ordtok=MhZ3WVhb3PBKDFvsZMddvBdZ62> from <GET https://www.tianqi.com//tianqi/wuhan/20210803/>
2025-05-04 04:17:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210804%2f&_ordtok=7BZ3WVF5FqPq6MJStGs4KrqJQf> from <GET https://www.tianqi.com//tianqi/wuhan/20210804/>
2025-05-04 04:18:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210805%2f&_ordtok=W3W3WVLFmm4NJ6kv1j1M4QVDn5> from <GET https://www.tianqi.com//tianqi/wuhan/20210805/>
2025-05-04 04:18:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210806%2f&_ordtok=hHk3WVh5LH64j1WsTPPMZs2R6r> from <GET https://www.tianqi.com//tianqi/wuhan/20210806/>
2025-05-04 04:18:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210807%2f&_ordtok=ZK43WVFWQFq7MNsn6sQStWfrH5> from <GET https://www.tianqi.com//tianqi/wuhan/20210807/>
2025-05-04 04:18:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210808%2f&_ordtok=qPk3WVqZ7KVWDjqRsWd7sdBNd5> from <GET https://www.tianqi.com//tianqi/wuhan/20210808/>
2025-05-04 04:18:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210809%2f&_ordtok=r043WVRBVZM0PR6D5BFDJ5srLH> from <GET https://www.tianqi.com//tianqi/wuhan/20210809/>
2025-05-04 04:18:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210810%2f&_ordtok=B6W3WVLWWLbRR2lFM0MqRPRJBH> from <GET https://www.tianqi.com//tianqi/wuhan/20210810/>
2025-05-04 04:18:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210811%2f&_ordtok=k743WV50QkVVNDWVDV2jfvPfSM> from <GET https://www.tianqi.com//tianqi/wuhan/20210811/>
2025-05-04 04:18:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210812%2f&_ordtok=kRZ3WVqPjnsVrjPQQvR1V06JWR> from <GET https://www.tianqi.com//tianqi/wuhan/20210812/>
2025-05-04 04:18:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210813%2f&_ordtok=7Sk3WV54rSQmnj72P5M4Sk087q> from <GET https://www.tianqi.com//tianqi/wuhan/20210813/>
2025-05-04 04:18:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210814%2f&_ordtok=Mhk3WVL4JhkVN4fFv5MZ5t3v6S> from <GET https://www.tianqi.com//tianqi/wuhan/20210814/>
2025-05-04 04:18:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210815%2f&_ordtok=s343WVqR0VW3rMFsqPqnZMMsH6> from <GET https://www.tianqi.com//tianqi/wuhan/20210815/>
2025-05-04 04:18:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210816%2f&_ordtok=3FZ3WVL74WqJsZHZVjqtn4kV75> from <GET https://www.tianqi.com//tianqi/wuhan/20210816/>
2025-05-04 04:18:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210817%2f&_ordtok=2kZ3WVhHqVRLnFtNSqsrvTZRfD> from <GET https://www.tianqi.com//tianqi/wuhan/20210817/>
2025-05-04 04:18:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210818%2f&_ordtok=FNZ3WVF7N37ZHNF1sP25WrW34q> from <GET https://www.tianqi.com//tianqi/wuhan/20210818/>
2025-05-04 04:18:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:18:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210819%2f&_ordtok=jZW3WV37HRh4n6rrPp6QVDRQ7n> from <GET https://www.tianqi.com//tianqi/wuhan/20210819/>
2025-05-04 04:18:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210820%2f&_ordtok=M5W3WV3mLDD55ng3wNWTH3WtQQ> from <GET https://www.tianqi.com//tianqi/wuhan/20210820/>
2025-05-04 04:18:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20210821%2f&_ordtok=D6k3WV5jrH2JPGp8K8n8KQsbK5> from <GET https://www.tianqi.com//tianqi/wuhan/20210821/>
2025-05-04 04:18:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210822/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:18:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210823/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:18:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210824/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210825/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210822/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210823/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210824/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210825/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210822/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210822/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210823/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210823/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210824/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210824/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210825/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210825/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210826/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210827/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210828/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210829/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210826/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210827/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210828/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210829/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:19:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210826/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210826/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210827/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210827/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210828/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210828/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210829/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210829/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210830/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210831/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210901/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210902/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:19:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210830/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210831/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210901/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210902/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210830/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210830/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210831/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210831/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210901/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210901/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210902/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210902/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210903/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210904/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210905/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210906/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210903/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210904/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210905/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210906/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210903/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210903/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210904/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210904/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:20:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210905/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210905/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210906/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210906/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210907/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210908/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210909/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210910/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210907/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:20:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210908/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210909/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210910/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210907/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210907/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210908/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210908/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210909/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210909/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210910/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210910/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210911/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210912/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210913/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210914/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210911/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210912/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210913/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210914/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:21:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210911/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210911/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210912/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210912/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210913/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210913/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210914/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210914/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210915/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210916/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210917/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210918/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210915/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210916/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210917/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210918/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210915/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210915/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210916/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210916/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210917/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210917/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210918/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210918/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210919/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210920/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210921/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210922/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210919/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210920/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210921/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210922/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210919/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210919/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210920/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210920/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:22:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210921/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210921/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210922/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210922/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210923/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210924/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210925/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210926/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210923/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:22:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210924/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210925/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210926/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210923/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210923/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210924/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210924/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210925/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210925/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210926/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210926/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210927/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210928/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210929/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210930/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210927/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210928/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210929/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20210930/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210927/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210927/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:23:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210928/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210928/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210929/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210929/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20210930/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20210930/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211001/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:23:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211002/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211003/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211004/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211001/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211002/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211003/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211004/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211001/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211001/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211002/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211002/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211003/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211003/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211004/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211004/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211005/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211006/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211007/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211008/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211005/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211006/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:24:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211007/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211008/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211005/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211005/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211006/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211006/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211007/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211007/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211008/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211008/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211009/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:24:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211010/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211011/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211012/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211009/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211010/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211011/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211012/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211009/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211009/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211010/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211010/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211011/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211011/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211012/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211012/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211013/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211014/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211015/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211016/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211013/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211014/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211015/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:25:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211016/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211013/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211013/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211014/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211014/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211015/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211015/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211016/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211016/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211017/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211018/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:25:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211019/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211020/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211017/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211018/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211019/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211020/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211017/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211017/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211018/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211018/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211019/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211019/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211020/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211020/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211021/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:26:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211022/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211023/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211024/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211021/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211022/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211023/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211024/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211021/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:26:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211021/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211022/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211022/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211023/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211023/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211024/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211024/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211025/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211026/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211027/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211028/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211025/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211026/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211027/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211028/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211025/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211025/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211026/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211026/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211027/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211027/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211028/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211028/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211029/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211030/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211031/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:27:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211101/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211029/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211030/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211031/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211101/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211029/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211029/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211030/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211030/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211031/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:27:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211031/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211101/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211102/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211103/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211104/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211105/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211102/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211103/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211104/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211105/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211102/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211103/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211104/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211105/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211106/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211107/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211108/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211109/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:28:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211106/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211107/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211108/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211109/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:28:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211106/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211107/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211108/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211109/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211110/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211111/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211112/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211113/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211110/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211111/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211112/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211113/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211110/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211111/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211112/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211113/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211114/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:29:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211115/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211116/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211117/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211114/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211115/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211116/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:29:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211117/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211114/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211115/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211116/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211117/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211118/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211119/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211120/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211121/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211118/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211119/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211120/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211121/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211118/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211119/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211120/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211121/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211122/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211123/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:30:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211124/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211125/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211122/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211123/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211124/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211125/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211122/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:30:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211123/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211124/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211125/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211126/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211127/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211128/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211129/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211126/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211127/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211128/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211129/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211126/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211127/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211128/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:31:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211129/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211130/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211201/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211202/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211203/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211130/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211201/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:31:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211202/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211203/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211130/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211201/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211202/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211203/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211204/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211205/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211206/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211207/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211204/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211205/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211206/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211207/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211204/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211205/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211206/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:32:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211207/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211208/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211209/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211210/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211211/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211208/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211209/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:32:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211210/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211211/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211208/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211209/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211210/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211211/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211212/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211213/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211214/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211215/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211212/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211213/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211214/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211215/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211212/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211213/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211214/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211215/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:33:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211216/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211217/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211218/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211219/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211216/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211217/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211218/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20211219/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:33:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211216/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211217/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211218/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20211219/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20211219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:34:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211220%2f&_ordtok=2VW3WV5VBLK3nRJpq8880JM3SR> from <GET https://www.tianqi.com//tianqi/wuhan/20211220/>
2025-05-04 04:34:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211221%2f&_ordtok=2s43WVF7SmZBNV74R365bSPmBQ> from <GET https://www.tianqi.com//tianqi/wuhan/20211221/>
2025-05-04 04:34:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211222%2f&_ordtok=kqk3WVFD7M3JHpPZQr7WPkVDQ7> from <GET https://www.tianqi.com//tianqi/wuhan/20211222/>
2025-05-04 04:34:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211223%2f&_ordtok=hRk3WVZ2q5RqqqN5T4MQWWrFS5> from <GET https://www.tianqi.com//tianqi/wuhan/20211223/>
2025-05-04 04:34:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211224%2f&_ordtok=BNW3WVqMHB63FDSDt7vtPTH3sQ> from <GET https://www.tianqi.com//tianqi/wuhan/20211224/>
2025-05-04 04:34:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211225%2f&_ordtok=kb43WVZPDWsD6rrPTkqVVZHMZR> from <GET https://www.tianqi.com//tianqi/wuhan/20211225/>
2025-05-04 04:34:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211226%2f&_ordtok=RDZ3WVZR0HR6nVjf5w7TWsHHQQ> from <GET https://www.tianqi.com//tianqi/wuhan/20211226/>
2025-05-04 04:34:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211227%2f&_ordtok=72Z3WVhbrmQKFqfvj1P7H8D0Ss> from <GET https://www.tianqi.com//tianqi/wuhan/20211227/>
2025-05-04 04:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:34:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211228%2f&_ordtok=R0Z3WVh4hSHBj1kFFNWfkT0pNN> from <GET https://www.tianqi.com//tianqi/wuhan/20211228/>
2025-05-04 04:34:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211229%2f&_ordtok=H6W3WVF6SrS7PB10nkSWFWmW4V> from <GET https://www.tianqi.com//tianqi/wuhan/20211229/>
2025-05-04 04:34:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211230%2f&_ordtok=RDW3WVq42bHM60f2SF2vjQ36rM> from <GET https://www.tianqi.com//tianqi/wuhan/20211230/>
2025-05-04 04:34:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20211231%2f&_ordtok=hWZ3WV3PnQB7Pq778kn4FZ56Wq> from <GET https://www.tianqi.com//tianqi/wuhan/20211231/>
2025-05-04 04:34:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220101%2f&_ordtok=DK43WVR5bJPZJSWMJ5LtgNPqNn> from <GET https://www.tianqi.com//tianqi/wuhan/20220101/>
2025-05-04 04:34:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220102%2f&_ordtok=Bk43WVLrLS2QMB6rZNq1HFM3SB> from <GET https://www.tianqi.com//tianqi/wuhan/20220102/>
2025-05-04 04:34:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220103%2f&_ordtok=hFW3WV3SHZr4nvR6nv0qNf7NFr> from <GET https://www.tianqi.com//tianqi/wuhan/20220103/>
2025-05-04 04:34:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220104%2f&_ordtok=Vn43WVZVKnMrHvD3kN3TsZS560> from <GET https://www.tianqi.com//tianqi/wuhan/20220104/>
2025-05-04 04:35:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220105%2f&_ordtok=QB43WV52VkVhnqTkFFW4v778TR> from <GET https://www.tianqi.com//tianqi/wuhan/20220105/>
2025-05-04 04:35:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220106%2f&_ordtok=BL43WVZ7hF2bjrqn004JWVv5V5> from <GET https://www.tianqi.com//tianqi/wuhan/20220106/>
2025-05-04 04:35:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220107%2f&_ordtok=JFZ3WVZNRP3DQ83L2H3sDQ34FH> from <GET https://www.tianqi.com//tianqi/wuhan/20220107/>
2025-05-04 04:35:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220108%2f&_ordtok=jQW3WV3VrHK6NQkjFLRF0ST65n> from <GET https://www.tianqi.com//tianqi/wuhan/20220108/>
2025-05-04 04:35:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220109%2f&_ordtok=FV43WV3VJL6hsjfqfTnMs1W1Dr> from <GET https://www.tianqi.com//tianqi/wuhan/20220109/>
2025-05-04 04:35:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220110%2f&_ordtok=SnW3WVFJF0NhqvQ32sDT3jMs0F> from <GET https://www.tianqi.com//tianqi/wuhan/20220110/>
2025-05-04 04:35:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220111%2f&_ordtok=VSZ3WVRj6qDBMZWPnTjH00sj76> from <GET https://www.tianqi.com//tianqi/wuhan/20220111/>
2025-05-04 04:35:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220112%2f&_ordtok=6Jk3WV3HWM34sHSWNsPrvTSZtj> from <GET https://www.tianqi.com//tianqi/wuhan/20220112/>
2025-05-04 04:35:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220113%2f&_ordtok=K0W3WV5Q2j62nFqjZ3JT618MN6> from <GET https://www.tianqi.com//tianqi/wuhan/20220113/>
2025-05-04 04:35:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220114%2f&_ordtok=nQZ3WV3b0Wm6NRQvN0qDfNMvNq> from <GET https://www.tianqi.com//tianqi/wuhan/20220114/>
2025-05-04 04:35:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220115%2f&_ordtok=kBW3WVhMHNZNDBfTFd1QRTJqFr> from <GET https://www.tianqi.com//tianqi/wuhan/20220115/>
2025-05-04 04:35:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220116%2f&_ordtok=FhZ3WV5VQqrnsqJZDsLDFZNJns> from <GET https://www.tianqi.com//tianqi/wuhan/20220116/>
2025-05-04 04:35:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220117%2f&_ordtok=3ZW3WVh2DbHZnJtPfZqsQ086QF> from <GET https://www.tianqi.com//tianqi/wuhan/20220117/>
2025-05-04 04:35:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220118%2f&_ordtok=PW43WVhrHrsPjJFnZBf36rNQFN> from <GET https://www.tianqi.com//tianqi/wuhan/20220118/>
2025-05-04 04:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:35:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220119%2f&_ordtok=WPW3WVLmZZn4PD2sS401sVM1HF> from <GET https://www.tianqi.com//tianqi/wuhan/20220119/>
2025-05-04 04:35:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220120%2f&_ordtok=6FZ3WVFbJNM7M7HWfrnFqNjr04> from <GET https://www.tianqi.com//tianqi/wuhan/20220120/>
2025-05-04 04:35:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220121%2f&_ordtok=q7Z3WVhWKrnjPj7vv3mFtZN70T> from <GET https://www.tianqi.com//tianqi/wuhan/20220121/>
2025-05-04 04:35:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220122%2f&_ordtok=bMZ3WV3r03MP55DWtp4vDsqrpF> from <GET https://www.tianqi.com//tianqi/wuhan/20220122/>
2025-05-04 04:35:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220123%2f&_ordtok=SBW3WVqhR667FZH53js7H6j12r> from <GET https://www.tianqi.com//tianqi/wuhan/20220123/>
2025-05-04 04:35:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220124%2f&_ordtok=0L43WVL4LS4hsKLQGPs4DZkV5H> from <GET https://www.tianqi.com//tianqi/wuhan/20220124/>
2025-05-04 04:35:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220125%2f&_ordtok=SQW3WVh73KMQRrPgnF3S4vFFv6> from <GET https://www.tianqi.com//tianqi/wuhan/20220125/>
2025-05-04 04:36:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220126%2f&_ordtok=RZZ3WV3BjrsQ5HJ2rHFMQPfJtQ> from <GET https://www.tianqi.com//tianqi/wuhan/20220126/>
2025-05-04 04:36:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220127%2f&_ordtok=B243WV54R0H7nkHDjKq4FnSWZF> from <GET https://www.tianqi.com//tianqi/wuhan/20220127/>
2025-05-04 04:36:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220128%2f&_ordtok=qnZ3WVh3B7Pn6S3vZ7ZfFTR26N> from <GET https://www.tianqi.com//tianqi/wuhan/20220128/>
2025-05-04 04:36:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220129%2f&_ordtok=QWZ3WVhMNFsLQ8vns27rP7T6T6> from <GET https://www.tianqi.com//tianqi/wuhan/20220129/>
2025-05-04 04:36:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220130%2f&_ordtok=m043WVLS7MN2qT8t0DS8q1RF4P> from <GET https://www.tianqi.com//tianqi/wuhan/20220130/>
2025-05-04 04:36:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220131%2f&_ordtok=NRW3WVZLBLmJRHVPtVB35RFSS5> from <GET https://www.tianqi.com//tianqi/wuhan/20220131/>
2025-05-04 04:36:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220201%2f&_ordtok=05Z3WVZrn3RnsFRrQNKF7T60Hr> from <GET https://www.tianqi.com//tianqi/wuhan/20220201/>
2025-05-04 04:36:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220202%2f&_ordtok=4sk3WVZjhBJ3Pkr6rjjsrZMZN5> from <GET https://www.tianqi.com//tianqi/wuhan/20220202/>
2025-05-04 04:36:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220203%2f&_ordtok=hbZ3WVFhn4hsDnrq5PN4MQVTfM> from <GET https://www.tianqi.com//tianqi/wuhan/20220203/>
2025-05-04 04:36:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220204%2f&_ordtok=P7W3WV3P7K206qZD1nDVCDZ5F7> from <GET https://www.tianqi.com//tianqi/wuhan/20220204/>
2025-05-04 04:36:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220205%2f&_ordtok=Zsk3WVLmV5LNqt5TFrQVZR74v5> from <GET https://www.tianqi.com//tianqi/wuhan/20220205/>
2025-05-04 04:36:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220206%2f&_ordtok=5SZ3WV5WZQBn5BnMHS0DZTQtfN> from <GET https://www.tianqi.com//tianqi/wuhan/20220206/>
2025-05-04 04:36:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220207%2f&_ordtok=bHZ3WV3jDbF767L4bMrbqbNtq6> from <GET https://www.tianqi.com//tianqi/wuhan/20220207/>
2025-05-04 04:36:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220208%2f&_ordtok=4ZW3WVLn3JZZrk6qDHs7H3BH3s> from <GET https://www.tianqi.com//tianqi/wuhan/20220208/>
2025-05-04 04:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:36:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220209%2f&_ordtok=qPZ3WVRJBqksNSQnHH6s372N37> from <GET https://www.tianqi.com//tianqi/wuhan/20220209/>
2025-05-04 04:36:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220210%2f&_ordtok=6Qk3WVhPP6BJFZRJRVrJskrp8s> from <GET https://www.tianqi.com//tianqi/wuhan/20220210/>
2025-05-04 04:36:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220211%2f&_ordtok=75W3WV3DJ5635MT7vFvDk2HT05> from <GET https://www.tianqi.com//tianqi/wuhan/20220211/>
2025-05-04 04:36:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220212%2f&_ordtok=WNZ3WV3sZWQ0jp5hrLQ74LpVPF> from <GET https://www.tianqi.com//tianqi/wuhan/20220212/>
2025-05-04 04:36:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220213%2f&_ordtok=hBW3WVhj0rLm67FSkk8Q2H6SDq> from <GET https://www.tianqi.com//tianqi/wuhan/20220213/>
2025-05-04 04:36:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220214%2f&_ordtok=mHZ3WVRnnq0WF48n2FPt7s8P6s> from <GET https://www.tianqi.com//tianqi/wuhan/20220214/>
2025-05-04 04:37:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220215%2f&_ordtok=h3k3WVLHQWZNs104WJHWVq2VZC> from <GET https://www.tianqi.com//tianqi/wuhan/20220215/>
2025-05-04 04:37:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220216%2f&_ordtok=FQW3WVZm4PL6sQbF05QF7kHfTF> from <GET https://www.tianqi.com//tianqi/wuhan/20220216/>
2025-05-04 04:37:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20220217%2f&_ordtok=FB43WV3qmmJnN4THktffM1pR6D> from <GET https://www.tianqi.com//tianqi/wuhan/20220217/>
2025-05-04 04:37:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220218/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220219/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220220/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220221/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220218/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220219/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220220/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220221/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220218/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220219/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:37:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220220/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220221/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220222/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220223/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220224/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220225/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220222/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:37:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220223/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220224/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220225/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220222/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220223/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220224/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220225/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220226/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220227/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220228/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220301/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220226/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220227/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220228/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220301/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220226/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220227/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220228/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:38:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220301/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220302/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220303/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220304/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220305/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220302/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:38:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220303/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220304/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220305/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220302/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220303/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220304/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220304/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220305/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220305/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220306/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220307/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220308/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220309/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220306/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220307/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220308/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220309/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220306/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220306/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:39:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220307/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220307/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220308/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220308/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220309/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220309/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220310/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:39:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220311/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220312/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220313/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220310/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220311/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220312/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220313/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220310/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220310/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220311/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220311/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220312/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220312/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220313/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220313/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220314/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220315/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220316/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220317/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220314/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220315/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:40:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220316/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220317/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220314/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220314/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220315/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220315/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220316/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220316/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220317/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220317/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:40:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220318/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220319/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220320/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220321/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220318/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220319/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220320/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220321/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220318/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220318/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220319/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220319/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220320/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220320/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220321/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220321/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220322/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220323/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220324/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220325/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220322/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220323/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:41:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220324/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220325/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220322/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220322/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220323/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220323/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220324/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220324/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220325/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220325/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220326/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:41:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220327/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220328/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220329/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220326/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220327/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220328/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220329/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220326/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220326/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220327/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220327/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220328/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220328/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220329/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220329/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220330/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220331/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:42:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220401/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220402/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220330/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220331/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220401/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220402/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220330/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220330/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220331/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220331/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:42:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220401/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220401/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220402/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220402/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220403/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220404/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220405/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220406/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220403/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220404/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220405/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220406/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220403/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220403/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220404/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220404/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220405/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220405/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220406/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220406/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220407/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220408/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:43:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220409/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220410/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220407/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220408/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220409/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220410/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220407/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220407/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220408/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220408/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220409/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:43:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220409/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220410/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220410/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220411/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220412/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220413/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220414/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220411/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220412/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220413/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220414/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220411/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220411/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220412/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220412/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220413/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220413/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220414/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220414/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220415/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220416/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220417/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:44:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220418/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220415/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220416/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220417/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220418/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:44:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220415/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220415/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220416/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220416/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220417/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220417/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220418/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220418/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 04:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:48:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220419/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220419/ took longer than 180.0 seconds..
2025-05-04 04:48:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220420/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220420/ took longer than 180.0 seconds..
2025-05-04 04:48:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220421/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220421/ took longer than 180.0 seconds..
2025-05-04 04:48:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220422/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220422/ took longer than 180.0 seconds..
2025-05-04 04:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220419/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220419/ took longer than 180.0 seconds..
2025-05-04 04:51:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220420/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220420/ took longer than 180.0 seconds..
2025-05-04 04:51:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220421/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220421/ took longer than 180.0 seconds..
2025-05-04 04:51:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220422/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220422/ took longer than 180.0 seconds..
2025-05-04 04:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:54:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220419/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220419/ took longer than 180.0 seconds..
2025-05-04 04:54:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220419/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220419/ took longer than 180.0 seconds..
2025-05-04 04:54:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220420/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220420/ took longer than 180.0 seconds..
2025-05-04 04:54:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220420/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220420/ took longer than 180.0 seconds..
2025-05-04 04:54:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220421/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220421/ took longer than 180.0 seconds..
2025-05-04 04:54:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220421/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220421/ took longer than 180.0 seconds..
2025-05-04 04:54:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220422/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220422/ took longer than 180.0 seconds..
2025-05-04 04:54:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220422/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220422/ took longer than 180.0 seconds..
2025-05-04 04:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:57:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220423/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220423/ took longer than 180.0 seconds..
2025-05-04 04:57:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220424/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220424/ took longer than 180.0 seconds..
2025-05-04 04:57:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220425/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220425/ took longer than 180.0 seconds..
2025-05-04 04:57:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220426/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220426/ took longer than 180.0 seconds..
2025-05-04 04:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 04:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:00:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220423/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220423/ took longer than 180.0 seconds..
2025-05-04 05:00:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220424/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220424/ took longer than 180.0 seconds..
2025-05-04 05:00:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220425/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220425/ took longer than 180.0 seconds..
2025-05-04 05:00:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220426/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220426/ took longer than 180.0 seconds..
2025-05-04 05:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:03:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220423/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220423/ took longer than 180.0 seconds..
2025-05-04 05:03:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220423/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220423/ took longer than 180.0 seconds..
2025-05-04 05:03:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220424/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220424/ took longer than 180.0 seconds..
2025-05-04 05:03:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220424/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220424/ took longer than 180.0 seconds..
2025-05-04 05:03:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220425/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220425/ took longer than 180.0 seconds..
2025-05-04 05:03:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220425/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220425/ took longer than 180.0 seconds..
2025-05-04 05:03:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220426/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220426/ took longer than 180.0 seconds..
2025-05-04 05:03:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220426/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220426/ took longer than 180.0 seconds..
2025-05-04 05:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:06:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220427/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220427/ took longer than 180.0 seconds..
2025-05-04 05:06:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220428/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220428/ took longer than 180.0 seconds..
2025-05-04 05:06:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220429/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220429/ took longer than 180.0 seconds..
2025-05-04 05:06:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220430/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220430/ took longer than 180.0 seconds..
2025-05-04 05:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:09:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220427/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220427/ took longer than 180.0 seconds..
2025-05-04 05:09:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220428/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220428/ took longer than 180.0 seconds..
2025-05-04 05:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220429/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220429/ took longer than 180.0 seconds..
2025-05-04 05:09:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220430/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220430/ took longer than 180.0 seconds..
2025-05-04 05:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:12:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220427/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220427/ took longer than 180.0 seconds..
2025-05-04 05:12:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220427/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220427/ took longer than 180.0 seconds..
2025-05-04 05:12:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220428/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220428/ took longer than 180.0 seconds..
2025-05-04 05:12:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220428/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220428/ took longer than 180.0 seconds..
2025-05-04 05:12:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220429/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220429/ took longer than 180.0 seconds..
2025-05-04 05:12:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220429/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220429/ took longer than 180.0 seconds..
2025-05-04 05:12:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220430/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220430/ took longer than 180.0 seconds..
2025-05-04 05:12:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220430/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220430/ took longer than 180.0 seconds..
2025-05-04 05:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220501/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220501/ took longer than 180.0 seconds..
2025-05-04 05:15:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220502/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220502/ took longer than 180.0 seconds..
2025-05-04 05:15:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220503/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220503/ took longer than 180.0 seconds..
2025-05-04 05:15:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220504/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220504/ took longer than 180.0 seconds..
2025-05-04 05:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:18:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220501/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220501/ took longer than 180.0 seconds..
2025-05-04 05:18:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220502/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220502/ took longer than 180.0 seconds..
2025-05-04 05:18:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220503/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220503/ took longer than 180.0 seconds..
2025-05-04 05:18:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220504/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220504/ took longer than 180.0 seconds..
2025-05-04 05:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:21:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220501/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220501/ took longer than 180.0 seconds..
2025-05-04 05:21:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220501/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220501/ took longer than 180.0 seconds..
2025-05-04 05:21:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220502/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220502/ took longer than 180.0 seconds..
2025-05-04 05:21:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220502/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220502/ took longer than 180.0 seconds..
2025-05-04 05:21:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220503/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220503/ took longer than 180.0 seconds..
2025-05-04 05:21:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220503/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220503/ took longer than 180.0 seconds..
2025-05-04 05:21:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220504/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220504/ took longer than 180.0 seconds..
2025-05-04 05:21:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220504/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220504/ took longer than 180.0 seconds..
2025-05-04 05:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:24:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220505/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220505/ took longer than 180.0 seconds..
2025-05-04 05:24:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220506/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220506/ took longer than 180.0 seconds..
2025-05-04 05:24:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220507/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220507/ took longer than 180.0 seconds..
2025-05-04 05:24:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220508/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220508/ took longer than 180.0 seconds..
2025-05-04 05:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:27:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220505/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220505/ took longer than 180.0 seconds..
2025-05-04 05:27:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220506/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220506/ took longer than 180.0 seconds..
2025-05-04 05:27:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220507/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220507/ took longer than 180.0 seconds..
2025-05-04 05:27:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220508/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220508/ took longer than 180.0 seconds..
2025-05-04 05:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:30:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220505/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220505/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220505/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220505/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220506/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220506/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220507/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220507/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220508/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220508/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220507/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220507/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220506/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220506/ took longer than 180.0 seconds..
2025-05-04 05:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220508/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220508/ took longer than 180.0 seconds..
2025-05-04 05:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:33:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220509/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220509/ took longer than 180.0 seconds..
2025-05-04 05:33:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220510/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220510/ took longer than 180.0 seconds..
2025-05-04 05:33:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220511/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220511/ took longer than 180.0 seconds..
2025-05-04 05:33:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220512/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220512/ took longer than 180.0 seconds..
2025-05-04 05:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:36:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220509/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220509/ took longer than 180.0 seconds..
2025-05-04 05:36:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220510/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220510/ took longer than 180.0 seconds..
2025-05-04 05:36:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220511/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220511/ took longer than 180.0 seconds..
2025-05-04 05:36:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220512/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220512/ took longer than 180.0 seconds..
2025-05-04 05:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:39:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220509/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220509/ took longer than 180.0 seconds..
2025-05-04 05:39:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220509/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220509/ took longer than 180.0 seconds..
2025-05-04 05:39:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220510/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220510/ took longer than 180.0 seconds..
2025-05-04 05:39:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220510/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220510/ took longer than 180.0 seconds..
2025-05-04 05:39:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220511/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220511/ took longer than 180.0 seconds..
2025-05-04 05:39:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220511/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220511/ took longer than 180.0 seconds..
2025-05-04 05:39:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220512/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220512/ took longer than 180.0 seconds..
2025-05-04 05:39:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220512/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220512/ took longer than 180.0 seconds..
2025-05-04 05:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220513/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220513/ took longer than 180.0 seconds..
2025-05-04 05:42:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220514/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220514/ took longer than 180.0 seconds..
2025-05-04 05:42:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220515/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220515/ took longer than 180.0 seconds..
2025-05-04 05:42:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220516/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220516/ took longer than 180.0 seconds..
2025-05-04 05:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:45:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220513/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220513/ took longer than 180.0 seconds..
2025-05-04 05:45:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220514/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220514/ took longer than 180.0 seconds..
2025-05-04 05:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220515/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220515/ took longer than 180.0 seconds..
2025-05-04 05:45:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220516/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220516/ took longer than 180.0 seconds..
2025-05-04 05:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:48:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220513/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220513/ took longer than 180.0 seconds..
2025-05-04 05:48:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220513/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220513/ took longer than 180.0 seconds..
2025-05-04 05:48:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220514/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220514/ took longer than 180.0 seconds..
2025-05-04 05:48:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220514/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220514/ took longer than 180.0 seconds..
2025-05-04 05:48:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220515/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220515/ took longer than 180.0 seconds..
2025-05-04 05:48:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220515/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220515/ took longer than 180.0 seconds..
2025-05-04 05:48:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220516/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220516/ took longer than 180.0 seconds..
2025-05-04 05:48:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220516/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220516/ took longer than 180.0 seconds..
2025-05-04 05:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:51:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220517/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220517/ took longer than 180.0 seconds..
2025-05-04 05:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220518/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220518/ took longer than 180.0 seconds..
2025-05-04 05:51:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220519/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220519/ took longer than 180.0 seconds..
2025-05-04 05:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220520/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220520/ took longer than 180.0 seconds..
2025-05-04 05:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:54:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220517/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220517/ took longer than 180.0 seconds..
2025-05-04 05:54:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220518/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220518/ took longer than 180.0 seconds..
2025-05-04 05:54:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220519/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220519/ took longer than 180.0 seconds..
2025-05-04 05:54:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220520/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220520/ took longer than 180.0 seconds..
2025-05-04 05:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:57:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220517/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220517/ took longer than 180.0 seconds..
2025-05-04 05:57:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220517/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220517/ took longer than 180.0 seconds..
2025-05-04 05:57:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220518/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220518/ took longer than 180.0 seconds..
2025-05-04 05:57:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220518/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220518/ took longer than 180.0 seconds..
2025-05-04 05:57:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220519/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220519/ took longer than 180.0 seconds..
2025-05-04 05:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220519/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220519/ took longer than 180.0 seconds..
2025-05-04 05:57:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220520/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220520/ took longer than 180.0 seconds..
2025-05-04 05:57:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220520/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220520/ took longer than 180.0 seconds..
2025-05-04 05:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 05:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220521/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220521/ took longer than 180.0 seconds..
2025-05-04 06:00:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220522/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220522/ took longer than 180.0 seconds..
2025-05-04 06:00:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220523/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220523/ took longer than 180.0 seconds..
2025-05-04 06:00:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220524/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220524/ took longer than 180.0 seconds..
2025-05-04 06:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:03:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220521/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220521/ took longer than 180.0 seconds..
2025-05-04 06:03:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220522/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220522/ took longer than 180.0 seconds..
2025-05-04 06:03:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220523/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220523/ took longer than 180.0 seconds..
2025-05-04 06:03:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220524/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220524/ took longer than 180.0 seconds..
2025-05-04 06:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:06:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220521/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220521/ took longer than 180.0 seconds..
2025-05-04 06:06:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220521/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220521/ took longer than 180.0 seconds..
2025-05-04 06:06:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220522/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220522/ took longer than 180.0 seconds..
2025-05-04 06:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220522/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220522/ took longer than 180.0 seconds..
2025-05-04 06:06:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220523/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220523/ took longer than 180.0 seconds..
2025-05-04 06:06:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220523/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220523/ took longer than 180.0 seconds..
2025-05-04 06:06:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220524/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220524/ took longer than 180.0 seconds..
2025-05-04 06:06:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220524/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220524/ took longer than 180.0 seconds..
2025-05-04 06:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:09:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220525/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220525/ took longer than 180.0 seconds..
2025-05-04 06:09:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220526/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220526/ took longer than 180.0 seconds..
2025-05-04 06:09:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220527/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220527/ took longer than 180.0 seconds..
2025-05-04 06:09:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220528/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220528/ took longer than 180.0 seconds..
2025-05-04 06:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:12:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220525/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220525/ took longer than 180.0 seconds..
2025-05-04 06:12:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220526/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220526/ took longer than 180.0 seconds..
2025-05-04 06:12:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220527/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220527/ took longer than 180.0 seconds..
2025-05-04 06:12:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220528/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220528/ took longer than 180.0 seconds..
2025-05-04 06:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:15:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220525/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220525/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220525/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220525/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220526/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220526/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220527/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220527/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220528/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220528/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220527/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220527/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220526/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220526/ took longer than 180.0 seconds..
2025-05-04 06:15:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220528/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220528/ took longer than 180.0 seconds..
2025-05-04 06:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:18:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220529/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220529/ took longer than 180.0 seconds..
2025-05-04 06:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:18:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220530/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220530/ took longer than 180.0 seconds..
2025-05-04 06:18:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220531/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220531/ took longer than 180.0 seconds..
2025-05-04 06:18:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220601/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220601/ took longer than 180.0 seconds..
2025-05-04 06:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:21:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220529/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220529/ took longer than 180.0 seconds..
2025-05-04 06:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:21:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220530/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220530/ took longer than 180.0 seconds..
2025-05-04 06:21:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220531/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220531/ took longer than 180.0 seconds..
2025-05-04 06:21:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220601/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220601/ took longer than 180.0 seconds..
2025-05-04 06:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:24:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220529/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220529/ took longer than 180.0 seconds..
2025-05-04 06:24:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220529/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220529/ took longer than 180.0 seconds..
2025-05-04 06:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:24:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220530/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220530/ took longer than 180.0 seconds..
2025-05-04 06:24:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220530/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220530/ took longer than 180.0 seconds..
2025-05-04 06:24:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220531/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220531/ took longer than 180.0 seconds..
2025-05-04 06:24:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220531/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220531/ took longer than 180.0 seconds..
2025-05-04 06:24:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220601/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220601/ took longer than 180.0 seconds..
2025-05-04 06:24:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220601/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220601/ took longer than 180.0 seconds..
2025-05-04 06:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:27:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220602/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220602/ took longer than 180.0 seconds..
2025-05-04 06:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:27:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220603/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220603/ took longer than 180.0 seconds..
2025-05-04 06:27:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220604/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220604/ took longer than 180.0 seconds..
2025-05-04 06:27:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220605/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220605/ took longer than 180.0 seconds..
2025-05-04 06:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220602/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220602/ took longer than 180.0 seconds..
2025-05-04 06:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:30:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220603/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220603/ took longer than 180.0 seconds..
2025-05-04 06:30:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220604/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220604/ took longer than 180.0 seconds..
2025-05-04 06:30:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220605/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220605/ took longer than 180.0 seconds..
2025-05-04 06:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:33:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220602/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220602/ took longer than 180.0 seconds..
2025-05-04 06:33:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220602/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220602/ took longer than 180.0 seconds..
2025-05-04 06:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:33:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220603/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220603/ took longer than 180.0 seconds..
2025-05-04 06:33:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220603/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220603/ took longer than 180.0 seconds..
2025-05-04 06:33:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220604/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220604/ took longer than 180.0 seconds..
2025-05-04 06:33:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220604/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220604/ took longer than 180.0 seconds..
2025-05-04 06:33:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220605/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220605/ took longer than 180.0 seconds..
2025-05-04 06:33:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220605/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220605/ took longer than 180.0 seconds..
2025-05-04 06:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:36:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220606/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220606/ took longer than 180.0 seconds..
2025-05-04 06:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:36:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220607/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220607/ took longer than 180.0 seconds..
2025-05-04 06:36:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220608/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220608/ took longer than 180.0 seconds..
2025-05-04 06:36:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220609/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220609/ took longer than 180.0 seconds..
2025-05-04 06:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:39:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220606/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220606/ took longer than 180.0 seconds..
2025-05-04 06:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:39:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220607/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220607/ took longer than 180.0 seconds..
2025-05-04 06:39:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220608/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220608/ took longer than 180.0 seconds..
2025-05-04 06:39:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220609/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220609/ took longer than 180.0 seconds..
2025-05-04 06:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:42:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220606/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220606/ took longer than 180.0 seconds..
2025-05-04 06:42:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220606/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220606/ took longer than 180.0 seconds..
2025-05-04 06:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:42:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220607/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220607/ took longer than 180.0 seconds..
2025-05-04 06:42:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220607/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220607/ took longer than 180.0 seconds..
2025-05-04 06:42:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220608/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220608/ took longer than 180.0 seconds..
2025-05-04 06:42:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220608/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220608/ took longer than 180.0 seconds..
2025-05-04 06:42:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220609/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220609/ took longer than 180.0 seconds..
2025-05-04 06:42:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220609/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220609/ took longer than 180.0 seconds..
2025-05-04 06:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:45:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220610/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220610/ took longer than 180.0 seconds..
2025-05-04 06:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:45:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220611/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220611/ took longer than 180.0 seconds..
2025-05-04 06:45:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220612/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220612/ took longer than 180.0 seconds..
2025-05-04 06:45:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220613/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220613/ took longer than 180.0 seconds..
2025-05-04 06:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:48:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220610/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220610/ took longer than 180.0 seconds..
2025-05-04 06:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:48:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220611/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220611/ took longer than 180.0 seconds..
2025-05-04 06:48:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220612/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220612/ took longer than 180.0 seconds..
2025-05-04 06:48:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220613/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220613/ took longer than 180.0 seconds..
2025-05-04 06:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:51:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220610/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220610/ took longer than 180.0 seconds..
2025-05-04 06:51:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220610/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220610/ took longer than 180.0 seconds..
2025-05-04 06:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:51:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220611/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220611/ took longer than 180.0 seconds..
2025-05-04 06:51:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220611/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220611/ took longer than 180.0 seconds..
2025-05-04 06:51:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220612/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220612/ took longer than 180.0 seconds..
2025-05-04 06:51:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220612/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220612/ took longer than 180.0 seconds..
2025-05-04 06:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220613/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220613/ took longer than 180.0 seconds..
2025-05-04 06:51:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220613/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220613/ took longer than 180.0 seconds..
2025-05-04 06:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:54:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220614/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220614/ took longer than 180.0 seconds..
2025-05-04 06:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:54:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220615/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220615/ took longer than 180.0 seconds..
2025-05-04 06:54:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220616/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220616/ took longer than 180.0 seconds..
2025-05-04 06:54:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220617/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220617/ took longer than 180.0 seconds..
2025-05-04 06:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:57:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220614/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220614/ took longer than 180.0 seconds..
2025-05-04 06:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:57:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220615/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220615/ took longer than 180.0 seconds..
2025-05-04 06:57:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220616/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220616/ took longer than 180.0 seconds..
2025-05-04 06:57:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220617/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220617/ took longer than 180.0 seconds..
2025-05-04 06:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 06:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:00:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220614/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220614/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220614/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220614/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:00:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220615/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220615/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220616/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220616/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220617/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220617/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220618/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:00:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220617/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220617/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220615/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220615/ took longer than 180.0 seconds..
2025-05-04 07:00:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220616/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20220616/ took longer than 180.0 seconds..
2025-05-04 07:00:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220619/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:00:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220620/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220621/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220618/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220619/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220620/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220621/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220618/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220618/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220619/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220619/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220620/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220620/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220621/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220621/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220622/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220623/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220624/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220625/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220622/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220623/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220624/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220625/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:01:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220622/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220622/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220623/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220623/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220624/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220624/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220625/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220625/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220626/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220627/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220628/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:01:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220629/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220626/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220627/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220628/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220629/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220626/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220626/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220627/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220627/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220628/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220628/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220629/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220629/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220630/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220701/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220702/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220703/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220630/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220701/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220702/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220703/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220630/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220630/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:02:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220701/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220701/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220702/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220702/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220703/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220703/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220704/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220705/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220706/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:02:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220707/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220704/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220705/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220706/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220707/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220704/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220704/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220705/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220705/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220706/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220706/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220707/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220707/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220708/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220709/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220710/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220711/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220708/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220709/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:03:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220710/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220711/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220708/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220708/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220709/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220709/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220710/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220710/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220711/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220711/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220712/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:03:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220713/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220714/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220715/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220712/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220713/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220714/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220715/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220712/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220712/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220713/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220713/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220714/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220714/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220715/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220715/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220716/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220717/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220718/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220719/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220716/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220717/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:04:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220718/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220719/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220716/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220716/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220717/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220717/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220718/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220718/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220719/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220719/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220720/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:04:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220721/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220722/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220723/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220720/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220721/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220722/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220723/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220720/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220720/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220721/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220721/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220722/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220722/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220723/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220723/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220724/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220725/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220726/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220727/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220724/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220725/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220726/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:05:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220727/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220724/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220724/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220725/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220725/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220726/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220726/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220727/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:05:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220727/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220728/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220729/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220730/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220731/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220728/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220729/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220730/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220731/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220728/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220728/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220729/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220729/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220730/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220730/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220731/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220731/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220801/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220802/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220803/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220804/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:06:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220801/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220802/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220803/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220804/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220801/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220801/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220802/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220802/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220803/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220803/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220804/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220804/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220805/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220806/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220807/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220808/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220805/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220806/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220807/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220808/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220805/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220805/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220806/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220806/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220807/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220807/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220808/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220808/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220809/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220810/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220811/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220812/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220809/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:07:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220810/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220811/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220812/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220809/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220809/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220810/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220810/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220811/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220811/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220812/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220812/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:07:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220813/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220814/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220815/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220816/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220813/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220814/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220815/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220816/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220813/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220813/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220814/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220814/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220815/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220815/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220816/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220816/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:08:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220817/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220818/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220819/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220820/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220817/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220818/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220819/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220820/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220817/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220817/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220818/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220818/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220819/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220819/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220820/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220820/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220821/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220822/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220823/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220824/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220821/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220822/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220823/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220824/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220821/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220821/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220822/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220822/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220823/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220823/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220824/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220824/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:09:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220825/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220826/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220827/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220828/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220825/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220826/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220827/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:09:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220828/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220825/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220825/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220826/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220826/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220827/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220827/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220828/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220828/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220829/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220830/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220831/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220901/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220829/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220830/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220831/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220901/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220829/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220829/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220830/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220830/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220831/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220831/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220901/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220901/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220902/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:10:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220903/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220904/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220905/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220902/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220903/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220904/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220905/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:10:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220902/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220902/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220903/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220903/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220904/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220904/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220905/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220905/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220906/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220907/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220908/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220909/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220906/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220907/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220908/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220909/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220906/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220906/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220907/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220907/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220908/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220908/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:11:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220909/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220909/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220910/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220911/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220912/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220913/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220910/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:11:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220911/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220912/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220913/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220910/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220910/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220911/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220911/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220912/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220912/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220913/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220913/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220914/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220915/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220916/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220917/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220914/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220915/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220916/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220917/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220914/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220914/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220915/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220915/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220916/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220916/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220917/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220917/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:12:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220918/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220919/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220920/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220921/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220918/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220919/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220920/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:12:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220921/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220918/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220918/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220919/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220919/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220920/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220920/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220921/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220921/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220922/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220923/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220924/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220925/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220922/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220923/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220924/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220925/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220922/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220922/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:13:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220923/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220923/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220924/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220924/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220925/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220925/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220926/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220927/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220928/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220929/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:13:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220926/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220927/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220928/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220929/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220926/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220926/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220927/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220927/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220928/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220928/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220929/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220929/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220930/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221001/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221002/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221003/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20220930/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221001/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221002/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221003/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20220930/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20220930/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:14:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221001/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221001/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221002/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221002/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221003/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221003/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221004/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221005/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221006/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221007/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:14:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221004/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221005/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221006/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221007/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221004/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221004/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221005/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221005/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221006/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221006/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221007/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221007/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221008/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221009/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221010/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221011/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221008/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221009/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221010/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221011/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221008/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221008/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221009/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221009/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221010/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221010/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:15:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221011/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221011/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221012/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221013/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221014/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221015/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221012/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221013/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:15:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221014/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221015/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221012/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221012/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221013/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221013/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221014/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221014/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221015/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221015/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:16:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221016/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221017/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221018/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221019/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221016/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:16:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221017/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221018/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221019/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221016/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221016/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221017/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221017/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221018/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221018/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221019/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221019/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221020/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:16:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221021/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221022/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221023/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221020/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221021/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221022/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221023/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221020/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221020/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221021/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221021/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221022/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221022/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221023/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221023/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221024/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221025/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221026/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221027/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221024/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221025/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:17:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221026/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221027/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221024/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221024/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221025/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221025/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221026/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221026/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221027/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221027/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221028/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:17:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221029/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221030/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221031/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221028/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221029/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221030/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221031/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221028/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221028/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221029/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221029/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221030/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221030/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221031/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221031/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221101/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221102/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221103/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221104/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221101/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221102/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:18:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221103/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221104/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221101/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221102/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:18:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221103/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221104/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221105/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221106/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221107/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221108/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221105/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221106/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221107/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221108/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221105/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221106/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221107/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221108/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221109/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221110/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221111/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:19:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221112/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221109/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221110/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221111/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221112/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221109/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221110/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:19:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221111/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221112/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221113/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221114/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221115/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221116/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221113/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221114/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221115/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221116/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221113/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221114/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221115/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221116/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221117/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221118/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221119/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221120/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:20:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221117/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221118/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221119/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221120/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221117/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221118/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221119/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:20:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221120/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221121/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221122/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221123/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221124/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221121/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221122/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221123/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221124/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221121/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221122/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221123/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221124/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221125/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:21:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221126/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221127/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221128/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221125/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221126/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221127/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:21:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221128/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221125/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221126/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221127/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221128/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221129/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221130/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221201/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221202/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221129/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221130/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221201/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221202/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221129/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221130/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221201/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221202/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:22:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221203/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221204/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221205/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221206/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221203/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221204/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:22:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221205/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221206/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221203/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221204/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221205/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221206/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221207/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221208/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221209/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221210/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221207/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221208/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221209/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221210/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221207/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221208/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221209/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:23:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221210/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221211/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221212/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221213/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221214/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221211/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221212/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:23:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221213/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20221214/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221211/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221212/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221213/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20221214/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20221214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:24:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221215%2f&_ordtok=2Rk3WVFRRSZPNDqHq0mWnrNrrj> from <GET https://www.tianqi.com//tianqi/wuhan/20221215/>
2025-05-04 07:24:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221216%2f&_ordtok=6bk3WVh6B6qHHnRvFMP7HSMjrQ> from <GET https://www.tianqi.com//tianqi/wuhan/20221216/>
2025-05-04 07:24:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221217%2f&_ordtok=mDk3WVL4B7VkMLrRtbkn6PbrHn> from <GET https://www.tianqi.com//tianqi/wuhan/20221217/>
2025-05-04 07:24:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221218%2f&_ordtok=mBk3WV5JQWZ2QsN94VsFMjV4nn> from <GET https://www.tianqi.com//tianqi/wuhan/20221218/>
2025-05-04 07:24:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221219%2f&_ordtok=D2W3WVhZkq0hs7fqvq7fWk4qfr> from <GET https://www.tianqi.com//tianqi/wuhan/20221219/>
2025-05-04 07:24:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221220%2f&_ordtok=FQ43WVhHqsFmR0vkQfNsRs44sH> from <GET https://www.tianqi.com//tianqi/wuhan/20221220/>
2025-05-04 07:24:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221221%2f&_ordtok=MQ43WV3b3MmDnvRnDsZTrNM1nQ> from <GET https://www.tianqi.com//tianqi/wuhan/20221221/>
2025-05-04 07:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:24:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221222%2f&_ordtok=WFW3WVq5hDm55WsbMFSqL61WJ7> from <GET https://www.tianqi.com//tianqi/wuhan/20221222/>
2025-05-04 07:24:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221223%2f&_ordtok=6JW3WV5s2sZZ64MB5W7pjqlNtN> from <GET https://www.tianqi.com//tianqi/wuhan/20221223/>
2025-05-04 07:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221224%2f&_ordtok=LB43WV5W0SZVnHNjj5KJp1N7RN> from <GET https://www.tianqi.com//tianqi/wuhan/20221224/>
2025-05-04 07:24:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221225%2f&_ordtok=SPZ3WV5BjqjHNZsRrQj11qM00Q> from <GET https://www.tianqi.com//tianqi/wuhan/20221225/>
2025-05-04 07:24:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221226%2f&_ordtok=hqW3WV3555B2qvNMDSWZVsTjD0> from <GET https://www.tianqi.com//tianqi/wuhan/20221226/>
2025-05-04 07:24:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221227%2f&_ordtok=LZk3WVRnHZVRP6q0tFWF46LRZQ> from <GET https://www.tianqi.com//tianqi/wuhan/20221227/>
2025-05-04 07:24:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221228%2f&_ordtok=DhZ3WV35DLb2QsftCnDLCfTnWV> from <GET https://www.tianqi.com//tianqi/wuhan/20221228/>
2025-05-04 07:24:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221229%2f&_ordtok=jQW3WV3VrHK6NJMWrLRRMLW5LQ> from <GET https://www.tianqi.com//tianqi/wuhan/20221229/>
2025-05-04 07:25:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221230%2f&_ordtok=MJW3WVhnR6nLJKRW4MTvtPZNJF> from <GET https://www.tianqi.com//tianqi/wuhan/20221230/>
2025-05-04 07:25:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20221231%2f&_ordtok=Vsk3WVqHn2qPnn2v3Mw32Jwnp2> from <GET https://www.tianqi.com//tianqi/wuhan/20221231/>
2025-05-04 07:25:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230101%2f&_ordtok=b0Z3WVL0bLDbRcR1PZNrDRNQrH> from <GET https://www.tianqi.com//tianqi/wuhan/20230101/>
2025-05-04 07:25:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230102%2f&_ordtok=B243WV54R0H7n7p4QKqHqKWz45> from <GET https://www.tianqi.com//tianqi/wuhan/20230102/>
2025-05-04 07:25:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230103%2f&_ordtok=jm43WV3RhDV46WVN33VHv75R6P> from <GET https://www.tianqi.com//tianqi/wuhan/20230103/>
2025-05-04 07:25:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230104%2f&_ordtok=QKk3WVZVLQDLFHW5VfR0sftRvQ> from <GET https://www.tianqi.com//tianqi/wuhan/20230104/>
2025-05-04 07:25:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230105%2f&_ordtok=0MW3WVLhHJm2rV0JVWnMrPDjFr> from <GET https://www.tianqi.com//tianqi/wuhan/20230105/>
2025-05-04 07:25:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230106%2f&_ordtok=5W43WVZmj4jPrQ7R4rf5V1Ps2j> from <GET https://www.tianqi.com//tianqi/wuhan/20230106/>
2025-05-04 07:25:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230107%2f&_ordtok=s6W3WV3QKVZND0NKv7fZ4054Ds> from <GET https://www.tianqi.com//tianqi/wuhan/20230107/>
2025-05-04 07:25:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230108%2f&_ordtok=nkk3WVhRFM676tDPDtRsF1sPS5> from <GET https://www.tianqi.com//tianqi/wuhan/20230108/>
2025-05-04 07:25:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230109%2f&_ordtok=Zh43WVhQHMHJH5Jt7kDv6STZ1H> from <GET https://www.tianqi.com//tianqi/wuhan/20230109/>
2025-05-04 07:25:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230110%2f&_ordtok=HF43WVh0kZWDFfknP22qTfnfFq> from <GET https://www.tianqi.com//tianqi/wuhan/20230110/>
2025-05-04 07:25:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230111%2f&_ordtok=jkZ3WV5S42HqnvPghBSfjDJv0Q> from <GET https://www.tianqi.com//tianqi/wuhan/20230111/>
2025-05-04 07:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:25:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230112%2f&_ordtok=7H43WV3MSN7mnK6rtQn3DKqnM5> from <GET https://www.tianqi.com//tianqi/wuhan/20230112/>
2025-05-04 07:25:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230113%2f&_ordtok=HjW3WVF0ZN6HPGP0NknnVRS5MM> from <GET https://www.tianqi.com//tianqi/wuhan/20230113/>
2025-05-04 07:25:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230114%2f&_ordtok=Fb43WVFVqR3MjWNk5HqDMFDQtD> from <GET https://www.tianqi.com//tianqi/wuhan/20230114/>
2025-05-04 07:25:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230115%2f&_ordtok=2jZ3WVZkMR0JDq6rMPPNnQDGnQ> from <GET https://www.tianqi.com//tianqi/wuhan/20230115/>
2025-05-04 07:25:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230116%2f&_ordtok=2M43WVqSZqJjrKLnH2FN5nK3KQ> from <GET https://www.tianqi.com//tianqi/wuhan/20230116/>
2025-05-04 07:25:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230117%2f&_ordtok=7Bk3WVqbrRnWQKKMQsvWwwJ7b6> from <GET https://www.tianqi.com//tianqi/wuhan/20230117/>
2025-05-04 07:25:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230118%2f&_ordtok=jBZ3WVhHbHqjrf60J7tPbJW4qH> from <GET https://www.tianqi.com//tianqi/wuhan/20230118/>
2025-05-04 07:25:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230119%2f&_ordtok=sL43WV5khhbDqsjv37WTVsT4F5> from <GET https://www.tianqi.com//tianqi/wuhan/20230119/>
2025-05-04 07:26:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230120%2f&_ordtok=MZZ3WVZrqPbkPKWcRLN5Qrs0CN> from <GET https://www.tianqi.com//tianqi/wuhan/20230120/>
2025-05-04 07:26:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230121%2f&_ordtok=W4k3WVh57DKLDqDZQtjsSpNSkj> from <GET https://www.tianqi.com//tianqi/wuhan/20230121/>
2025-05-04 07:26:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230122%2f&_ordtok=mBW3WVhB2nN5Ms54sHSsSH3rF5> from <GET https://www.tianqi.com//tianqi/wuhan/20230122/>
2025-05-04 07:26:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230123%2f&_ordtok=QSk3WV3Kq2Lj5P0MMr5RV5f74Q> from <GET https://www.tianqi.com//tianqi/wuhan/20230123/>
2025-05-04 07:26:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230124%2f&_ordtok=QBk3WVFhqqjsrZJZPjHZ5RDpDj> from <GET https://www.tianqi.com//tianqi/wuhan/20230124/>
2025-05-04 07:26:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230125%2f&_ordtok=S2W3WV5qrWmPsVq2fNnjNkjVWM> from <GET https://www.tianqi.com//tianqi/wuhan/20230125/>
2025-05-04 07:26:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230126%2f&_ordtok=kPk3WVq3sQMMMGDnRJbVjJLDTM> from <GET https://www.tianqi.com//tianqi/wuhan/20230126/>
2025-05-04 07:26:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230127%2f&_ordtok=PnZ3WVF6Dn5DNWH3FD0tFQq2VH> from <GET https://www.tianqi.com//tianqi/wuhan/20230127/>
2025-05-04 07:26:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230128%2f&_ordtok=jJ43WVZB2m7LqSkfSGDtP6QqK7> from <GET https://www.tianqi.com//tianqi/wuhan/20230128/>
2025-05-04 07:26:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230129%2f&_ordtok=h7W3WVqNWqVQRVZDVQvfjWnrkM> from <GET https://www.tianqi.com//tianqi/wuhan/20230129/>
2025-05-04 07:26:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230130%2f&_ordtok=qBW3WVZPF0mKQHJ45R766FfNNS> from <GET https://www.tianqi.com//tianqi/wuhan/20230130/>
2025-05-04 07:26:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230131%2f&_ordtok=nFW3WVR7rms5MTqSP0Mt1nkF3P> from <GET https://www.tianqi.com//tianqi/wuhan/20230131/>
2025-05-04 07:26:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230201%2f&_ordtok=FbW3WVZs0bk0nDf8SJ0v5kMnWR> from <GET https://www.tianqi.com//tianqi/wuhan/20230201/>
2025-05-04 07:26:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230202%2f&_ordtok=hhZ3WV32BmBBRqjvg5jDsP6NHs> from <GET https://www.tianqi.com//tianqi/wuhan/20230202/>
2025-05-04 07:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:26:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230203%2f&_ordtok=kmk3WVZs5K57MPHPJrQnq2vF67> from <GET https://www.tianqi.com//tianqi/wuhan/20230203/>
2025-05-04 07:26:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230204%2f&_ordtok=jWk3WVRqFPRMHQ64WJJmMFJ0V6> from <GET https://www.tianqi.com//tianqi/wuhan/20230204/>
2025-05-04 07:26:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230205%2f&_ordtok=jJZ3WV3BhMM3s5pLMD7WZ6s55n> from <GET https://www.tianqi.com//tianqi/wuhan/20230205/>
2025-05-04 07:26:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230206%2f&_ordtok=3Sk3WV3rHVWKF64L25bFqLNZPF> from <GET https://www.tianqi.com//tianqi/wuhan/20230206/>
2025-05-04 07:26:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230207%2f&_ordtok=q6k3WVLm75KkJDRjSl21J14tRq> from <GET https://www.tianqi.com//tianqi/wuhan/20230207/>
2025-05-04 07:26:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230208%2f&_ordtok=nJW3WVF52M6sjqnFW7LkHRNnkM> from <GET https://www.tianqi.com//tianqi/wuhan/20230208/>
2025-05-04 07:26:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230209%2f&_ordtok=j6Z3WVhSRJh5RVj7KKrWWTKfLP> from <GET https://www.tianqi.com//tianqi/wuhan/20230209/>
2025-05-04 07:27:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230210%2f&_ordtok=mKW3WVF4QbJ6qL0SSZ7b7M4kWM> from <GET https://www.tianqi.com//tianqi/wuhan/20230210/>
2025-05-04 07:27:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230211%2f&_ordtok=7Lk3WV3ksDMJP505WNsk2WMjwj> from <GET https://www.tianqi.com//tianqi/wuhan/20230211/>
2025-05-04 07:27:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20230212%2f&_ordtok=BFW3WVq5KjNNP6wzg7gq1RSVHR> from <GET https://www.tianqi.com//tianqi/wuhan/20230212/>
2025-05-04 07:27:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230213/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230214/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230215/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230216/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230213/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230214/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230215/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230216/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230213/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:27:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230214/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230215/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230216/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230217/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230218/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230219/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230220/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:27:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230217/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230218/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230219/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230220/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230217/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230218/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230219/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230220/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230221/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230222/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230223/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230224/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230221/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230222/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230223/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230224/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230221/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:28:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230222/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230223/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230224/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230225/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230226/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230227/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230228/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230225/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:28:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230226/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230227/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230228/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230225/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230226/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230227/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230228/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230301/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230302/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230303/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230304/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230301/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230302/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230303/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230304/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230301/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:29:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230302/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230303/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230304/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230304/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230305/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:29:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230306/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230307/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230308/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230305/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230306/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230307/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230308/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230305/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230305/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230306/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230306/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230307/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230307/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230308/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230308/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230309/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230310/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230311/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230312/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230309/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230310/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230311/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:30:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230312/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230309/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230309/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230310/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230310/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230311/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230311/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230312/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230312/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230313/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230314/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:30:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230315/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230316/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230313/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230314/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230315/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230316/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230313/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230313/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230314/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230314/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230315/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230315/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230316/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230316/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230317/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230318/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230319/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230320/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230317/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230318/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230319/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:31:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230320/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230317/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230317/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230318/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230318/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230319/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230319/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230320/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230320/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230321/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230322/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:31:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230323/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230324/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230321/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230322/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230323/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230324/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230321/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230321/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230322/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230322/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230323/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230323/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230324/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230324/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230325/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230326/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230327/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230328/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230325/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:32:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230326/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230327/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230328/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230325/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230325/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230326/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230326/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230327/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230327/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230328/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230328/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:32:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230329/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230330/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230331/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230401/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230329/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230330/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230331/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230401/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230329/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230329/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230330/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230330/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230331/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230331/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230401/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230401/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230402/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230403/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230404/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230405/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230402/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230403/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230404/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:33:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230405/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230402/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230402/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230403/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230403/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230404/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230404/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230405/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230405/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230406/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230407/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:33:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230408/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230409/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230406/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230407/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230408/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230409/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230406/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230406/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230407/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230407/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230408/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230408/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230409/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230409/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230410/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230411/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230412/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230413/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230410/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230411/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230412/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230413/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230410/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230410/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:34:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230411/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230411/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230412/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:34:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230412/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:35:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230413/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230413/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 07:35:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230414/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230415/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230416/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230417/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230414/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230415/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230416/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230417/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230414/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230414/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230415/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230415/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230416/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230416/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230417/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230417/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230418/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230419/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230420/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230421/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:35:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230418/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230419/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230420/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230421/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230418/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230418/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230419/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230419/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230420/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230420/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230421/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:35:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230421/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230422/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230423/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230424/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230425/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230422/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230423/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230424/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230425/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230422/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230422/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230423/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230423/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230424/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230424/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230425/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230425/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230426/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230427/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230428/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230429/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:36:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230426/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230427/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230428/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230429/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230426/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230426/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230427/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230427/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230428/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230428/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230429/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230429/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:36:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230430/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230501/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230502/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230503/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230430/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230501/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230502/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230503/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230430/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230430/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230501/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230501/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230502/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230502/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230503/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230503/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230504/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230505/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230506/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230507/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:37:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230504/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230505/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230506/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230507/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230504/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230504/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230505/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230505/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230506/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:37:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230506/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230507/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230507/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230508/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230509/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230510/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230511/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230508/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230509/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230510/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230511/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230508/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230508/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230509/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230509/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230510/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230510/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230511/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230511/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230512/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230513/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230514/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230515/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230512/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230513/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:38:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230514/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230515/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230512/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230512/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230513/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230513/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230514/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230514/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230515/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230515/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230516/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:38:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230517/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230518/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230519/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230516/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230517/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230518/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230519/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230516/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230516/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230517/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230517/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230518/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230518/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230519/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230519/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230520/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230521/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230522/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230523/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230520/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230521/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:39:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230522/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230523/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230520/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230520/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230521/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:39:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230521/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230522/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230522/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230523/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230523/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230524/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230525/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230526/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230527/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230524/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230525/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230526/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230527/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230524/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230524/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230525/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230525/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230526/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230526/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230527/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230527/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230528/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230529/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230530/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:40:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230531/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230528/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230529/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230530/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230531/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230528/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230528/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230529/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230529/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230530/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230530/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:40:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230531/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230531/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230601/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230602/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230603/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230604/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230601/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230602/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230603/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230604/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230601/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230601/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230602/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230602/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230603/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230603/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230604/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230604/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230605/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230606/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230607/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:41:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230608/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230605/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230606/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230607/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230608/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230605/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230605/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230606/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230606/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230607/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230607/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230608/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:41:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230608/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230609/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230610/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230611/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230612/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230609/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230610/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230611/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230612/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230609/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230609/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230610/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230610/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230611/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230611/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230612/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230612/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 07:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:42:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230613/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230614/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230615/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230616/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230613/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230614/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230615/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:42:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230616/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230613/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230613/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230614/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230614/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230615/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230615/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230616/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230616/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230617/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230618/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230619/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230620/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230617/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230618/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230619/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230620/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230617/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230617/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230618/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230618/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230619/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230619/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230620/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230620/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230621/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230622/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:43:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230623/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230624/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230621/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230622/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230623/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230624/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230621/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230621/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230622/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:43:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230622/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230623/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230623/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230624/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230624/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230625/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230626/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230627/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230628/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230625/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230626/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230627/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230628/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230625/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230625/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230626/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230626/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230627/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230627/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230628/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230628/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230629/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230630/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:44:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230701/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230702/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230629/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230630/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230701/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230702/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:44:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230629/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230629/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230630/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230630/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230701/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230701/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230702/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230702/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230703/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230704/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230705/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230706/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230703/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230704/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230705/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230706/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230703/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230703/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230704/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230704/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230705/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230705/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:45:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230706/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230706/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230707/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230708/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230709/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230710/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230707/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230708/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:45:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230709/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230710/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230707/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230707/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230708/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230708/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230709/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230709/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230710/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230710/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230711/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230712/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230713/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230714/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230711/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230712/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230713/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230714/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230711/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230711/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230712/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230712/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230713/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230713/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:46:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230714/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230714/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230715/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230716/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230717/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230718/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230715/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230716/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:46:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230717/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230718/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230715/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230715/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230716/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230716/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230717/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230717/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230718/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230718/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230719/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230720/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230721/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230722/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230719/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230720/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230721/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230722/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230719/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230719/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:47:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230720/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230720/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230721/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230721/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230722/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230722/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230723/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230724/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230725/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:47:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230726/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230723/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230724/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230725/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230726/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230723/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230723/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230724/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230724/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230725/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230725/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230726/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230726/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230727/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230728/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230729/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230730/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230727/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230728/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230729/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230730/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230727/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:48:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230727/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230728/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230728/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230729/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230729/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230730/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230730/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230731/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230801/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230802/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:48:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230803/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230731/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230801/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230802/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230803/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230731/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230731/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230801/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230801/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230802/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230802/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230803/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230803/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230804/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230805/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230806/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230807/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230804/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230805/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230806/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230807/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230804/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230804/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:49:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230805/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230805/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230806/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230806/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230807/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230807/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230808/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230809/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230810/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230811/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:49:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230808/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230809/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230810/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230811/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230808/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230808/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230809/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230809/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230810/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230810/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230811/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230811/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230812/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230813/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230814/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:50:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230815/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230812/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230813/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230814/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230815/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230812/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230812/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230813/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230813/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230814/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230814/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230815/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:50:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230815/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230816/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230817/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230818/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230819/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230816/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230817/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230818/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230819/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230816/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230816/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230817/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230817/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230818/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230818/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230819/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230819/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230820/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230821/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230822/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230823/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230820/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230821/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230822/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230823/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230820/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230820/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230821/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230821/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230822/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230822/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230823/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230823/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:51:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230824/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230825/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230826/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230827/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230824/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230825/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230826/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230827/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230824/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230824/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230825/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230825/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230826/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230826/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230827/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230827/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230828/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230829/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230830/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230831/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230828/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:52:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230829/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230830/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230831/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230828/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:52:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230828/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230829/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230829/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230830/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230830/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230831/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230831/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230901/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230902/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230903/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230904/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230901/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230902/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230903/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230904/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230901/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230901/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230902/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230902/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230903/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230903/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230904/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230904/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230905/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230906/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:53:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230907/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230908/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230905/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230906/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230907/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230908/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230905/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230905/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230906/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:53:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230906/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230907/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230907/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230908/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230908/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230909/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230910/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230911/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230912/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230909/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230910/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230911/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230912/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230909/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230909/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230910/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230910/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230911/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230911/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230912/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230912/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230913/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230914/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230915/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230916/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:54:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230913/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230914/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230915/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230916/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230913/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230913/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230914/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230914/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230915/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:54:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230915/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230916/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230916/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230917/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230918/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230919/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230920/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230917/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230918/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230919/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230920/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230917/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230918/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230917/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230918/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230919/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230919/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230920/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230920/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230921/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:55:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230922/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230923/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230924/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230921/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230922/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230923/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230924/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:55:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230921/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230921/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230922/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230922/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230923/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230923/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230924/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230924/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230925/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230926/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230927/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230928/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230925/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230926/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230927/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230928/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230925/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230925/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230926/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230926/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230927/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230927/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230928/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230928/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230929/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230930/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:56:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231001/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231002/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230929/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20230930/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231001/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231002/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230929/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230929/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20230930/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:56:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20230930/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231001/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231001/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231002/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231002/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231003/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231004/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231005/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231006/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231003/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231004/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231005/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231006/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231003/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231003/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231004/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231004/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231005/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231005/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231006/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231006/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231007/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231008/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231009/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:57:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231010/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231007/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231008/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231009/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231010/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:57:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231007/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231007/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231008/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231008/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231009/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231009/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231010/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231010/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231011/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231012/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231013/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231014/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231011/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231012/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231013/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231014/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231011/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231011/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:58:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231012/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231012/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231013/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231013/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231014/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231014/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231015/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231016/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231017/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231018/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:58:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231015/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231016/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231017/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231018/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231015/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231015/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231016/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231016/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231017/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231017/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231018/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231018/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231019/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231020/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231021/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231022/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231019/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231020/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231021/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231022/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231019/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231019/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231020/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231020/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 07:59:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231021/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231021/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231022/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231022/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231023/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231024/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231025/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231026/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 07:59:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231023/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231024/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231025/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231026/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231023/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231023/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231024/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231024/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231025/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231025/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231026/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231026/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231027/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231028/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231029/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231030/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231027/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231028/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231029/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231030/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231027/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231027/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:00:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231028/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231028/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231029/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231029/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231030/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231030/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231031/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:00:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231101/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231102/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231103/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231031/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231101/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231102/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231103/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231031/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231031/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231101/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231102/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231103/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231104/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231105/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231106/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231107/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231104/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231105/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231106/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:01:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231107/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231104/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231105/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231106/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231107/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231108/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231109/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:01:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231110/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231111/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231108/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231109/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231110/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231111/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231108/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231109/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231110/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231111/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231112/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231113/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231114/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231115/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231112/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231113/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:02:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231114/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231115/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231112/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231113/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231114/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231115/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231116/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231117/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:02:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231118/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231119/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231116/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231117/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231118/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231119/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231116/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231117/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231118/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231119/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231120/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231121/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231122/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231123/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:03:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231120/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231121/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231122/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231123/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231120/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231121/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231122/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231123/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:03:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231124/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231125/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231126/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231127/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231124/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231125/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231126/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231127/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231124/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231125/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231126/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231127/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231128/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231129/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231130/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231201/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231128/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:04:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231129/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231130/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231201/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231128/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231129/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231130/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231201/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:04:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231202/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231203/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231204/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231205/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231202/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231203/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231204/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231205/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231202/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231203/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231204/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231205/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231206/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231207/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231208/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231209/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231206/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:05:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231207/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231208/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20231209/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:05:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231206/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231207/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231208/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20231209/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20231209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:06:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231210%2f&_ordtok=hJ43WVLQBbs3DMZRNnvnR3qn4J> from <GET https://www.tianqi.com//tianqi/wuhan/20231210/>
2025-05-04 08:06:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231211%2f&_ordtok=HBW3WVRMK2LZM2tFJ66rk74fsr> from <GET https://www.tianqi.com//tianqi/wuhan/20231211/>
2025-05-04 08:06:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231212%2f&_ordtok=4MW3WVqPq4BkMSDB6V67tntPVF> from <GET https://www.tianqi.com//tianqi/wuhan/20231212/>
2025-05-04 08:06:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231213%2f&_ordtok=mK43WVhQJ66KQQr4060Fqtns4q> from <GET https://www.tianqi.com//tianqi/wuhan/20231213/>
2025-05-04 08:06:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231214%2f&_ordtok=64k3WVqNKNJmjZZ1gs4vS7Nf2S> from <GET https://www.tianqi.com//tianqi/wuhan/20231214/>
2025-05-04 08:06:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231215%2f&_ordtok=jrW3WVZMWLsb6PrHWMq0q20Rnt> from <GET https://www.tianqi.com//tianqi/wuhan/20231215/>
2025-05-04 08:06:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231216%2f&_ordtok=7rk3WVhMS6r4jqtJ7NJ47101LM> from <GET https://www.tianqi.com//tianqi/wuhan/20231216/>
2025-05-04 08:06:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231217%2f&_ordtok=52W3WVLrWbhF6r4sLQnWF6JtdN> from <GET https://www.tianqi.com//tianqi/wuhan/20231217/>
2025-05-04 08:06:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231218%2f&_ordtok=h7W3WVqNWqVQRrf0VQvN7SSwRq> from <GET https://www.tianqi.com//tianqi/wuhan/20231218/>
2025-05-04 08:06:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231219%2f&_ordtok=rFk3WVZSM2k2QQQrZwj3J72Rkr> from <GET https://www.tianqi.com//tianqi/wuhan/20231219/>
2025-05-04 08:06:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231220%2f&_ordtok=Rrk3WVZFJmj7MpTDstZZHZjFZH> from <GET https://www.tianqi.com//tianqi/wuhan/20231220/>
2025-05-04 08:06:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231221%2f&_ordtok=b7Z3WVZNKR3SFqPNf40qPZDFkj> from <GET https://www.tianqi.com//tianqi/wuhan/20231221/>
2025-05-04 08:06:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231222%2f&_ordtok=VQW3WVRhnsV3PJPSfwRD3N16nV> from <GET https://www.tianqi.com//tianqi/wuhan/20231222/>
2025-05-04 08:06:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231223%2f&_ordtok=M7W3WVhMMhDVH2D4S2fnjWHVv5> from <GET https://www.tianqi.com//tianqi/wuhan/20231223/>
2025-05-04 08:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:06:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231224%2f&_ordtok=7QZ3WVFZPPPJQMsMWVMMQ1F2Tj> from <GET https://www.tianqi.com//tianqi/wuhan/20231224/>
2025-05-04 08:06:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231225%2f&_ordtok=R443WVZr2Z66D42j0NssJV33ts> from <GET https://www.tianqi.com//tianqi/wuhan/20231225/>
2025-05-04 08:06:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231226%2f&_ordtok=kqW3WVL2sVmKjq4RkVNjWPPpkR> from <GET https://www.tianqi.com//tianqi/wuhan/20231226/>
2025-05-04 08:06:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231227%2f&_ordtok=jrk3WVL5L6BJQNT1HtkqN10nRs> from <GET https://www.tianqi.com//tianqi/wuhan/20231227/>
2025-05-04 08:06:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231228%2f&_ordtok=6BZ3WVhhQDSm6T5wssrTWJvvNs> from <GET https://www.tianqi.com//tianqi/wuhan/20231228/>
2025-05-04 08:06:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231229%2f&_ordtok=rbW3WVZqNskkj5Z7ntTgtqgv6M> from <GET https://www.tianqi.com//tianqi/wuhan/20231229/>
2025-05-04 08:07:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231230%2f&_ordtok=M3k3WVRZhBhrQvZPv7N03nM0qN> from <GET https://www.tianqi.com//tianqi/wuhan/20231230/>
2025-05-04 08:07:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20231231%2f&_ordtok=3sk3WVhMBNL6R606Z35s8VM72Q> from <GET https://www.tianqi.com//tianqi/wuhan/20231231/>
2025-05-04 08:07:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240101%2f&_ordtok=rRk3WV5VM3LVHsD4SqnrfFW18P> from <GET https://www.tianqi.com//tianqi/wuhan/20240101/>
2025-05-04 08:07:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240102%2f&_ordtok=LKW3WVRZrQF7Jt6qqtvjr8HNnR> from <GET https://www.tianqi.com//tianqi/wuhan/20240102/>
2025-05-04 08:07:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240103%2f&_ordtok=6Mk3WV30mHqhR88HJsSsSNQT6Q> from <GET https://www.tianqi.com//tianqi/wuhan/20240103/>
2025-05-04 08:07:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240104%2f&_ordtok=rW43WV3mhF0SN4jJHTZz4FSSZ7> from <GET https://www.tianqi.com//tianqi/wuhan/20240104/>
2025-05-04 08:07:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240105%2f&_ordtok=n3W3WVR2VbKhFMkJQF1snVRS2V> from <GET https://www.tianqi.com//tianqi/wuhan/20240105/>
2025-05-04 08:07:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240106%2f&_ordtok=Wr43WVhhQFFWFqFr70S7rPDnDH> from <GET https://www.tianqi.com//tianqi/wuhan/20240106/>
2025-05-04 08:07:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240107%2f&_ordtok=4SW3WVRBZbJJFlqnF5rZq363V7> from <GET https://www.tianqi.com//tianqi/wuhan/20240107/>
2025-05-04 08:07:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240108%2f&_ordtok=HmZ3WVFbqN6RqsFjnMTQSZkWtj> from <GET https://www.tianqi.com//tianqi/wuhan/20240108/>
2025-05-04 08:07:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240109%2f&_ordtok=Drk3WVFn0NqFP8QWfqL777LWkF> from <GET https://www.tianqi.com//tianqi/wuhan/20240109/>
2025-05-04 08:07:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240110%2f&_ordtok=hqW3WV3555B2q3njDSWSFkPVrQ> from <GET https://www.tianqi.com//tianqi/wuhan/20240110/>
2025-05-04 08:07:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240111%2f&_ordtok=J3W3WVLZ6rP35r8L8f8rvJ6LHP> from <GET https://www.tianqi.com//tianqi/wuhan/20240111/>
2025-05-04 08:07:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240112%2f&_ordtok=hkZ3WVZ7MqJqJQrFZVJnHW0L7F> from <GET https://www.tianqi.com//tianqi/wuhan/20240112/>
2025-05-04 08:07:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240113%2f&_ordtok=5JZ3WVL2LDhZrWj55qNPJ2prtF> from <GET https://www.tianqi.com//tianqi/wuhan/20240113/>
2025-05-04 08:07:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240114%2f&_ordtok=n3Z3WVLVRRVDjW8Q8NNMFfpj5H> from <GET https://www.tianqi.com//tianqi/wuhan/20240114/>
2025-05-04 08:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:07:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240115%2f&_ordtok=JQk3WVZhmn7BjR07fFr5MqqWkM> from <GET https://www.tianqi.com//tianqi/wuhan/20240115/>
2025-05-04 08:07:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240116%2f&_ordtok=sSW3WVRjHLZQH60HkqJkLs0rtn> from <GET https://www.tianqi.com//tianqi/wuhan/20240116/>
2025-05-04 08:07:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240117%2f&_ordtok=00k3WV5MJPZLnQVq78578j70NP> from <GET https://www.tianqi.com//tianqi/wuhan/20240117/>
2025-05-04 08:07:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240118%2f&_ordtok=K6k3WVqbjDMZFJ4r2sNH5WkfZN> from <GET https://www.tianqi.com//tianqi/wuhan/20240118/>
2025-05-04 08:08:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240119%2f&_ordtok=QRW3WVZ73F4RMtH5FjP50Zp70R> from <GET https://www.tianqi.com//tianqi/wuhan/20240119/>
2025-05-04 08:08:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240120%2f&_ordtok=kZZ3WV5NnhMkQsR58577nPnt4t> from <GET https://www.tianqi.com//tianqi/wuhan/20240120/>
2025-05-04 08:08:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240121%2f&_ordtok=Q6k3WVFLWR36FTrJmt0Q3q2sks> from <GET https://www.tianqi.com//tianqi/wuhan/20240121/>
2025-05-04 08:08:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240122%2f&_ordtok=7Q43WVhBLqP3Hbmjr4KPrlJWNV> from <GET https://www.tianqi.com//tianqi/wuhan/20240122/>
2025-05-04 08:08:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240123%2f&_ordtok=HDZ3WV5BLD0SQrPF26PrM0Ff0B> from <GET https://www.tianqi.com//tianqi/wuhan/20240123/>
2025-05-04 08:08:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240124%2f&_ordtok=2M43WVqSZqJjrrQSH2F7j76rZP> from <GET https://www.tianqi.com//tianqi/wuhan/20240124/>
2025-05-04 08:08:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240125%2f&_ordtok=Dq43WVLZ3kkDQ6Rjsvmqjtv326> from <GET https://www.tianqi.com//tianqi/wuhan/20240125/>
2025-05-04 08:08:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240126%2f&_ordtok=Zhk3WVZshnVbn0QM6J2201rTHH> from <GET https://www.tianqi.com//tianqi/wuhan/20240126/>
2025-05-04 08:08:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240127%2f&_ordtok=FWW3WVhZh7LnJtStrTNW2t1WPP> from <GET https://www.tianqi.com//tianqi/wuhan/20240127/>
2025-05-04 08:08:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240128%2f&_ordtok=RQk3WV5FD52W5PjnTt74M1WN6Q> from <GET https://www.tianqi.com//tianqi/wuhan/20240128/>
2025-05-04 08:08:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240129%2f&_ordtok=q4Z3WV3WnQbjFP5rj1QW3W37kP> from <GET https://www.tianqi.com//tianqi/wuhan/20240129/>
2025-05-04 08:08:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240130%2f&_ordtok=RWk3WVLFVn2hH5t6SvnQ7bvZvn> from <GET https://www.tianqi.com//tianqi/wuhan/20240130/>
2025-05-04 08:08:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240131%2f&_ordtok=nhZ3WVLMR0LJFrTPvt2n2RftZr> from <GET https://www.tianqi.com//tianqi/wuhan/20240131/>
2025-05-04 08:08:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240201%2f&_ordtok=VhW3WVqNSrjKNtj5DkSNv47r7r> from <GET https://www.tianqi.com//tianqi/wuhan/20240201/>
2025-05-04 08:08:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240202%2f&_ordtok=75W3WV3DJ5635Mtg1FvgsZRZ0q> from <GET https://www.tianqi.com//tianqi/wuhan/20240202/>
2025-05-04 08:08:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240203%2f&_ordtok=2jZ3WVZkMR0JDN9PMPPjSb5FR5> from <GET https://www.tianqi.com//tianqi/wuhan/20240203/>
2025-05-04 08:08:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240204%2f&_ordtok=JRZ3WVZmHV67rqLn4bGZG4qGks> from <GET https://www.tianqi.com//tianqi/wuhan/20240204/>
2025-05-04 08:08:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:08:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240205%2f&_ordtok=V2k3WVZNNHDZr7WLsZWSLNZMPq> from <GET https://www.tianqi.com//tianqi/wuhan/20240205/>
2025-05-04 08:08:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240206%2f&_ordtok=WkZ3WVhjs6N3nPZvkkJv36kZj5> from <GET https://www.tianqi.com//tianqi/wuhan/20240206/>
2025-05-04 08:08:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240207%2f&_ordtok=3hW3WV3Kmm5QMHMLh0B303L05M> from <GET https://www.tianqi.com//tianqi/wuhan/20240207/>
2025-05-04 08:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240208/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240209/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240210/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240211/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240208/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240209/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240210/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240211/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240208/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240209/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240210/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240211/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240212/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240213/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240214/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240215/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240212/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240213/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:09:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240214/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240215/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240212/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240213/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240214/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240215/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:09:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240216/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240217/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240218/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240219/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240216/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240217/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240218/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240219/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240216/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240217/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240218/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240219/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240220/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240221/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240222/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240223/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240220/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240221/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240222/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:10:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240223/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240220/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240221/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240222/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240223/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240224/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240225/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:10:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240226/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240227/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240224/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240225/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240226/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240227/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240224/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240225/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240226/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240227/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240228/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240229/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240301/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:11:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240302/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240228/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240229/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240301/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240302/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240228/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240229/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240229/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240301/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:11:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240301/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240302/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240302/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240303/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240304/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240305/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240306/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240303/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240304/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240305/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240306/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240303/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240303/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240304/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240304/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240305/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240305/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240306/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240306/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240307/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240308/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240309/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240310/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:12:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240307/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240308/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240309/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240310/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240307/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240307/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240308/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240308/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240309/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240309/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240310/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:12:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240310/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240311/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240312/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240313/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240314/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240311/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240312/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240313/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240314/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240311/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240311/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240312/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240312/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240313/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240313/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240314/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240314/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240315/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240316/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240317/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240318/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:13:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240315/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240316/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240317/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240318/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:13:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240315/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240315/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240316/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240316/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240317/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240317/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240318/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240318/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240319/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240320/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240321/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240322/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240319/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240320/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240321/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240322/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240319/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240319/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240320/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240320/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240321/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240321/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240322/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240322/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240323/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240324/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240325/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:14:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240326/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240323/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240324/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240325/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240326/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240323/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240323/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240324/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:14:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240324/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240325/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240325/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240326/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240326/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240327/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240328/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240329/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240330/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240327/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240328/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240329/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240330/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240327/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240327/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240328/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240328/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240329/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240329/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240330/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240330/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240331/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240401/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240402/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:15:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240403/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240331/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240401/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240402/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240403/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240331/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240331/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240401/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240401/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240402/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240402/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240403/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240403/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240404/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240405/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240406/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240407/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240404/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240405/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240406/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240407/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240404/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240404/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:16:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240405/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240405/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240406/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240406/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240408/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:16:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240407/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240407/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 08:16:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240409/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:16:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240410/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:16:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240408/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:16:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240411/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240409/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240410/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240408/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240408/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240411/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240409/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240409/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240410/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240410/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240412/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240411/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240411/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240413/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240414/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240412/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240415/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240413/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240414/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240412/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240412/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240415/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240413/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240413/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:17:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240414/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240414/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240416/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240415/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240415/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240417/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240418/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240416/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240419/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:17:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240417/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240418/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240416/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240416/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240419/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240417/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240417/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240418/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240418/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240420/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240419/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240419/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240421/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240422/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240420/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240423/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240421/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240422/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240420/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240420/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240423/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240421/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240421/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:18:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240422/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240422/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240424/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240423/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240423/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240425/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240426/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240424/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240427/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240425/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:18:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240426/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240424/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240424/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240427/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240425/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240425/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240426/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240426/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240428/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240427/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240427/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240429/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240430/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240428/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240501/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240429/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240430/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240428/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240428/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:19:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240501/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240429/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240429/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240430/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240430/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240502/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240501/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240501/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240503/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:19:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240504/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240502/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240505/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240503/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240504/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240502/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240502/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240505/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240503/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240503/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240504/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240504/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240506/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240505/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240505/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240507/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240508/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240506/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240509/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240507/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240508/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240506/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240506/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240509/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:20:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240507/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240507/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240508/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240508/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240510/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240509/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240509/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240511/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240512/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240510/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:20:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240513/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240511/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240512/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240510/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240510/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240513/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240511/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240511/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240512/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240512/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240514/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240513/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240513/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240515/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240516/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240514/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240517/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240515/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240516/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240514/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240514/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:21:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240517/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240515/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240515/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240516/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240516/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240518/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240517/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240517/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240519/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:21:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240520/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240518/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240521/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240519/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240520/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240518/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240518/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240521/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240519/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240519/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240520/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240520/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240522/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240521/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240521/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240523/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240524/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240522/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240525/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240523/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240524/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:22:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240522/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240522/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240525/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240523/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240523/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240524/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240524/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240526/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240525/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240525/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240527/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:22:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240528/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240526/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240529/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240527/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240528/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240526/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240526/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240529/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240527/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240527/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240528/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240528/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240530/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240529/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240529/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240531/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240601/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240530/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240602/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240531/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240601/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240530/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240530/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:23:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240602/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240531/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240531/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240601/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240601/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240603/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240602/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240602/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240604/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:23:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240605/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240603/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240606/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240604/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240605/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240603/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240603/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240606/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240604/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240604/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240605/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240605/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240607/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240606/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240606/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240608/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:24:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240609/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240607/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240610/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240608/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240609/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240607/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240607/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240610/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240608/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240608/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240609/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:24:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240609/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240611/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240610/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240610/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240612/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240613/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240611/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240614/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240612/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240613/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240611/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240611/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240614/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240612/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240612/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240613/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240613/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240615/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240614/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240614/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240616/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240617/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240615/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:25:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240618/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240616/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240617/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240615/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240615/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240618/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240616/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240616/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240617/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240617/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:25:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240619/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240618/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240618/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240620/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240621/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240619/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240622/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240620/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240621/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240619/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240619/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240622/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240620/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240620/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240621/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240621/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240623/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240622/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240622/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240624/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240625/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240623/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240626/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:26:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240624/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240625/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240623/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240623/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240626/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240624/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:26:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240624/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240625/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240625/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240627/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240626/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240626/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240628/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240629/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240627/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240630/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240628/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240629/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240627/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240627/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240630/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240628/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240628/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240629/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240629/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240701/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240630/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240630/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240702/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240703/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:27:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240701/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240704/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240702/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240703/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240701/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240701/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240704/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240702/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240702/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240703/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:27:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240703/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240705/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240704/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240704/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240706/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240707/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240705/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240708/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240706/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240707/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240705/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240705/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240708/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240706/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240706/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240707/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240707/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240709/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240708/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240708/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240710/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240711/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:28:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240709/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240712/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240710/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240711/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240709/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240709/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240712/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240710/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240710/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240711/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:28:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240711/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240713/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240712/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240712/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240714/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240715/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240713/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240716/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240714/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240715/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240713/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240713/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240716/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240714/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240714/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240715/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240715/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240717/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240716/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240716/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240718/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:29:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240719/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240717/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240720/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240718/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240719/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240717/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240717/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240720/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240718/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240718/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:29:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240719/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240719/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240721/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240720/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240720/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240722/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240723/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240721/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240724/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240722/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240723/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240721/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240721/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240724/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240722/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240722/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240723/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240723/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240725/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240724/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240724/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240726/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240727/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240725/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:30:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240728/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240726/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240727/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240725/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240725/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240728/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240726/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240726/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240727/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:30:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240727/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240729/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240728/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240728/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240730/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240731/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240729/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240801/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240730/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240731/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240729/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240729/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240801/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240730/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240730/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240731/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240731/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240802/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240801/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240801/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240803/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240804/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:31:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240802/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240805/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240803/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240804/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:31:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240802/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240802/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20240805/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240803/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240803/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240804/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240804/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240806%2f&_ordtok=JW43WV5F7H7Lr5pTqj5jf45SDM> from <GET https://www.tianqi.com//tianqi/wuhan/20240806/>
2025-05-04 08:32:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20240805/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20240805/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 08:32:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240807%2f&_ordtok=NF43WVFjLZH6nf8Q7LFqt7R6jf> from <GET https://www.tianqi.com//tianqi/wuhan/20240807/>
2025-05-04 08:32:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240808%2f&_ordtok=n2k3WVLrBQmD52B0j6nTDjSqB3> from <GET https://www.tianqi.com//tianqi/wuhan/20240808/>
2025-05-04 08:32:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240809%2f&_ordtok=JJk3WVZVMqLVJ4fJHs02T58tvj> from <GET https://www.tianqi.com//tianqi/wuhan/20240809/>
2025-05-04 08:32:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240810%2f&_ordtok=J3k3WVLkqKmR60v1sfLvvFqnkP> from <GET https://www.tianqi.com//tianqi/wuhan/20240810/>
2025-05-04 08:32:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240811%2f&_ordtok=r3W3WVR6BZV3560Z0QKtL4JSDd> from <GET https://www.tianqi.com//tianqi/wuhan/20240811/>
2025-05-04 08:32:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240812%2f&_ordtok=FF43WVLrRVhsPvsfD5j6r2MBWP> from <GET https://www.tianqi.com//tianqi/wuhan/20240812/>
2025-05-04 08:32:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240813%2f&_ordtok=Sjk3WVFj6Kj6nfWjHQjFP8P4PR> from <GET https://www.tianqi.com//tianqi/wuhan/20240813/>
2025-05-04 08:32:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240814%2f&_ordtok=Jk43WVqLRWDDPRTHJcqBQNFcrr> from <GET https://www.tianqi.com//tianqi/wuhan/20240814/>
2025-05-04 08:32:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240815%2f&_ordtok=0443WV3hKWmNrTjHNHSfSrPM33> from <GET https://www.tianqi.com//tianqi/wuhan/20240815/>
2025-05-04 08:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:32:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240816%2f&_ordtok=VBW3WVRNmL4HHH121Wf2N5j6q7> from <GET https://www.tianqi.com//tianqi/wuhan/20240816/>
2025-05-04 08:32:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240817%2f&_ordtok=DQk3WVqWZ2RPjsrF6SWjMrrrFq> from <GET https://www.tianqi.com//tianqi/wuhan/20240817/>
2025-05-04 08:32:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240818%2f&_ordtok=ZB43WV5j64mmJNS6j548P0j6rR> from <GET https://www.tianqi.com//tianqi/wuhan/20240818/>
2025-05-04 08:32:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240819%2f&_ordtok=V6k3WV52hK6kjF0NZQZ03frWQj> from <GET https://www.tianqi.com//tianqi/wuhan/20240819/>
2025-05-04 08:32:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240820%2f&_ordtok=q2Z3WVL3qDW0sWTtNjL0nLD7jF> from <GET https://www.tianqi.com//tianqi/wuhan/20240820/>
2025-05-04 08:32:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240821%2f&_ordtok=LN43WV5ZDDRQPgwvcQNr51Z71R> from <GET https://www.tianqi.com//tianqi/wuhan/20240821/>
2025-05-04 08:32:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240822%2f&_ordtok=s343WVqR0VW3r60J6PqF5rHjrQ> from <GET https://www.tianqi.com//tianqi/wuhan/20240822/>
2025-05-04 08:33:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240823%2f&_ordtok=P7Z3WV53r2Qb5QnJVK6Qv6G2H2> from <GET https://www.tianqi.com//tianqi/wuhan/20240823/>
2025-05-04 08:33:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240824%2f&_ordtok=nrZ3WV5mL063rNKWkJDb6PVRjq> from <GET https://www.tianqi.com//tianqi/wuhan/20240824/>
2025-05-04 08:33:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240825%2f&_ordtok=mhZ3WVZrn6DkjkqPLFsvnj1rPw> from <GET https://www.tianqi.com//tianqi/wuhan/20240825/>
2025-05-04 08:33:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240826%2f&_ordtok=D2k3WVZZjSPhRTsHsvFzQPqfVF> from <GET https://www.tianqi.com//tianqi/wuhan/20240826/>
2025-05-04 08:33:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240827%2f&_ordtok=r4k3WVh4KjqrqbjTHvjtrDs6Lt> from <GET https://www.tianqi.com//tianqi/wuhan/20240827/>
2025-05-04 08:33:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240828%2f&_ordtok=snk3WVqhV62LRFkqKfZ7DM6Lbs> from <GET https://www.tianqi.com//tianqi/wuhan/20240828/>
2025-05-04 08:33:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240829%2f&_ordtok=Pk43WVhr466jR5ZS55MPPNR2MP> from <GET https://www.tianqi.com//tianqi/wuhan/20240829/>
2025-05-04 08:33:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240830%2f&_ordtok=QQW3WVL05mJZJ6tRZB2BBsT6wM> from <GET https://www.tianqi.com//tianqi/wuhan/20240830/>
2025-05-04 08:33:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240831%2f&_ordtok=35Z3WVLZPWmsjL5k88DNKD0WPq> from <GET https://www.tianqi.com//tianqi/wuhan/20240831/>
2025-05-04 08:33:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240901%2f&_ordtok=kS43WVZ3Q7bjMMJn4Ht8rM10F0> from <GET https://www.tianqi.com//tianqi/wuhan/20240901/>
2025-05-04 08:33:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240902%2f&_ordtok=SjW3WVqW6sJ2Dn5NDP5rKK1vTP> from <GET https://www.tianqi.com//tianqi/wuhan/20240902/>
2025-05-04 08:33:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240903%2f&_ordtok=s243WVh0jQJrRR36SkDML7SrG6> from <GET https://www.tianqi.com//tianqi/wuhan/20240903/>
2025-05-04 08:33:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240904%2f&_ordtok=j0Z3WVL7ShZk6DVjKWRN17SbM6> from <GET https://www.tianqi.com//tianqi/wuhan/20240904/>
2025-05-04 08:33:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240905%2f&_ordtok=hBk3WVZVkQq6MHHTZvZc6PSQPz> from <GET https://www.tianqi.com//tianqi/wuhan/20240905/>
2025-05-04 08:33:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240906%2f&_ordtok=5Mk3WV3LqDQK6WP57RkF2HQ3PQ> from <GET https://www.tianqi.com//tianqi/wuhan/20240906/>
2025-05-04 08:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:33:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240907%2f&_ordtok=k4k3WVFs4rjhqSSDfn0Rn2Q36m> from <GET https://www.tianqi.com//tianqi/wuhan/20240907/>
2025-05-04 08:33:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240908%2f&_ordtok=2Dk3WVRVsm5D6S140JP1k0nVPN> from <GET https://www.tianqi.com//tianqi/wuhan/20240908/>
2025-05-04 08:33:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240909%2f&_ordtok=QV43WVR74S64DqDFsKs56nNkRq> from <GET https://www.tianqi.com//tianqi/wuhan/20240909/>
2025-05-04 08:33:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240910%2f&_ordtok=ZBW3WVFVHVmLsD6JNMTDVHMDDs> from <GET https://www.tianqi.com//tianqi/wuhan/20240910/>
2025-05-04 08:33:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240911%2f&_ordtok=4Qk3WVh6JWPNPnZLDkV56NsWSr> from <GET https://www.tianqi.com//tianqi/wuhan/20240911/>
2025-05-04 08:34:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240912%2f&_ordtok=sMZ3WVFJKnF4s322200LHVZkJn> from <GET https://www.tianqi.com//tianqi/wuhan/20240912/>
2025-05-04 08:34:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240913%2f&_ordtok=RN43WVqnbHJrH7nn5RDkk0ptVN> from <GET https://www.tianqi.com//tianqi/wuhan/20240913/>
2025-05-04 08:34:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240914%2f&_ordtok=ZVW3WVh3BrPs6McDJ7ZCH8VjC7> from <GET https://www.tianqi.com//tianqi/wuhan/20240914/>
2025-05-04 08:34:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240915%2f&_ordtok=DWZ3WVFb73NhMLFGbbFWQFJJKR> from <GET https://www.tianqi.com//tianqi/wuhan/20240915/>
2025-05-04 08:34:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240916%2f&_ordtok=jrZ3WVhnZB6HqW6g42Z0JTRvJf> from <GET https://www.tianqi.com//tianqi/wuhan/20240916/>
2025-05-04 08:34:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240917%2f&_ordtok=ssk3WVL7qQNBqFD6rvQHVDtNsQ> from <GET https://www.tianqi.com//tianqi/wuhan/20240917/>
2025-05-04 08:34:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240918%2f&_ordtok=PP43WVqS7mMnD235MD0srRN62P> from <GET https://www.tianqi.com//tianqi/wuhan/20240918/>
2025-05-04 08:34:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240919%2f&_ordtok=WVZ3WVZjrm65nTv5MvgnPTR0HH> from <GET https://www.tianqi.com//tianqi/wuhan/20240919/>
2025-05-04 08:34:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240920%2f&_ordtok=LkZ3WVFQD50Lsn8VnSR7FnZ4FN> from <GET https://www.tianqi.com//tianqi/wuhan/20240920/>
2025-05-04 08:34:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240921%2f&_ordtok=jq43WVqhLH2NHZn6Zr8MMJSs70> from <GET https://www.tianqi.com//tianqi/wuhan/20240921/>
2025-05-04 08:34:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240922%2f&_ordtok=K0W3WV5Q2j62nLq0W3JDV37fL3> from <GET https://www.tianqi.com//tianqi/wuhan/20240922/>
2025-05-04 08:34:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240923%2f&_ordtok=S6W3WVRS50Qj6sPRTQTkwZFH7M> from <GET https://www.tianqi.com//tianqi/wuhan/20240923/>
2025-05-04 08:34:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240924%2f&_ordtok=QHW3WV3JSHh66nS5CMFLkDqjZV> from <GET https://www.tianqi.com//tianqi/wuhan/20240924/>
2025-05-04 08:34:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240925%2f&_ordtok=WVZ3WVZjrm65nsv5MvgSNVLD0s> from <GET https://www.tianqi.com//tianqi/wuhan/20240925/>
2025-05-04 08:34:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240926%2f&_ordtok=6Pk3WVZLMQkMPHJrsv9n87L5MV> from <GET https://www.tianqi.com//tianqi/wuhan/20240926/>
2025-05-04 08:34:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240927%2f&_ordtok=WP43WVq6qrZZrQTnM1tRJT3MWr> from <GET https://www.tianqi.com//tianqi/wuhan/20240927/>
2025-05-04 08:34:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240928%2f&_ordtok=MLZ3WVZ0mDq6PVZ70HSQnLtr6P> from <GET https://www.tianqi.com//tianqi/wuhan/20240928/>
2025-05-04 08:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:34:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240929%2f&_ordtok=ZV43WVFR0VJJP8qMHS6tRWktVn> from <GET https://www.tianqi.com//tianqi/wuhan/20240929/>
2025-05-04 08:34:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20240930%2f&_ordtok=FhW3WVhRPbFSPFHSV7S5sbkJ6s> from <GET https://www.tianqi.com//tianqi/wuhan/20240930/>
2025-05-04 08:34:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20241001%2f&_ordtok=SLk3WVFMHQBHFDBmDH37C8Bsnr> from <GET https://www.tianqi.com//tianqi/wuhan/20241001/>
2025-05-04 08:35:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20241002%2f&_ordtok=0V43WVhJk635J6nnFjNHSF4Z5M> from <GET https://www.tianqi.com//tianqi/wuhan/20241002/>
2025-05-04 08:35:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20241003%2f&_ordtok=KBZ3WV5bNZm7Jq2Fn2sWQZrfQ1> from <GET https://www.tianqi.com//tianqi/wuhan/20241003/>
2025-05-04 08:35:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20241004%2f&_ordtok=RMZ3WV3PkVmrPntWjS87jn88Dq> from <GET https://www.tianqi.com//tianqi/wuhan/20241004/>
2025-05-04 08:35:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241005/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241006/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241007/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241008/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241005/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241006/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241007/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241008/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241005/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241005/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241006/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241006/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241007/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241007/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241008/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241008/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241009/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:35:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241010/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241011/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241012/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241009/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241010/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241011/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:35:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241012/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241009/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241009/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241010/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241010/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241011/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241011/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241012/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241012/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241013/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241014/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241015/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241016/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241013/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241014/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241015/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241016/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241013/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241013/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241014/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241014/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241015/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241015/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241016/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241016/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241017/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241018/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:36:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241019/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241020/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241017/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241018/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241019/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241020/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241017/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241017/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241018/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:36:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241018/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241019/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241019/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241020/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241020/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241021/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241022/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241023/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241024/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241021/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241022/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241023/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241024/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241021/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241021/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241022/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241022/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241023/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241023/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:37:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241024/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241024/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241025/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241026/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241027/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241028/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241025/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241026/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:37:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241027/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241028/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241025/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241025/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241026/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241026/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241027/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241027/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241028/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241028/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241029/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241030/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241031/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241101/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241029/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241030/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241031/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241101/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241029/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241029/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241030/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241030/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241031/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241031/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241101/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:38:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241102/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241103/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241104/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241105/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241102/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241103/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241104/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:38:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241105/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241102/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241103/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241104/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241105/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241106/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241107/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241108/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241109/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241106/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241107/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241108/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241109/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241106/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241107/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241108/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241109/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:39:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241109/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241110/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241111/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241112/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241113/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241110/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241111/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241112/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:39:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241113/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241110/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241110/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241111/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241111/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241112/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241112/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241113/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241113/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241114/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241115/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241116/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241117/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241114/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241115/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241116/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241117/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241114/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241114/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241115/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241115/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:40:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241116/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241116/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241117/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241117/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241118/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241119/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241120/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241121/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241118/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241119/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:40:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241120/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241121/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241118/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241118/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241119/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241119/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241120/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241120/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241121/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241121/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241122/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241123/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241124/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241125/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241122/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241123/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241124/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241125/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241122/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241122/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241123/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241123/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241124/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241124/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:41:42 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241125/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241125/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241126/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241127/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241128/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241129/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241126/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:41:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241127/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241128/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241129/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241126/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241126/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241127/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241127/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241128/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241128/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241129/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241129/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241130/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241201/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241202/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241203/> (failed 1 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241130/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241201/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241202/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241203/> (failed 2 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241130/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241130/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:42:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241201/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241201/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241202/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241202/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241203/> (failed 3 times): Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:42:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241203/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 221.122.91.36:8080 [{'status': 407, 'reason': b'Unauthorized'}]
2025-05-04 08:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:45:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241204/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241204/ took longer than 180.0 seconds..
2025-05-04 08:46:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241205/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241205/ took longer than 180.0 seconds..
2025-05-04 08:46:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241206/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241206/ took longer than 180.0 seconds..
2025-05-04 08:46:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241207/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241207/ took longer than 180.0 seconds..
2025-05-04 08:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:47:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:48:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:48:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241204/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241204/ took longer than 180.0 seconds..
2025-05-04 08:49:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241205/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241205/ took longer than 180.0 seconds..
2025-05-04 08:49:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241206/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241206/ took longer than 180.0 seconds..
2025-05-04 08:49:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241207/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241207/ took longer than 180.0 seconds..
2025-05-04 08:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:50:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:51:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:51:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241204/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241204/ took longer than 180.0 seconds..
2025-05-04 08:51:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241204/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241204/ took longer than 180.0 seconds..
2025-05-04 08:52:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241205/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241205/ took longer than 180.0 seconds..
2025-05-04 08:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241205/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241205/ took longer than 180.0 seconds..
2025-05-04 08:52:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241206/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241206/ took longer than 180.0 seconds..
2025-05-04 08:52:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241206/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241206/ took longer than 180.0 seconds..
2025-05-04 08:52:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241207/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241207/ took longer than 180.0 seconds..
2025-05-04 08:52:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241207/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241207/ took longer than 180.0 seconds..
2025-05-04 08:52:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:54:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:54:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241208/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241208/ took longer than 180.0 seconds..
2025-05-04 08:55:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241209/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241209/ took longer than 180.0 seconds..
2025-05-04 08:55:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241210/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241210/ took longer than 180.0 seconds..
2025-05-04 08:55:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241211/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241211/ took longer than 180.0 seconds..
2025-05-04 08:55:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:56:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:57:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:57:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241208/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241208/ took longer than 180.0 seconds..
2025-05-04 08:58:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241209/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241209/ took longer than 180.0 seconds..
2025-05-04 08:58:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241210/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241210/ took longer than 180.0 seconds..
2025-05-04 08:58:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241211/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241211/ took longer than 180.0 seconds..
2025-05-04 08:58:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 08:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:00:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241208/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241208/ took longer than 180.0 seconds..
2025-05-04 09:00:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241208/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241208/ took longer than 180.0 seconds..
2025-05-04 09:01:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241209/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241209/ took longer than 180.0 seconds..
2025-05-04 09:01:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241209/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241209/ took longer than 180.0 seconds..
2025-05-04 09:01:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241210/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241210/ took longer than 180.0 seconds..
2025-05-04 09:01:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241210/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241210/ took longer than 180.0 seconds..
2025-05-04 09:01:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241211/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241211/ took longer than 180.0 seconds..
2025-05-04 09:01:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241211/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241211/ took longer than 180.0 seconds..
2025-05-04 09:01:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:03:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241212/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241212/ took longer than 180.0 seconds..
2025-05-04 09:04:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241213/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241213/ took longer than 180.0 seconds..
2025-05-04 09:04:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241214/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241214/ took longer than 180.0 seconds..
2025-05-04 09:04:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241215/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241215/ took longer than 180.0 seconds..
2025-05-04 09:04:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:05:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:06:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241212/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241212/ took longer than 180.0 seconds..
2025-05-04 09:07:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241213/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241213/ took longer than 180.0 seconds..
2025-05-04 09:07:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241214/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241214/ took longer than 180.0 seconds..
2025-05-04 09:07:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241215/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241215/ took longer than 180.0 seconds..
2025-05-04 09:07:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:08:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:09:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:09:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241212/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241212/ took longer than 180.0 seconds..
2025-05-04 09:09:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241212/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241212/ took longer than 180.0 seconds..
2025-05-04 09:10:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241213/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241213/ took longer than 180.0 seconds..
2025-05-04 09:10:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241213/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241213/ took longer than 180.0 seconds..
2025-05-04 09:10:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241214/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241214/ took longer than 180.0 seconds..
2025-05-04 09:10:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241214/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241214/ took longer than 180.0 seconds..
2025-05-04 09:10:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241215/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241215/ took longer than 180.0 seconds..
2025-05-04 09:10:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241215/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241215/ took longer than 180.0 seconds..
2025-05-04 09:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:12:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241216/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241216/ took longer than 180.0 seconds..
2025-05-04 09:13:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241217/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241217/ took longer than 180.0 seconds..
2025-05-04 09:13:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241218/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241218/ took longer than 180.0 seconds..
2025-05-04 09:13:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241219/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241219/ took longer than 180.0 seconds..
2025-05-04 09:13:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:15:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:15:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241216/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241216/ took longer than 180.0 seconds..
2025-05-04 09:16:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241217/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241217/ took longer than 180.0 seconds..
2025-05-04 09:16:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241218/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241218/ took longer than 180.0 seconds..
2025-05-04 09:16:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241219/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241219/ took longer than 180.0 seconds..
2025-05-04 09:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:18:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:18:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241216/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241216/ took longer than 180.0 seconds..
2025-05-04 09:18:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241216/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241216/ took longer than 180.0 seconds..
2025-05-04 09:19:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241217/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241217/ took longer than 180.0 seconds..
2025-05-04 09:19:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241217/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241217/ took longer than 180.0 seconds..
2025-05-04 09:19:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241218/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241218/ took longer than 180.0 seconds..
2025-05-04 09:19:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241218/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241218/ took longer than 180.0 seconds..
2025-05-04 09:19:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241219/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241219/ took longer than 180.0 seconds..
2025-05-04 09:19:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241219/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241219/ took longer than 180.0 seconds..
2025-05-04 09:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:20:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:21:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:21:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241220/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241220/ took longer than 180.0 seconds..
2025-05-04 09:22:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241221/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241221/ took longer than 180.0 seconds..
2025-05-04 09:22:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241222/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241222/ took longer than 180.0 seconds..
2025-05-04 09:22:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241223/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241223/ took longer than 180.0 seconds..
2025-05-04 09:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:24:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241220/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241220/ took longer than 180.0 seconds..
2025-05-04 09:25:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241221/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241221/ took longer than 180.0 seconds..
2025-05-04 09:25:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241222/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241222/ took longer than 180.0 seconds..
2025-05-04 09:25:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241223/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241223/ took longer than 180.0 seconds..
2025-05-04 09:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:26:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:27:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241220/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241220/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241220/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241220/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241221/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241221/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241222/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241222/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241223/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241223/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241221/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241221/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241222/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241222/ took longer than 180.0 seconds..
2025-05-04 09:28:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241223/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241223/ took longer than 180.0 seconds..
2025-05-04 09:28:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:31:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241224/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241224/ took longer than 180.0 seconds..
2025-05-04 09:31:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241225/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241225/ took longer than 180.0 seconds..
2025-05-04 09:31:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241226/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241226/ took longer than 180.0 seconds..
2025-05-04 09:31:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241227/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241227/ took longer than 180.0 seconds..
2025-05-04 09:31:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:32:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:34:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241224/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241224/ took longer than 180.0 seconds..
2025-05-04 09:34:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241225/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241225/ took longer than 180.0 seconds..
2025-05-04 09:34:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241226/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241226/ took longer than 180.0 seconds..
2025-05-04 09:34:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241227/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241227/ took longer than 180.0 seconds..
2025-05-04 09:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:35:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:36:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:37:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241224/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241224/ took longer than 180.0 seconds..
2025-05-04 09:37:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241224/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241224/ took longer than 180.0 seconds..
2025-05-04 09:37:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241225/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241225/ took longer than 180.0 seconds..
2025-05-04 09:37:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241225/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241225/ took longer than 180.0 seconds..
2025-05-04 09:37:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241226/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241226/ took longer than 180.0 seconds..
2025-05-04 09:37:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241226/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241226/ took longer than 180.0 seconds..
2025-05-04 09:37:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241227/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241227/ took longer than 180.0 seconds..
2025-05-04 09:37:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241227/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241227/ took longer than 180.0 seconds..
2025-05-04 09:37:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:39:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:40:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241228/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241228/ took longer than 180.0 seconds..
2025-05-04 09:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241229/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241229/ took longer than 180.0 seconds..
2025-05-04 09:40:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241230/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241230/ took longer than 180.0 seconds..
2025-05-04 09:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241231/> (failed 1 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241231/ took longer than 180.0 seconds..
2025-05-04 09:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:43:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241228/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241228/ took longer than 180.0 seconds..
2025-05-04 09:43:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241229/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241229/ took longer than 180.0 seconds..
2025-05-04 09:43:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241230/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241230/ took longer than 180.0 seconds..
2025-05-04 09:43:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20241231/> (failed 2 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241231/ took longer than 180.0 seconds..
2025-05-04 09:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 09:46:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241228/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241228/ took longer than 180.0 seconds..
2025-05-04 09:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241228/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241228/ took longer than 180.0 seconds..
2025-05-04 09:46:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241229/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241229/ took longer than 180.0 seconds..
2025-05-04 09:46:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241229/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241229/ took longer than 180.0 seconds..
2025-05-04 09:46:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241230/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241230/ took longer than 180.0 seconds..
2025-05-04 09:46:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241230/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241230/ took longer than 180.0 seconds..
2025-05-04 09:46:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20241231/> (failed 3 times): User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241231/ took longer than 180.0 seconds..
2025-05-04 09:46:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20241231/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.tianqi.com//tianqi/wuhan/20241231/ took longer than 180.0 seconds..
2025-05-04 09:46:18 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-04 09:46:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4401,
 'downloader/exception_type_count/scrapy.core.downloader.handlers.http11.TunnelError': 736,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 1260,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 1797,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 608,
 'downloader/request_bytes': 2001922,
 'downloader/request_count': 4761,
 'downloader/request_method_count/GET': 4761,
 'downloader/response_bytes': 144360,
 'downloader/response_count': 360,
 'downloader/response_status_count/307': 360,
 'elapsed_time_seconds': 38377.352865,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 4, 1, 46, 18, 211009, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 3300,
 'log_count/ERROR': 2934,
 'log_count/INFO': 649,
 'offsite/domains': 1,
 'offsite/filtered': 360,
 'responses_per_minute': None,
 'retry/count': 2934,
 'retry/max_reached': 1467,
 'retry/reason_count/scrapy.core.downloader.handlers.http11.TunnelError': 488,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 840,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 1198,
 'retry/reason_count/twisted.internet.error.TimeoutError': 408,
 'scheduler/dequeued': 4761,
 'scheduler/dequeued/memory': 4761,
 'scheduler/enqueued': 4761,
 'scheduler/enqueued/memory': 4761,
 'start_time': datetime.datetime(2025, 5, 3, 15, 6, 40, 858144, tzinfo=datetime.timezone.utc)}
2025-05-04 09:46:18 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-04 10:42:03 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-04 10:42:03 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-04 10:42:03 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-04 10:42:03 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-04 10:42:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:42:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:42:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:42:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:42:03 [scrapy.extensions.telnet] INFO: Telnet Password: 042d811694d4c805
2025-05-04 10:42:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-04 10:42:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-04 10:42:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-04 10:42:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-04 10:42:04 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-04 10:42:04 [scrapy.core.engine] INFO: Spider opened
2025-05-04 10:42:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 10:42:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-04 10:42:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 1 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 2 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 3 times): DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.DNSLookupError: DNS lookup failed: address '159.75.163.606' not found: [Errno 11001] getaddrinfo failed.
2025-05-04 10:42:29 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-05-04 10:42:29 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-05-04 10:42:31 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-05-04 10:43:06 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-04 10:43:06 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-04 10:43:06 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-04 10:43:06 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-04 10:43:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:43:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:43:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:43:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:43:06 [scrapy.extensions.telnet] INFO: Telnet Password: cf1e781814f6de6e
2025-05-04 10:43:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-04 10:43:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-04 10:43:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-04 10:43:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-04 10:43:07 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-04 10:43:07 [scrapy.core.engine] INFO: Spider opened
2025-05-04 10:43:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 10:43:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-04 10:43:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200101/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200101/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200102/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200102/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200103/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200103/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200104/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200104/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:43:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200105/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200105/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:02 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200106/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200106/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200107/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200107/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 10:44:08 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-05-04 10:44:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.tianqi.com//tianqi/wuhan/20200108/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:08 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-05-04 10:44:08 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-05-04 10:44:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.tianqi.com//tianqi/wuhan/20200108/>
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "C:\ProgramData\Miniconda3\envs\weather_predict\lib\site-packages\scrapy\core\downloader\middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2025-05-04 10:44:23 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-04 10:44:23 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-04 10:44:23 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-04 10:44:23 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-04 10:44:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:44:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:44:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:44:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:44:23 [scrapy.extensions.telnet] INFO: Telnet Password: b85e3c73facd8c72
2025-05-04 10:44:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-04 10:44:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-04 10:44:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-04 10:44:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-04 10:44:24 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-04 10:44:24 [scrapy.core.engine] INFO: Spider opened
2025-05-04 10:44:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 10:44:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-04 10:44:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200101%2f&_ordtok=2043WVL2nL02D6S3JKm5B7hKsH> from <GET https://www.tianqi.com//tianqi/wuhan/20200101/>
2025-05-04 10:44:25 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'gateway.zscloud.net': <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200101%2f&_ordtok=2043WVL2nL02D6S3JKm5B7hKsH>
2025-05-04 10:44:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://gateway.zscloud.net:443/auD?origurl=https%3A%2F%2Fwww%2etianqi%2ecom%2f%2f%2f%2ftianqi%2fwuhan%2f20200102%2f&_ordtok=Q543WV34brFsQNkPnFJj7C6JZJ> from <GET https://www.tianqi.com//tianqi/wuhan/20200102/>
2025-05-04 10:44:27 [scrapy.core.engine] INFO: Closing spider (finished)
2025-05-04 10:44:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 804,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 802,
 'downloader/response_count': 2,
 'downloader/response_status_count/307': 2,
 'elapsed_time_seconds': 2.60038,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 5, 4, 2, 44, 27, 187388, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 8,
 'log_count/INFO': 10,
 'offsite/domains': 1,
 'offsite/filtered': 2,
 'responses_per_minute': None,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2025, 5, 4, 2, 44, 24, 587008, tzinfo=datetime.timezone.utc)}
2025-05-04 10:44:27 [scrapy.core.engine] INFO: Spider closed (finished)
2025-05-04 10:46:46 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: weather_project)
2025-05-04 10:46:46 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.13.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.0.15 3 Sep 2024), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0
2025-05-04 10:46:46 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-04 10:46:46 [asyncio] DEBUG: Using selector: SelectSelector
2025-05-04 10:46:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:46:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:46:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-05-04 10:46:46 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-05-04 10:46:46 [scrapy.extensions.telnet] INFO: Telnet Password: 55cc03c10d4b5665
2025-05-04 10:46:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-05-04 10:46:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'weather_project',
 'CONCURRENT_REQUESTS': 4,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_debug.log',
 'NEWSPIDER_MODULE': 'weather_project.spiders',
 'SPIDER_MODULES': ['weather_project.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-05-04 10:46:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-05-04 10:46:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-05-04 10:46:48 [scrapy.middleware] INFO: Enabled item pipelines:
['weather_project.pipelines.year5_WeatherPipeline']
2025-05-04 10:46:48 [scrapy.core.engine] INFO: Spider opened
2025-05-04 10:46:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 10:46:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-05-04 10:47:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-05-04 10:48:28 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-05-04 10:48:28 [scrapy.core.engine] INFO: Closing spider (shutdown)
